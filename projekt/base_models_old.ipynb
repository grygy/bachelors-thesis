{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tempfile\n",
    "from os import path\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_X, train_y, model_path, batch_size=64):\n",
    "    if path.exists(model_path):\n",
    "        print(\"Model is already trained and saved here: \" + model_path)\n",
    "        return\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    checkpoint_filepath = './tmp/'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "    model.fit(\n",
    "        train_images,\n",
    "        train_labels,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        validation_split=0.1,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[model_checkpoint_callback]\n",
    "    )\n",
    "    \n",
    "    # save model\n",
    "    model.save(model_path)\n",
    "    print('Saved to: ' + model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wrap model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_model(base_model, num_classes):\n",
    "    inputs = base_model.inputs\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(num_classes)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "INPUT_SHAPE = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar_dataset():\n",
    "    (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "    train_images = tf.cast(train_images, tf.float32)\n",
    "    test_images = tf.cast(test_images, tf.float32)\n",
    "    \n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    return (train_images, train_labels), (test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_cifar_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mobilenetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './cifar_models/MobileNetV2_cifar_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is already trained and saved here: ./cifar_models/MobileNetV2_cifar_model.h5\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(include_top=False, weights=None, input_shape=INPUT_SHAPE)\n",
    "\n",
    "model = wrap_model(base_model=base_model, num_classes=NUM_CLASSES)\n",
    "\n",
    "train_model(model=model, train_X=train_images, train_y=train_labels, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNets - B0, B4\n",
    "\n",
    "https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = './cifar_models/EfficentNetB0_cifar_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is already trained and saved here: ./cifar_models/EfficentNetB0_cifar_model.h5\n"
     ]
    }
   ],
   "source": [
    "base_model = EfficientNetB0(include_top=False, weights=None, input_shape=INPUT_SHAPE)\n",
    "\n",
    "model = wrap_model(base_model=base_model, num_classes=NUM_CLASSES)\n",
    "\n",
    "train_model(model=model, train_X=train_images, train_y=train_labels, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = './cifar_models/EfficentNetB4_cifar_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is already trained and saved here: ./cifar_models/EfficentNetB4_cifar_model.h5\n"
     ]
    }
   ],
   "source": [
    "base_model = EfficientNetB4(include_top=False, weights=None, input_shape=INPUT_SHAPE)\n",
    "\n",
    "model = wrap_model(base_model=base_model, num_classes=NUM_CLASSES)\n",
    "\n",
    "train_model(model=model, train_X=train_images, train_y=train_labels, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "INPUT_SHAPE = (32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_dataset():\n",
    "    (train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "    # resize image to minimum dimensions for models\n",
    "    # adding new pixels to sides\n",
    "    train_images = np.expand_dims(train_images, axis=-1)\n",
    "    train_images = tf.image.resize_with_crop_or_pad(train_images, target_height=32, target_width=32)\n",
    "\n",
    "    test_images = np.expand_dims(test_images, axis=-1)\n",
    "    test_images = tf.image.resize_with_crop_or_pad(test_images, target_height=32, target_width=32)\n",
    "\n",
    "    train_images = tf.cast(train_images, tf.float32)\n",
    "    test_images = tf.cast(test_images, tf.float32)\n",
    "\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    return (train_images, train_labels), (test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_mnist_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mobilenetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './mnist_models/MobileNetV2_mnist_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is already trained and saved here: ./mnist_models/MobileNetV2_mnist_model.h5\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(include_top=False, weights=None, input_shape=INPUT_SHAPE)\n",
    "\n",
    "model = wrap_model(base_model=base_model, num_classes=NUM_CLASSES)\n",
    "\n",
    "train_model(model=model, train_X=train_images, train_y=train_labels, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNets - B0, B4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = './mnist_models/EfficentNetB0_mnist_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is already trained and saved here: ./mnist_models/EfficentNetB0_mnist_model.h5\n"
     ]
    }
   ],
   "source": [
    "base_model = EfficientNetB0(include_top=False, weights=None, input_shape=INPUT_SHAPE)\n",
    "\n",
    "model = wrap_model(base_model=base_model, num_classes=NUM_CLASSES)\n",
    "\n",
    "train_model(model=model, train_X=train_images, train_y=train_labels, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = './mnist_models/EfficentNetB4_mnist_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is already trained and saved here: ./mnist_models/EfficentNetB4_mnist_model.h5\n"
     ]
    }
   ],
   "source": [
    "base_model = EfficientNetB4(include_top=False, weights=None, input_shape=INPUT_SHAPE)\n",
    "\n",
    "model = wrap_model(base_model=base_model, num_classes=NUM_CLASSES)\n",
    "\n",
    "train_model(model=model, train_X=train_images, train_y=train_labels, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beans dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "INPUT_SHAPE = (500, 500, 3)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ds_to_tensors(ds):\n",
    "    \"\"\"returns tuple of train_X, train_y\"\"\"\n",
    "    a = ds.map(lambda a, b: a)\n",
    "    tf_list = []\n",
    "    for i in a:\n",
    "        tf_list.append(i)\n",
    "    train_X = tf.stack(tf_list, axis=0)\n",
    "    \n",
    "    b = ds.map(lambda a, b: b)\n",
    "    tf_list = []\n",
    "    for i in b:\n",
    "        tf_list.append([i.numpy()])\n",
    "    train_y = np.array(tf_list, dtype=np.uint8)\n",
    "    return train_X, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_beans_dataset():\n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        'beans',\n",
    "        split=['train','test'],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "    \n",
    "    # convert to tensors and np array from tf.DataSet\n",
    "    train_images, train_labels = convert_ds_to_tensors(ds_train)\n",
    "    test_images, test_labels = convert_ds_to_tensors(ds_test)\n",
    "\n",
    "    train_images = tf.cast(train_images, tf.float32)\n",
    "    test_images = tf.cast(test_images, tf.float32)\n",
    "    \n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    return (train_images, train_labels), (test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_beans_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mobilenetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './beans_models/MobileNetV2_beans_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is already trained and saved here: ./beans_models/MobileNetV2_beans_model.h5\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(include_top=False, weights=None, input_shape=INPUT_SHAPE)\n",
    "\n",
    "model = wrap_model(base_model=base_model, num_classes=NUM_CLASSES)\n",
    "\n",
    "train_model(model=model, train_X=train_images, train_y=train_labels, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNets - B0, B4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = './beans_models/EfficentNetB0_beans_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is already trained and saved here: ./beans_models/EfficentNetB0_beans_model.h5\n"
     ]
    }
   ],
   "source": [
    "base_model = EfficientNetB0(include_top=False, weights=None, input_shape=INPUT_SHAPE)\n",
    "\n",
    "model = wrap_model(base_model=base_model, num_classes=NUM_CLASSES)\n",
    "\n",
    "train_model(model=model, train_X=train_images, train_y=train_labels, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = './beans_models/EfficentNetB4_beans_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "base_model = EfficientNetB4(include_top=False, weights=None, input_shape=INPUT_SHAPE)\n",
    "\n",
    "model = wrap_model(base_model=base_model, num_classes=NUM_CLASSES)\n",
    "\n",
    "train_model(model=model, train_X=train_images, train_y=train_labels, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
