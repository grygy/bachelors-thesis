{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from os import path\n",
    "import pathlib\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the images to [0, 1]\n",
    "def normalize(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "def random_crop(image):\n",
    "    cropped_image = tf.image.random_crop(\n",
    "        image, size=[256, 256, 3])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def random_jitter(image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    image = random_crop(image)\n",
    "\n",
    "    # random mirroring\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def preprocess_flowers_train(image, label):\n",
    "    image = random_jitter(image)\n",
    "    return image, label\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "def preprocess_flowers(image, label):\n",
    "    image = tf.image.resize(image, [256, 256],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return image, label\n",
    "\n",
    "def load_flowers_dataset():  \n",
    "    (ds_train, ds_validation, ds_test), ds_info = tfds.load(name=\"tf_flowers\", \n",
    "                                             with_info=True,\n",
    "                                             split=['train[:70%]', 'train[70%:85%]', 'train[85%:]'],  #70/15/15 split\n",
    "                                             as_supervised=True)\n",
    "\n",
    "    ds_train = ds_train.map(normalize)    \n",
    "    ds_train = ds_train.map(preprocess_flowers)\n",
    "    ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "    \n",
    "    ds_validation = ds_validation.map(normalize)\n",
    "    ds_validation = ds_validation.map(preprocess_flowers)\n",
    "    \n",
    "    ds_test = ds_test.map(normalize)\n",
    "    ds_test = ds_test.map(preprocess_flowers)\n",
    "    \n",
    "    return ds_train, ds_validation, ds_test\n",
    "\n",
    "def load_beans_datasets():\n",
    "    (ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
    "        'beans',\n",
    "        split=['train', 'validation', 'test'],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "    \n",
    "    ds_train = ds_train.map(normalize)\n",
    "    ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "    \n",
    "    ds_validation = ds_validation.map(normalize)\n",
    "    \n",
    "    ds_test = ds_test.map(normalize)\n",
    "    \n",
    "    return ds_train, ds_validation, ds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization after training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization after training\n",
    "\n",
    "1. Dynamic range quantization\n",
    "2. Full integer quantization\n",
    "3. Float16 quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dynamic range quantization\n",
    "\n",
    "Only the weights are converted from float to 8 bit int. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Full integer quantization\n",
    "\n",
    "Weights and activation outputs are quantizated. Good for microcontrolers and TPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_quantization(model_path, ds):\n",
    "    # check if model was already in optimization folder\n",
    "    if (len(model_path.split('/')[0].split('_')) == 3):\n",
    "        optimized_dir = pathlib.Path(model_path.split('/')[0] + '/')\n",
    "    else:\n",
    "        optimized_dir = pathlib.Path(model_path.split('/')[0] + '_optimized/')\n",
    "    model_name = model_path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    # save converted tflite model\n",
    "    tf_model_path = optimized_dir/(model_name + '.tflite')\n",
    "    size = tf_model_path.write_bytes(tflite_model)\n",
    "    print('Converted TFLite model ('+ str(size) +' Bytes) saved to: ' + str(tf_model_path))\n",
    "    \n",
    "    # 1. optimize model using dynamic range quantization\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model_quant = converter.convert()\n",
    "    \n",
    "    tf_quant_model_path = optimized_dir/(model_name + '_dynamic_rage_quantization.tflite')\n",
    "    size = tf_quant_model_path.write_bytes(tflite_model_quant)\n",
    "    print('Dynamic range quantizatized TFLite model ('+ str(size) +' Bytes) saved to: ' + str(tf_quant_model_path))\n",
    "    \n",
    "    # 2. Full integer quantization\n",
    "    def representative_data_gen():\n",
    "        for input_value, _ in ds.batch(1).take(100):\n",
    "            # Model has only one input so each data point has one element.\n",
    "            yield [input_value]\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "\n",
    "    tflite_model_quant = converter.convert()\n",
    "    tf_quant_model_path = optimized_dir/(model_name + '_full_integer_quantization.tflite')\n",
    "    size = tf_quant_model_path.write_bytes(tflite_model_quant)\n",
    "    print('Full integer quantizatized TFLite model ('+ str(size) +' Bytes) saved to: ' + str(tf_quant_model_path))\n",
    "    \n",
    "    # 2.1 Full integer quantization with input and output in integer too\n",
    "    try:\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_data_gen\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.uint8\n",
    "        converter.inference_output_type = tf.uint8\n",
    "\n",
    "        tflite_model_quant = converter.convert()\n",
    "        tf_quant_model_path = optimized_dir/(model_name + '_full_integer_quantization_integer_io.tflite')\n",
    "        size = tf_quant_model_path.write_bytes(tflite_model_quant)\n",
    "        print('Full integer quantizatized with integer io TFLite model ('+ str(size) +' Bytes) saved to: ' + str(tf_quant_model_path))\n",
    "    except:\n",
    "        print('ERROR: Failed Full integer quantizatized with integer io TFLite model')\n",
    "        \n",
    "    # 3. float16 quantization\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "    \n",
    "    tflite_model_quant = converter.convert()\n",
    "    tf_quant_model_path = optimized_dir/(model_name + '_float16_quantization.tflite')\n",
    "    size = tf_quant_model_path.write_bytes(tflite_model_quant)\n",
    "    print('float16 quantizatized TFLite model ('+ str(size) +' Bytes) saved to: ' + str(tf_quant_model_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning and fine-tuning\n",
    "\n",
    "1. Prune model to different sparsity  ( tf uses magnitude-based pruning )\n",
    "    1. ConstantSparsity - sparsity is kept constant during training.\n",
    "    2. PolynomialDecay - the degree of sparsity is changed during training.\n",
    "2. Fine-tune model\n",
    "\n",
    "https://www.machinecurve.com/index.php/2020/09/29/tensorflow-pruning-schedules-constantsparsity-and-polynomialdecay/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "PRUNING_EPOCHS = 10\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some layers cannot be pruned\n",
    "\n",
    "def prune_prunable_layers(model, pruning_params):\n",
    "    \"\"\"returns model for pruning with avoided non prunable layers\"\"\"\n",
    "    \n",
    "    # Rescaling layer cannot be pruned\n",
    "    def apply_pruning_to_prunable(layer):\n",
    "        if isinstance(layer, tf.keras.layers.experimental.preprocessing.Rescaling) or isinstance(layer, tf.keras.layers.experimental.preprocessing.Normalization):\n",
    "            return layer\n",
    "        return prune_low_magnitude(layer, **pruning_params)\n",
    "    model_for_pruning = tf.keras.models.clone_model(\n",
    "                                model,\n",
    "                                clone_function=apply_pruning_to_prunable,\n",
    "                            )\n",
    "    return model_for_pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model_path, batch_size, pruning_epochs, ds_train, ds_validation, sparsity):\n",
    "     # check if model was already in optimization folder\n",
    "    if (len(model_path.split('/')[0].split('_')) == 3):\n",
    "        optimized_dir = pathlib.Path(model_path.split('/')[0] + '/')\n",
    "    else:\n",
    "        optimized_dir = pathlib.Path(model_path.split('/')[0] + '_optimized/')\n",
    "    model_name = model_path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    sparsities = [0.5, 0.75, 0.9]\n",
    "    \n",
    "    ds_train = ds_train.batch(batch_size)\n",
    "    ds_validation = ds_validation.batch(batch_size)\n",
    "    \n",
    "    ds_train.cache()\n",
    "    ds_validation.cache()\n",
    "    \n",
    "    # get number of images\n",
    "    num_images = 0\n",
    "    for i in ds_train.as_numpy_iterator():\n",
    "        num_images+=1\n",
    "\n",
    "    end_step = np.ceil(num_images / batch_size).astype(np.int32) * pruning_epochs\n",
    "\n",
    "    # Define pruning configuration\n",
    "    pruning_params_constant = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=sparsity,\n",
    "                                                                    begin_step=0,\n",
    "                                                                    end_step=end_step)\n",
    "    }\n",
    "\n",
    "    pruning_params_polynomial = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0,\n",
    "                                                                final_sparsity=sparsity,\n",
    "                                                                begin_step=0,\n",
    "                                                                end_step=end_step)\n",
    "    }\n",
    "\n",
    "    # Rescaling layer cannot be wrapped in prune low magnitude\n",
    "    try:\n",
    "        model_for_pruning_constant = prune_low_magnitude(model, **pruning_params_constant)\n",
    "        model_for_pruning_polynomial = prune_low_magnitude(model, **pruning_params_polynomial)\n",
    "    except:\n",
    "        model_for_pruning_constant = prune_prunable_layers(model, pruning_params_constant) \n",
    "        model_for_pruning_polynomial = prune_prunable_layers(model, pruning_params_polynomial)\n",
    "\n",
    "\n",
    "    # Compile models for pruning\n",
    "    model_for_pruning_constant.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "    model_for_pruning_polynomial.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    constant_log_dir = pathlib.Path(\"./tmp/\" + model_name + '_ConstantSparsity' + str(int(sparsity*100)))\n",
    "    constant_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    polynomial_log_dir = pathlib.Path(\"./tmp/\" + model_name + '_PolynomialDecay' + str(int(sparsity*100)))\n",
    "    polynomial_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Model callbacks\n",
    "    constant_callbacks = [\n",
    "        tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "        tfmot.sparsity.keras.PruningSummaries(log_dir=str(constant_log_dir))\n",
    "    ]\n",
    "    polynomial_callbacks = [\n",
    "        tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "        tfmot.sparsity.keras.PruningSummaries(log_dir=str(polynomial_log_dir))\n",
    "    ]\n",
    "\n",
    "    # Fitting data\n",
    "    model_for_pruning_constant.fit(ds_train,\n",
    "                              validation_data=ds_validation,\n",
    "                              epochs=pruning_epochs,\n",
    "                              callbacks=constant_callbacks)\n",
    "\n",
    "    model_for_pruning_polynomial.fit(ds_train,\n",
    "                              validation_data=ds_validation,\n",
    "                              epochs=pruning_epochs,\n",
    "                              callbacks=polynomial_callbacks)\n",
    "\n",
    "    # Save pruned models\n",
    "    model_constant_path = optimized_dir/(model_name + '_ConstantSparsity' + str(int(sparsity*100)) + '.h5')\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning_constant)\n",
    "    model_for_export.save(str(model_constant_path))\n",
    "    print('saved ' + str(model_constant_path))\n",
    "\n",
    "    model_polynomial_path = optimized_dir/(model_name + '_PolynomialDecay' + str(int(sparsity*100)) + '.h5')\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning_polynomial)\n",
    "    model_for_export.save(str(model_polynomial_path))\n",
    "    print('saved ' + str(model_polynomial_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some layers cannot be weight clustered\n",
    "\n",
    "def cluster_clustred_layers(model, cluster_params):    \n",
    "    # Rescaling layer cannot be pruned\n",
    "    def apply_clustering_to_clusterable(layer):\n",
    "        if model.layers[0] == layer or  model.layers[-1] == layer:\n",
    "            return layer\n",
    "        try:\n",
    "            x = cluster_weights(layer, **cluster_params)\n",
    "            return x\n",
    "        except:\n",
    "            return layer\n",
    "\n",
    "    model_for_clustering = tf.keras.models.clone_model(\n",
    "                                model,\n",
    "                                clone_function=apply_clustering_to_clusterable,\n",
    "                            )\n",
    "    return model_for_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_cluster_model(model_path, batch_size, epochs, ds_train, ds_validation, number_of_clusters):\n",
    "    \"\"\" Weight clustering on given moodel \n",
    "    note: cannot use for cycle in this function to do different number of clusters because of compatibility issues\"\"\"\n",
    "     # check if model was already in optimization folder\n",
    "    if (len(model_path.split('/')[0].split('_')) == 3):\n",
    "        optimized_dir = pathlib.Path(model_path.split('/')[0] + '/')\n",
    "    else:\n",
    "        optimized_dir = pathlib.Path(model_path.split('/')[0] + '_optimized/')\n",
    "    model_name = model_path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    ds_train = ds_train.batch(batch_size)\n",
    "    ds_validation = ds_validation.batch(batch_size)\n",
    "    \n",
    "    ds_train.cache()\n",
    "    ds_validation.cache()\n",
    "    \n",
    "    # get number of images\n",
    "    num_images = 0\n",
    "    for i in ds_train.as_numpy_iterator():\n",
    "        num_images+=1\n",
    "\n",
    "    end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "    # Define weight clustering configuration\n",
    "    cluster_params_kmeans = {\n",
    "                                  'number_of_clusters': number_of_clusters,\n",
    "                                  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS\n",
    "                                }\n",
    "\n",
    "    # Rescaling layer cannot be wrapped in prune low magnitude\n",
    "    try:\n",
    "        model_for_clustering_kmeans = cluster_weights(model, **cluster_params_kmeans)\n",
    "    except:\n",
    "        model_for_clustering_kmeans = cluster_clustred_layers(model, cluster_params_kmeans)\n",
    "\n",
    "    # Compile models for clustering\n",
    "    model_for_clustering_kmeans.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    # Fitting data        \n",
    "    model_for_clustering_kmeans.fit(ds_train,\n",
    "                              validation_data=ds_validation,\n",
    "                              epochs=epochs)\n",
    "\n",
    "    # Save pruned models\n",
    "    model_kmeans_path = optimized_dir/(model_name + '_KMeansPlusPlus' + str(number_of_clusters) + '.h5')\n",
    "    model_for_export = tfmot.clustering.keras.strip_clustering(model_for_clustering_kmeans)\n",
    "    model_for_export.save(str(model_kmeans_path))\n",
    "    print('saved ' + str(model_kmeans_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimze models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "flowers_datasets = load_flowers_dataset()\n",
    "beans_datasets = load_beans_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "Due to bad tensorflow optimization of calling fit function in a loop, calling prune_model in a loop is unusable.\n",
    "Solution: don't use for loops\n",
    "Issue: https://github.com/tensorflow/tensorflow/issues/34025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prune base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macenpav/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 20s - loss: 0.3058 - accuracy: 0.9041WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1502s vs `on_train_batch_end` time: 0.3473s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1502s vs `on_train_batch_end` time: 0.3473s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 54s 597ms/step - loss: 0.3580 - accuracy: 0.8871 - val_loss: 5.1500 - val_accuracy: 0.3557\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 38s 526ms/step - loss: 0.0960 - accuracy: 0.9710 - val_loss: 5.0288 - val_accuracy: 0.3829\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 37s 525ms/step - loss: 0.0344 - accuracy: 0.9891 - val_loss: 4.2880 - val_accuracy: 0.4011\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 36s 533ms/step - loss: 0.0588 - accuracy: 0.9813 - val_loss: 2.2261 - val_accuracy: 0.5971\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 37s 530ms/step - loss: 0.0705 - accuracy: 0.9781 - val_loss: 1.5959 - val_accuracy: 0.6352\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 35s 534ms/step - loss: 0.0371 - accuracy: 0.9872 - val_loss: 1.7022 - val_accuracy: 0.6388\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 36s 530ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 1.3656 - val_accuracy: 0.6969\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 34s 511ms/step - loss: 0.0434 - accuracy: 0.9844 - val_loss: 2.0763 - val_accuracy: 0.6479\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 37s 506ms/step - loss: 0.0416 - accuracy: 0.9833 - val_loss: 2.9599 - val_accuracy: 0.6080\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 36s 523ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 1.8586 - val_accuracy: 0.6770\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 30s - loss: 0.0299 - accuracy: 0.9929WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1490s vs `on_train_batch_end` time: 0.6146s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1490s vs `on_train_batch_end` time: 0.6146s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 58s 616ms/step - loss: 0.1085 - accuracy: 0.9670 - val_loss: 2.9428 - val_accuracy: 0.5808\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 34s 519ms/step - loss: 0.1731 - accuracy: 0.9413 - val_loss: 4.3531 - val_accuracy: 0.5735\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 32s 535ms/step - loss: 0.0723 - accuracy: 0.9759 - val_loss: 3.3222 - val_accuracy: 0.6098\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 37s 522ms/step - loss: 0.0518 - accuracy: 0.9831 - val_loss: 6.5352 - val_accuracy: 0.5445\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 32s 513ms/step - loss: 0.0987 - accuracy: 0.9665 - val_loss: 10.4302 - val_accuracy: 0.4392\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 35s 503ms/step - loss: 0.1381 - accuracy: 0.9529 - val_loss: 10.3451 - val_accuracy: 0.5100\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 35s 524ms/step - loss: 0.0583 - accuracy: 0.9836 - val_loss: 8.6702 - val_accuracy: 0.5082\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 36s 528ms/step - loss: 0.0636 - accuracy: 0.9801 - val_loss: 15.0354 - val_accuracy: 0.4682\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 32s 550ms/step - loss: 0.1907 - accuracy: 0.9413 - val_loss: 17.7256 - val_accuracy: 0.3394\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 33s 525ms/step - loss: 0.1002 - accuracy: 0.9653 - val_loss: 23.8993 - val_accuracy: 0.3339\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50.h5\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50.h5\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 29s - loss: 1.8683 - accuracy: 0.5018WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1510s vs `on_train_batch_end` time: 0.5831s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1510s vs `on_train_batch_end` time: 0.5831s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 53s 593ms/step - loss: 1.3621 - accuracy: 0.6090 - val_loss: 3.9587 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 30s 529ms/step - loss: 0.4331 - accuracy: 0.8242 - val_loss: 4.3595 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 31s 528ms/step - loss: 0.1594 - accuracy: 0.9592 - val_loss: 4.5802 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 33s 537ms/step - loss: 0.1052 - accuracy: 0.9777 - val_loss: 4.9835 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 32s 521ms/step - loss: 0.1288 - accuracy: 0.9625 - val_loss: 5.1171 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 39s 557ms/step - loss: 0.1020 - accuracy: 0.9709 - val_loss: 5.2919 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 37s 540ms/step - loss: 0.1084 - accuracy: 0.9661 - val_loss: 5.4508 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 36s 536ms/step - loss: 0.1012 - accuracy: 0.9688 - val_loss: 5.3896 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 36s 529ms/step - loss: 0.0517 - accuracy: 0.9868 - val_loss: 5.6054 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 34s 522ms/step - loss: 0.0530 - accuracy: 0.9871 - val_loss: 5.6810 - val_accuracy: 0.2668\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 31s - loss: 0.0734 - accuracy: 0.9827WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1463s vs `on_train_batch_end` time: 0.6368s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1463s vs `on_train_batch_end` time: 0.6368s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 54s 595ms/step - loss: 0.2528 - accuracy: 0.9157 - val_loss: 6.6258 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 33s 534ms/step - loss: 0.2951 - accuracy: 0.9009 - val_loss: 5.7449 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 34s 532ms/step - loss: 0.2157 - accuracy: 0.9184 - val_loss: 5.2072 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 35s 526ms/step - loss: 0.2431 - accuracy: 0.9110 - val_loss: 5.0934 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 35s 533ms/step - loss: 0.1069 - accuracy: 0.9659 - val_loss: 6.1679 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 36s 532ms/step - loss: 0.0515 - accuracy: 0.9840 - val_loss: 5.7989 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 34s 541ms/step - loss: 0.0355 - accuracy: 0.9933 - val_loss: 5.3291 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 36s 522ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 5.1304 - val_accuracy: 0.2686\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 32s 532ms/step - loss: 0.0286 - accuracy: 0.9899 - val_loss: 5.4675 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 35s 510ms/step - loss: 0.2393 - accuracy: 0.9142 - val_loss: 3.5020 - val_accuracy: 0.4174\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75.h5\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75.h5\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 28s - loss: 3.9170 - accuracy: 0.2914WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1530s vs `on_train_batch_end` time: 0.5488s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1530s vs `on_train_batch_end` time: 0.5488s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 56s 591ms/step - loss: 2.9286 - accuracy: 0.3711 - val_loss: 3.1051 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 37s 530ms/step - loss: 1.0559 - accuracy: 0.6079 - val_loss: 2.8824 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 39s 535ms/step - loss: 0.8123 - accuracy: 0.7015 - val_loss: 2.7914 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 35s 548ms/step - loss: 0.6016 - accuracy: 0.8021 - val_loss: 2.7655 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 36s 535ms/step - loss: 0.4445 - accuracy: 0.8632 - val_loss: 2.8184 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 35s 527ms/step - loss: 0.3561 - accuracy: 0.8851 - val_loss: 2.8705 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 33s 510ms/step - loss: 0.3017 - accuracy: 0.8930 - val_loss: 2.9406 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 35s 518ms/step - loss: 0.3214 - accuracy: 0.8886 - val_loss: 2.9909 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 35s 535ms/step - loss: 0.3022 - accuracy: 0.9026 - val_loss: 3.0590 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 38s 537ms/step - loss: 0.2639 - accuracy: 0.9102 - val_loss: 3.1188 - val_accuracy: 0.2668\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 29s - loss: 0.6395 - accuracy: 0.8290WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1512s vs `on_train_batch_end` time: 0.5699s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1512s vs `on_train_batch_end` time: 0.5699s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 52s 597ms/step - loss: 0.9309 - accuracy: 0.6907 - val_loss: 2.2783 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 33s 537ms/step - loss: 0.6764 - accuracy: 0.7412 - val_loss: 3.0429 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 38s 557ms/step - loss: 0.4508 - accuracy: 0.8334 - val_loss: 3.5481 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 37s 533ms/step - loss: 0.4408 - accuracy: 0.8369 - val_loss: 3.9086 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 34s 524ms/step - loss: 0.3641 - accuracy: 0.8789 - val_loss: 3.4979 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 35s 513ms/step - loss: 0.2674 - accuracy: 0.9103 - val_loss: 4.1487 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 35s 532ms/step - loss: 0.2970 - accuracy: 0.8931 - val_loss: 4.5642 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 35s 549ms/step - loss: 0.2068 - accuracy: 0.9228 - val_loss: 5.2915 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 36s 525ms/step - loss: 0.2314 - accuracy: 0.9128 - val_loss: 6.0401 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 34s 532ms/step - loss: 0.2583 - accuracy: 0.8997 - val_loss: 5.1285 - val_accuracy: 0.2668\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90.h5\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90.h5\n"
     ]
    }
   ],
   "source": [
    "prune_model(model_path='flowers_models/MobileNetV2_flowers_model.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='flowers_models/MobileNetV2_flowers_model.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='flowers_models/MobileNetV2_flowers_model.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 44s - loss: 0.7728 - accuracy: 0.7121WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2461s vs `on_train_batch_end` time: 0.8278s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2461s vs `on_train_batch_end` time: 0.8278s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 79s 879ms/step - loss: 0.5923 - accuracy: 0.7785 - val_loss: 1.5731 - val_accuracy: 0.4773\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 729ms/step - loss: 0.1828 - accuracy: 0.9404 - val_loss: 1.9018 - val_accuracy: 0.4973\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 42s 752ms/step - loss: 0.0795 - accuracy: 0.9765 - val_loss: 2.0443 - val_accuracy: 0.5481\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 43s 758ms/step - loss: 0.0547 - accuracy: 0.9831 - val_loss: 1.2520 - val_accuracy: 0.6806\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 42s 775ms/step - loss: 0.0809 - accuracy: 0.9727 - val_loss: 1.4513 - val_accuracy: 0.6534\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 46s 737ms/step - loss: 0.0733 - accuracy: 0.9764 - val_loss: 1.3660 - val_accuracy: 0.6770\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 44s 756ms/step - loss: 0.0609 - accuracy: 0.9820 - val_loss: 1.3995 - val_accuracy: 0.6951\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 45s 746ms/step - loss: 0.0725 - accuracy: 0.9733 - val_loss: 1.4192 - val_accuracy: 0.6915\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 41s 747ms/step - loss: 0.0457 - accuracy: 0.9831 - val_loss: 2.4678 - val_accuracy: 0.5481\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 44s 760ms/step - loss: 0.1135 - accuracy: 0.9595 - val_loss: 2.6180 - val_accuracy: 0.5263\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 47s - loss: 0.0770 - accuracy: 0.9759WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2451s vs `on_train_batch_end` time: 0.9283s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2451s vs `on_train_batch_end` time: 0.9283s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 81s 879ms/step - loss: 0.1260 - accuracy: 0.9614 - val_loss: 3.8911 - val_accuracy: 0.4374\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 44s 763ms/step - loss: 0.1186 - accuracy: 0.9572 - val_loss: 3.0033 - val_accuracy: 0.5336\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 45s 761ms/step - loss: 0.1253 - accuracy: 0.9527 - val_loss: 2.6494 - val_accuracy: 0.6062\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 44s 747ms/step - loss: 0.0956 - accuracy: 0.9623 - val_loss: 2.7205 - val_accuracy: 0.5898\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 40s 744ms/step - loss: 0.1782 - accuracy: 0.9386 - val_loss: 3.0062 - val_accuracy: 0.5626\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 42s 750ms/step - loss: 0.1182 - accuracy: 0.9591 - val_loss: 1.9782 - val_accuracy: 0.6134\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 46s 744ms/step - loss: 0.0339 - accuracy: 0.9898 - val_loss: 1.7728 - val_accuracy: 0.6497\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 46s 741ms/step - loss: 0.1140 - accuracy: 0.9600 - val_loss: 1.9941 - val_accuracy: 0.6461\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 48s 763ms/step - loss: 0.0661 - accuracy: 0.9770 - val_loss: 1.5455 - val_accuracy: 0.7114\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 39s 736ms/step - loss: 0.0889 - accuracy: 0.9708 - val_loss: 1.7248 - val_accuracy: 0.6425\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50.h5\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50.h5\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 46s - loss: 1.4212 - accuracy: 0.3840WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2411s vs `on_train_batch_end` time: 0.9132s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2411s vs `on_train_batch_end` time: 0.9132s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 77s 874ms/step - loss: 1.2200 - accuracy: 0.5120 - val_loss: 1.8158 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 750ms/step - loss: 0.8584 - accuracy: 0.6818 - val_loss: 1.8276 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 45s 742ms/step - loss: 0.6356 - accuracy: 0.7946 - val_loss: 1.4092 - val_accuracy: 0.3702\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 41s 734ms/step - loss: 0.4012 - accuracy: 0.8990 - val_loss: 1.4196 - val_accuracy: 0.4828\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 47s 739ms/step - loss: 0.2796 - accuracy: 0.9260 - val_loss: 1.4320 - val_accuracy: 0.5100\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 47s 750ms/step - loss: 0.2219 - accuracy: 0.9456 - val_loss: 1.5949 - val_accuracy: 0.5535\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 41s 732ms/step - loss: 0.1873 - accuracy: 0.9482 - val_loss: 1.0908 - val_accuracy: 0.6443\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 46s 754ms/step - loss: 0.1435 - accuracy: 0.9673 - val_loss: 1.1553 - val_accuracy: 0.6243\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 46s 747ms/step - loss: 0.1250 - accuracy: 0.9644 - val_loss: 1.2107 - val_accuracy: 0.6388\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 43s 744ms/step - loss: 0.1386 - accuracy: 0.9575 - val_loss: 1.3946 - val_accuracy: 0.6207\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 43s - loss: 0.1340 - accuracy: 0.9703WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2416s vs `on_train_batch_end` time: 0.8440s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2416s vs `on_train_batch_end` time: 0.8440s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 79s 835ms/step - loss: 0.2654 - accuracy: 0.9192 - val_loss: 1.9785 - val_accuracy: 0.5789\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 42s 740ms/step - loss: 0.2239 - accuracy: 0.9252 - val_loss: 2.0486 - val_accuracy: 0.5880\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 42s 744ms/step - loss: 0.1714 - accuracy: 0.9323 - val_loss: 2.0495 - val_accuracy: 0.6171\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 45s 737ms/step - loss: 0.2035 - accuracy: 0.9278 - val_loss: 1.8478 - val_accuracy: 0.6207\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 39s 737ms/step - loss: 0.2405 - accuracy: 0.9215 - val_loss: 4.5919 - val_accuracy: 0.4555\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 44s 750ms/step - loss: 0.1622 - accuracy: 0.9456 - val_loss: 1.6805 - val_accuracy: 0.6570\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 46s 759ms/step - loss: 0.1478 - accuracy: 0.9495 - val_loss: 1.4376 - val_accuracy: 0.6915\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 47s 767ms/step - loss: 0.0960 - accuracy: 0.9767 - val_loss: 1.8058 - val_accuracy: 0.6152\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 43s 749ms/step - loss: 0.1011 - accuracy: 0.9665 - val_loss: 1.5275 - val_accuracy: 0.6751\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 44s 766ms/step - loss: 0.1084 - accuracy: 0.9617 - val_loss: 1.7985 - val_accuracy: 0.6461\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75.h5\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75.h5\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 43s - loss: 1.7493 - accuracy: 0.3035WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2475s vs `on_train_batch_end` time: 0.8268s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2475s vs `on_train_batch_end` time: 0.8268s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 76s 867ms/step - loss: 1.6785 - accuracy: 0.2825 - val_loss: 2.8489 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 754ms/step - loss: 1.5950 - accuracy: 0.3413 - val_loss: 2.2904 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 43s 750ms/step - loss: 1.5618 - accuracy: 0.3802 - val_loss: 1.9368 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 45s 737ms/step - loss: 1.5280 - accuracy: 0.4118 - val_loss: 1.7449 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 43s 744ms/step - loss: 1.4901 - accuracy: 0.4577 - val_loss: 1.6661 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 46s 761ms/step - loss: 1.4596 - accuracy: 0.4740 - val_loss: 1.6009 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 46s 731ms/step - loss: 1.4277 - accuracy: 0.4848 - val_loss: 1.5531 - val_accuracy: 0.2904\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 47s 745ms/step - loss: 1.3914 - accuracy: 0.5120 - val_loss: 1.4754 - val_accuracy: 0.3194\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 44s 745ms/step - loss: 1.3570 - accuracy: 0.5270 - val_loss: 1.4338 - val_accuracy: 0.4483\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 40s 749ms/step - loss: 1.3193 - accuracy: 0.5370 - val_loss: 1.3924 - val_accuracy: 0.4174\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 46s - loss: 1.2660 - accuracy: 0.4883WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2521s vs `on_train_batch_end` time: 0.8928s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2521s vs `on_train_batch_end` time: 0.8928s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 81s 895ms/step - loss: 1.1562 - accuracy: 0.5271 - val_loss: 4.1351 - val_accuracy: 0.4864\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 42s 754ms/step - loss: 0.8153 - accuracy: 0.6727 - val_loss: 4.2152 - val_accuracy: 0.4773\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 42s 724ms/step - loss: 0.6883 - accuracy: 0.7243 - val_loss: 1.8514 - val_accuracy: 0.5463\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 46s 727ms/step - loss: 0.5517 - accuracy: 0.7890 - val_loss: 3.2529 - val_accuracy: 0.4356\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 37s 761ms/step - loss: 0.3863 - accuracy: 0.8406 - val_loss: 1.8385 - val_accuracy: 0.6098\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 45s 740ms/step - loss: 0.2801 - accuracy: 0.8962 - val_loss: 3.8564 - val_accuracy: 0.4483\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 40s 748ms/step - loss: 0.2984 - accuracy: 0.8950 - val_loss: 1.7538 - val_accuracy: 0.6279\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 44s 738ms/step - loss: 0.3540 - accuracy: 0.8758 - val_loss: 1.7717 - val_accuracy: 0.5935\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 41s 748ms/step - loss: 0.2356 - accuracy: 0.9221 - val_loss: 1.8617 - val_accuracy: 0.6407\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 47s 754ms/step - loss: 0.2018 - accuracy: 0.9318 - val_loss: 2.2653 - val_accuracy: 0.5917\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90.h5\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90.h5\n"
     ]
    }
   ],
   "source": [
    "prune_model(model_path='flowers_models/EfficentNetB0_flowers_model.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1], \n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='flowers_models/EfficentNetB0_flowers_model.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1], \n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='flowers_models/EfficentNetB0_flowers_model.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1], \n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macenpav/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 20s - loss: 0.6184 - accuracy: 0.8572WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4185s vs `on_train_batch_end` time: 1.2123s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4185s vs `on_train_batch_end` time: 1.2123s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 53s 2s/step - loss: 0.5875 - accuracy: 0.8552 - val_loss: 1.5991 - val_accuracy: 0.5338\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.1781 - accuracy: 0.9296 - val_loss: 4.0393 - val_accuracy: 0.5564\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1089 - accuracy: 0.9697 - val_loss: 4.4042 - val_accuracy: 0.4887\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0475 - accuracy: 0.9837 - val_loss: 3.0142 - val_accuracy: 0.4962\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0338 - accuracy: 0.9895 - val_loss: 4.3552 - val_accuracy: 0.6090\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 2.9429 - val_accuracy: 0.6015\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1067 - accuracy: 0.9626 - val_loss: 1.6338 - val_accuracy: 0.6992\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1558 - accuracy: 0.9435 - val_loss: 2.4729 - val_accuracy: 0.6767\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1061 - accuracy: 0.9647 - val_loss: 2.7181 - val_accuracy: 0.6466\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0464 - accuracy: 0.9879 - val_loss: 2.1116 - val_accuracy: 0.7068\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 23s - loss: 0.0749 - accuracy: 0.9680WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4198s vs `on_train_batch_end` time: 1.6412s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4198s vs `on_train_batch_end` time: 1.6412s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 53s 2s/step - loss: 0.1016 - accuracy: 0.9610 - val_loss: 4.1431 - val_accuracy: 0.6316\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1341 - accuracy: 0.9611 - val_loss: 9.6285 - val_accuracy: 0.4812\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0675 - accuracy: 0.9806 - val_loss: 5.8350 - val_accuracy: 0.5865\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0172 - accuracy: 0.9985 - val_loss: 9.9832 - val_accuracy: 0.5263\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 13.9046 - val_accuracy: 0.3684\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 27.3363 - val_accuracy: 0.3459\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.2814 - accuracy: 0.9215 - val_loss: 12.2386 - val_accuracy: 0.4812\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2250 - accuracy: 0.9111 - val_loss: 6.7590 - val_accuracy: 0.5263\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0976 - accuracy: 0.9604 - val_loss: 8.7028 - val_accuracy: 0.4211\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0823 - accuracy: 0.9741 - val_loss: 8.3122 - val_accuracy: 0.5263\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50.h5\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50.h5\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 24s - loss: 1.6950 - accuracy: 0.5828WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4185s vs `on_train_batch_end` time: 1.6588s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4185s vs `on_train_batch_end` time: 1.6588s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 51s 2s/step - loss: 1.3982 - accuracy: 0.6213 - val_loss: 1.1567 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.3990 - accuracy: 0.8528 - val_loss: 1.1944 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.2310 - accuracy: 0.9306 - val_loss: 1.2994 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1158 - accuracy: 0.9729 - val_loss: 1.5247 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0791 - accuracy: 0.9815 - val_loss: 1.5415 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0591 - accuracy: 0.9862 - val_loss: 1.6809 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0443 - accuracy: 0.9912 - val_loss: 1.8017 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0478 - accuracy: 0.9914 - val_loss: 1.9752 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0633 - accuracy: 0.9869 - val_loss: 2.1066 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0539 - accuracy: 0.9857 - val_loss: 2.4438 - val_accuracy: 0.3308\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 23s - loss: 0.1297 - accuracy: 0.9509WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4109s vs `on_train_batch_end` time: 1.6226s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4109s vs `on_train_batch_end` time: 1.6226s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 53s 2s/step - loss: 0.2393 - accuracy: 0.9108 - val_loss: 2.0910 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.2740 - accuracy: 0.8969 - val_loss: 1.7010 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2203 - accuracy: 0.9197 - val_loss: 2.3330 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1100 - accuracy: 0.9617 - val_loss: 3.7505 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1012 - accuracy: 0.9688 - val_loss: 3.5479 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0494 - accuracy: 0.9869 - val_loss: 3.6504 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0778 - accuracy: 0.9662 - val_loss: 3.7850 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1028 - accuracy: 0.9649 - val_loss: 2.1503 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0995 - accuracy: 0.9558 - val_loss: 3.3137 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0818 - accuracy: 0.9722 - val_loss: 5.2378 - val_accuracy: 0.3308\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75.h5\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75.h5\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 22s - loss: 1.3784 - accuracy: 0.3951WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4096s vs `on_train_batch_end` time: 1.5780s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4096s vs `on_train_batch_end` time: 1.5780s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 52s 2s/step - loss: 1.2064 - accuracy: 0.4685 - val_loss: 1.1073 - val_accuracy: 0.3383\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.6349 - accuracy: 0.7247 - val_loss: 1.1016 - val_accuracy: 0.3383\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.4866 - accuracy: 0.8216 - val_loss: 1.1025 - val_accuracy: 0.3383\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.3388 - accuracy: 0.8949 - val_loss: 1.1033 - val_accuracy: 0.3383\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.2166 - accuracy: 0.9599 - val_loss: 1.1052 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1505 - accuracy: 0.9632 - val_loss: 1.1058 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1373 - accuracy: 0.9618 - val_loss: 1.1053 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0987 - accuracy: 0.9769 - val_loss: 1.1080 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1022 - accuracy: 0.9722 - val_loss: 1.1079 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1393 - accuracy: 0.9514 - val_loss: 1.1191 - val_accuracy: 0.3308\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 23s - loss: 0.4694 - accuracy: 0.8582WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4170s vs `on_train_batch_end` time: 1.6554s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4170s vs `on_train_batch_end` time: 1.6554s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 53s 2s/step - loss: 0.6462 - accuracy: 0.7855 - val_loss: 1.1108 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.5363 - accuracy: 0.7889 - val_loss: 1.1175 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.3077 - accuracy: 0.8795 - val_loss: 1.1525 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.2065 - accuracy: 0.9365 - val_loss: 1.1380 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1625 - accuracy: 0.9390 - val_loss: 1.2735 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0984 - accuracy: 0.9745 - val_loss: 1.2398 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1296 - accuracy: 0.9578 - val_loss: 1.1772 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1500 - accuracy: 0.9437 - val_loss: 1.2622 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.2021 - accuracy: 0.9265 - val_loss: 1.6054 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1258 - accuracy: 0.9557 - val_loss: 1.8445 - val_accuracy: 0.3308\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90.h5\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90.h5\n"
     ]
    }
   ],
   "source": [
    "prune_model(model_path='beans_models/MobileNetV2_beans_model.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='beans_models/MobileNetV2_beans_model.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='beans_models/MobileNetV2_beans_model.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[64,32,32,480] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/prune_low_magnitude_block4c_activation/mul-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_548175]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b55262ad2dee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m prune_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mds_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mds_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mpruning_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRUNING_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a3166338c0d5>\u001b[0m in \u001b[0;36mprune_model\u001b[0;34m(model_path, batch_size, pruning_epochs, ds_train, ds_validation, sparsity)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Fitting data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     model_for_pruning_constant.fit(ds_train,\n\u001b[0m\u001b[1;32m     75\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpruning_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[64,32,32,480] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/prune_low_magnitude_block4c_activation/mul-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_548175]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "prune_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1], \n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1], \n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1], \n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Weight cluster base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 38s 572ms/step - loss: 0.2422 - accuracy: 0.9275 - val_loss: 1.3989 - val_accuracy: 0.7005\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 39s 522ms/step - loss: 0.0117 - accuracy: 0.9978 - val_loss: 1.6330 - val_accuracy: 0.6933\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 32s 539ms/step - loss: 0.0145 - accuracy: 0.9946 - val_loss: 1.7333 - val_accuracy: 0.6733\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 30s 517ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.9644 - val_accuracy: 0.6860\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 40s 531ms/step - loss: 0.0052 - accuracy: 0.9973 - val_loss: 1.5252 - val_accuracy: 0.7042\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 36s 544ms/step - loss: 0.0199 - accuracy: 0.9924 - val_loss: 2.6876 - val_accuracy: 0.6316\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 39s 528ms/step - loss: 0.0790 - accuracy: 0.9706 - val_loss: 1.6436 - val_accuracy: 0.6878\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 37s 547ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 2.0865 - val_accuracy: 0.6661\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 38s 534ms/step - loss: 0.0572 - accuracy: 0.9783 - val_loss: 1.6155 - val_accuracy: 0.5898\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 34s 525ms/step - loss: 0.0809 - accuracy: 0.9719 - val_loss: 1.5698 - val_accuracy: 0.6933\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32.h5\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 42s 529ms/step - loss: 0.2339 - accuracy: 0.9473 - val_loss: 1.5981 - val_accuracy: 0.6806\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 29s 540ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 1.8921 - val_accuracy: 0.6806\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 28s 523ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 2.2294 - val_accuracy: 0.6679\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 33s 543ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 2.0989 - val_accuracy: 0.6987\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 39s 528ms/step - loss: 0.0489 - accuracy: 0.9855 - val_loss: 1.7243 - val_accuracy: 0.5535\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 35s 514ms/step - loss: 0.2753 - accuracy: 0.9059 - val_loss: 1.4084 - val_accuracy: 0.6588\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 36s 535ms/step - loss: 0.0464 - accuracy: 0.9836 - val_loss: 2.0276 - val_accuracy: 0.6534\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 38s 508ms/step - loss: 0.0678 - accuracy: 0.9752 - val_loss: 1.9902 - val_accuracy: 0.6189\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 34s 517ms/step - loss: 0.0417 - accuracy: 0.9824 - val_loss: 1.7872 - val_accuracy: 0.6806\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 32s 534ms/step - loss: 0.0089 - accuracy: 0.9956 - val_loss: 2.0228 - val_accuracy: 0.6987\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models/MobileNetV2_flowers_model.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models/MobileNetV2_flowers_model.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 51s 755ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 1.6021 - val_accuracy: 0.6933\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 41s 739ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 1.8646 - val_accuracy: 0.6897\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 46s 721ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 1.8520 - val_accuracy: 0.6933\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 47s 732ms/step - loss: 7.6542e-04 - accuracy: 0.9999 - val_loss: 1.8964 - val_accuracy: 0.6951\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 43s 697ms/step - loss: 6.3385e-04 - accuracy: 0.9993 - val_loss: 1.9094 - val_accuracy: 0.6951\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 42s 744ms/step - loss: 4.1009e-04 - accuracy: 0.9995 - val_loss: 1.9348 - val_accuracy: 0.6969\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 45s 710ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 1.9459 - val_accuracy: 0.7005\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 42s 721ms/step - loss: 1.6302e-04 - accuracy: 0.9999 - val_loss: 1.9856 - val_accuracy: 0.6987\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 39s 724ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 2.0109 - val_accuracy: 0.6987\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 43s 708ms/step - loss: 5.4054e-04 - accuracy: 0.9994 - val_loss: 2.0203 - val_accuracy: 0.6987\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32.h5\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 50s 741ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 1.6358 - val_accuracy: 0.6806\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 42s 684ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 2.1320 - val_accuracy: 0.6497\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 46s 703ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 2.2033 - val_accuracy: 0.6552\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 43s 707ms/step - loss: 0.0063 - accuracy: 0.9952 - val_loss: 2.1062 - val_accuracy: 0.6788\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 46s 704ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 2.3579 - val_accuracy: 0.6951\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 42s 707ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 2.4234 - val_accuracy: 0.6788\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 37s 709ms/step - loss: 7.0468e-04 - accuracy: 0.9993 - val_loss: 2.3732 - val_accuracy: 0.6842\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 44s 704ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 2.3162 - val_accuracy: 0.6933\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 42s 714ms/step - loss: 4.0908e-04 - accuracy: 0.9997 - val_loss: 2.3146 - val_accuracy: 0.6897\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 43s 695ms/step - loss: 5.2426e-04 - accuracy: 0.9994 - val_loss: 2.2715 - val_accuracy: 0.6897\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models/EfficentNetB0_flowers_model.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models/EfficentNetB0_flowers_model.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 39s 2s/step - loss: 5.9402 - accuracy: 0.5883 - val_loss: 0.8820 - val_accuracy: 0.5489\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.8479 - accuracy: 0.6229 - val_loss: 0.7968 - val_accuracy: 0.6165\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.7125 - accuracy: 0.6890 - val_loss: 0.6677 - val_accuracy: 0.6692\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.6054 - accuracy: 0.7477 - val_loss: 0.6110 - val_accuracy: 0.7068\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.4822 - accuracy: 0.8004 - val_loss: 0.7550 - val_accuracy: 0.6992\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.3038 - accuracy: 0.8860 - val_loss: 0.7577 - val_accuracy: 0.7744\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.1932 - accuracy: 0.9362 - val_loss: 0.8160 - val_accuracy: 0.7368\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.1153 - accuracy: 0.9494 - val_loss: 1.0115 - val_accuracy: 0.7143\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.0775 - accuracy: 0.9730 - val_loss: 0.8756 - val_accuracy: 0.7669\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 1.0083 - val_accuracy: 0.7820\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32.h5\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 40s 2s/step - loss: 4.8585 - accuracy: 0.6726 - val_loss: 1.1376 - val_accuracy: 0.3684\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0085 - accuracy: 0.4581 - val_loss: 0.9780 - val_accuracy: 0.5188\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.8379 - accuracy: 0.5880 - val_loss: 1.0151 - val_accuracy: 0.5263\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.7273 - accuracy: 0.6665 - val_loss: 0.8398 - val_accuracy: 0.6316\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.5775 - accuracy: 0.7492 - val_loss: 0.7873 - val_accuracy: 0.6617\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.4519 - accuracy: 0.7909 - val_loss: 1.2507 - val_accuracy: 0.6090\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.3671 - accuracy: 0.8514 - val_loss: 1.1128 - val_accuracy: 0.6541\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.2490 - accuracy: 0.8996 - val_loss: 0.9292 - val_accuracy: 0.7218\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.1673 - accuracy: 0.9350 - val_loss: 1.0768 - val_accuracy: 0.6692\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.1211 - accuracy: 0.9638 - val_loss: 1.4546 - val_accuracy: 0.6241\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models/MobileNetV2_beans_model.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models/MobileNetV2_beans_model.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[64,32,32,480] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/cluster_block4c_activation/mul-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_746724]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bafeed581077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m weight_cluster_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mds_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mds_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRUNING_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5c99d32a386c>\u001b[0m in \u001b[0;36mweight_cluster_model\u001b[0;34m(model_path, batch_size, epochs, ds_train, ds_validation, number_of_clusters)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Fitting data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     model_for_clustering_kmeans.fit(ds_train,\n\u001b[0m\u001b[1;32m     45\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                               epochs=epochs)\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[64,32,32,480] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/cluster_block4c_activation/mul-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_746724]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. weight cluster prunned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 40s 563ms/step - loss: 3.4468 - accuracy: 0.6025 - val_loss: 1.1391 - val_accuracy: 0.6570\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 31s 530ms/step - loss: 0.1773 - accuracy: 0.9416 - val_loss: 1.4946 - val_accuracy: 0.6860\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 37s 560ms/step - loss: 0.0394 - accuracy: 0.9860 - val_loss: 1.4401 - val_accuracy: 0.7169\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 40s 530ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 1.6013 - val_accuracy: 0.7205\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 36s 535ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 1.6630 - val_accuracy: 0.7114\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 37s 533ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 1.7817 - val_accuracy: 0.7151\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 36s 551ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 1.9477 - val_accuracy: 0.6933\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 39s 539ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 1.8747 - val_accuracy: 0.7078\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 39s 549ms/step - loss: 9.8342e-04 - accuracy: 1.0000 - val_loss: 1.7357 - val_accuracy: 0.7151\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 36s 554ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 1.7358 - val_accuracy: 0.7151\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 36s 550ms/step - loss: 3.8840 - accuracy: 0.5132 - val_loss: 1.0528 - val_accuracy: 0.6207\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 37s 545ms/step - loss: 0.5530 - accuracy: 0.8009 - val_loss: 1.1481 - val_accuracy: 0.6860\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 36s 533ms/step - loss: 0.1340 - accuracy: 0.9475 - val_loss: 1.4633 - val_accuracy: 0.7024\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 39s 528ms/step - loss: 0.0177 - accuracy: 0.9983 - val_loss: 1.3589 - val_accuracy: 0.7132\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 37s 540ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 1.4632 - val_accuracy: 0.7223\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 39s 530ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 1.5491 - val_accuracy: 0.7187\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 36s 532ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 1.5801 - val_accuracy: 0.7187\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 37s 527ms/step - loss: 9.2440e-04 - accuracy: 0.9998 - val_loss: 1.5303 - val_accuracy: 0.7260\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 38s 533ms/step - loss: 7.2376e-04 - accuracy: 0.9999 - val_loss: 1.5530 - val_accuracy: 0.7332\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 30s 542ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 1.5571 - val_accuracy: 0.7205\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 34s 560ms/step - loss: 3.6074 - accuracy: 0.5775 - val_loss: 1.0917 - val_accuracy: 0.6370\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 34s 541ms/step - loss: 0.5100 - accuracy: 0.8079 - val_loss: 1.2421 - val_accuracy: 0.6806\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 35s 553ms/step - loss: 0.0607 - accuracy: 0.9780 - val_loss: 1.3934 - val_accuracy: 0.6969\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 31s 522ms/step - loss: 0.0169 - accuracy: 0.9974 - val_loss: 1.4361 - val_accuracy: 0.7296\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 33s 529ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 1.5807 - val_accuracy: 0.7278\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 38s 543ms/step - loss: 9.5194e-04 - accuracy: 1.0000 - val_loss: 1.6546 - val_accuracy: 0.7296\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 40s 541ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 1.6129 - val_accuracy: 0.7332\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 39s 531ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 1.6154 - val_accuracy: 0.7314\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 30s 532ms/step - loss: 8.1746e-04 - accuracy: 0.9998 - val_loss: 1.8074 - val_accuracy: 0.7169\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 36s 539ms/step - loss: 8.8789e-04 - accuracy: 0.9998 - val_loss: 1.6481 - val_accuracy: 0.7314\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 36s 539ms/step - loss: 3.7807 - accuracy: 0.5037 - val_loss: 1.0383 - val_accuracy: 0.6298\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 39s 535ms/step - loss: 0.5721 - accuracy: 0.7806 - val_loss: 1.1069 - val_accuracy: 0.6770\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 39s 531ms/step - loss: 0.1144 - accuracy: 0.9599 - val_loss: 1.3495 - val_accuracy: 0.7005\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 39s 540ms/step - loss: 0.0248 - accuracy: 0.9954 - val_loss: 1.6829 - val_accuracy: 0.7024\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 38s 529ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 1.7478 - val_accuracy: 0.7005\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 36s 541ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 1.7297 - val_accuracy: 0.7042\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 35s 535ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 1.7907 - val_accuracy: 0.7187\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 32s 531ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 1.7793 - val_accuracy: 0.7205\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 37s 534ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.7623 - val_accuracy: 0.7042\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 31s 533ms/step - loss: 9.2483e-04 - accuracy: 0.9998 - val_loss: 1.7983 - val_accuracy: 0.7060\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 44s 542ms/step - loss: 1.6680 - accuracy: 0.5581 - val_loss: 0.8394 - val_accuracy: 0.7078\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 29s 531ms/step - loss: 0.2244 - accuracy: 0.9278 - val_loss: 1.0915 - val_accuracy: 0.7005\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 39s 524ms/step - loss: 0.1318 - accuracy: 0.9560 - val_loss: 1.5383 - val_accuracy: 0.6860\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 32s 549ms/step - loss: 0.0438 - accuracy: 0.9855 - val_loss: 1.4699 - val_accuracy: 0.7151\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 35s 521ms/step - loss: 0.0577 - accuracy: 0.9802 - val_loss: 1.3685 - val_accuracy: 0.6987\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 38s 509ms/step - loss: 0.0679 - accuracy: 0.9762 - val_loss: 1.6055 - val_accuracy: 0.6842\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 32s 518ms/step - loss: 0.0913 - accuracy: 0.9730 - val_loss: 1.5071 - val_accuracy: 0.7060\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 27s 532ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 1.6767 - val_accuracy: 0.7005\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 39s 525ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 1.7435 - val_accuracy: 0.7042\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 38s 527ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 1.8309 - val_accuracy: 0.6407\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 46s 564ms/step - loss: 1.3436 - accuracy: 0.6323 - val_loss: 0.9331 - val_accuracy: 0.6915\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 39s 516ms/step - loss: 0.1829 - accuracy: 0.9357 - val_loss: 1.0338 - val_accuracy: 0.6951\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 40s 533ms/step - loss: 0.0529 - accuracy: 0.9858 - val_loss: 1.6777 - val_accuracy: 0.6661\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 37s 515ms/step - loss: 0.0792 - accuracy: 0.9711 - val_loss: 1.3216 - val_accuracy: 0.7024\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 38s 514ms/step - loss: 0.0597 - accuracy: 0.9784 - val_loss: 1.4651 - val_accuracy: 0.6987\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 32s 535ms/step - loss: 0.0393 - accuracy: 0.9855 - val_loss: 1.5944 - val_accuracy: 0.6897\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 35s 502ms/step - loss: 0.0385 - accuracy: 0.9866 - val_loss: 1.6307 - val_accuracy: 0.6679\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 32s 500ms/step - loss: 0.1049 - accuracy: 0.9604 - val_loss: 1.5193 - val_accuracy: 0.6878\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 31s 529ms/step - loss: 0.1847 - accuracy: 0.9225 - val_loss: 1.8821 - val_accuracy: 0.6152\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 27s 521ms/step - loss: 0.1283 - accuracy: 0.9534 - val_loss: 1.7915 - val_accuracy: 0.6642\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 43s 539ms/step - loss: 1.3461 - accuracy: 0.6531 - val_loss: 0.9117 - val_accuracy: 0.6806\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 39s 536ms/step - loss: 0.2257 - accuracy: 0.9209 - val_loss: 1.5061 - val_accuracy: 0.6751\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 39s 526ms/step - loss: 0.1282 - accuracy: 0.9555 - val_loss: 1.5870 - val_accuracy: 0.7187\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 34s 549ms/step - loss: 0.0430 - accuracy: 0.9872 - val_loss: 1.7722 - val_accuracy: 0.6987\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 38s 532ms/step - loss: 0.0664 - accuracy: 0.9795 - val_loss: 1.5529 - val_accuracy: 0.7005\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 27s 517ms/step - loss: 0.0569 - accuracy: 0.9774 - val_loss: 1.7572 - val_accuracy: 0.7151\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 40s 538ms/step - loss: 0.0599 - accuracy: 0.9769 - val_loss: 1.6627 - val_accuracy: 0.6788\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 35s 559ms/step - loss: 0.0693 - accuracy: 0.9737 - val_loss: 1.4725 - val_accuracy: 0.6915\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 30s 541ms/step - loss: 0.0317 - accuracy: 0.9892 - val_loss: 1.8351 - val_accuracy: 0.7060\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 30s 554ms/step - loss: 0.0746 - accuracy: 0.9721 - val_loss: 1.8438 - val_accuracy: 0.6461\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 45s 548ms/step - loss: 1.4008 - accuracy: 0.6421 - val_loss: 1.0369 - val_accuracy: 0.6951\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 33s 525ms/step - loss: 0.2066 - accuracy: 0.9295 - val_loss: 1.0783 - val_accuracy: 0.6951\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 35s 539ms/step - loss: 0.1070 - accuracy: 0.9628 - val_loss: 1.4481 - val_accuracy: 0.6733\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 37s 521ms/step - loss: 0.0450 - accuracy: 0.9885 - val_loss: 1.9170 - val_accuracy: 0.6425\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 31s 534ms/step - loss: 0.0735 - accuracy: 0.9730 - val_loss: 1.7052 - val_accuracy: 0.6860\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 39s 533ms/step - loss: 0.0856 - accuracy: 0.9724 - val_loss: 1.4337 - val_accuracy: 0.6897\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 37s 517ms/step - loss: 0.0904 - accuracy: 0.9731 - val_loss: 1.4747 - val_accuracy: 0.6842\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 34s 537ms/step - loss: 0.0396 - accuracy: 0.9897 - val_loss: 1.7350 - val_accuracy: 0.6624\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 37s 537ms/step - loss: 0.0531 - accuracy: 0.9814 - val_loss: 1.6317 - val_accuracy: 0.6751\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 36s 539ms/step - loss: 0.0272 - accuracy: 0.9896 - val_loss: 2.0221 - val_accuracy: 0.6606\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 44s 530ms/step - loss: 2.3170 - accuracy: 0.2446 - val_loss: 1.5701 - val_accuracy: 0.2577\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 38s 529ms/step - loss: 1.4945 - accuracy: 0.3264 - val_loss: 1.2094 - val_accuracy: 0.4809\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 32s 526ms/step - loss: 1.0814 - accuracy: 0.5276 - val_loss: 1.0143 - val_accuracy: 0.6007\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 37s 539ms/step - loss: 0.8931 - accuracy: 0.6649 - val_loss: 0.8992 - val_accuracy: 0.6733\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 40s 550ms/step - loss: 0.7154 - accuracy: 0.7311 - val_loss: 0.9913 - val_accuracy: 0.6642\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 28s 529ms/step - loss: 0.5163 - accuracy: 0.8072 - val_loss: 0.9109 - val_accuracy: 0.6770\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 39s 536ms/step - loss: 0.4150 - accuracy: 0.8403 - val_loss: 0.9682 - val_accuracy: 0.6824\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 35s 531ms/step - loss: 0.3628 - accuracy: 0.8639 - val_loss: 1.0142 - val_accuracy: 0.6733\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 38s 516ms/step - loss: 0.3303 - accuracy: 0.8723 - val_loss: 1.1995 - val_accuracy: 0.6697\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 39s 525ms/step - loss: 0.2586 - accuracy: 0.9032 - val_loss: 1.1239 - val_accuracy: 0.6860\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 38s 549ms/step - loss: 2.3525 - accuracy: 0.2436 - val_loss: 1.4935 - val_accuracy: 0.3085\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 40s 565ms/step - loss: 1.4036 - accuracy: 0.3542 - val_loss: 1.2694 - val_accuracy: 0.4864\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 36s 541ms/step - loss: 1.0584 - accuracy: 0.5784 - val_loss: 0.8362 - val_accuracy: 0.6788\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 38s 526ms/step - loss: 0.7894 - accuracy: 0.6802 - val_loss: 0.9309 - val_accuracy: 0.6279\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 39s 532ms/step - loss: 0.6373 - accuracy: 0.7420 - val_loss: 0.8501 - val_accuracy: 0.7078\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 30s 537ms/step - loss: 0.4910 - accuracy: 0.8214 - val_loss: 0.8350 - val_accuracy: 0.6842\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 38s 555ms/step - loss: 0.3323 - accuracy: 0.8871 - val_loss: 1.0169 - val_accuracy: 0.6842\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 40s 563ms/step - loss: 0.3295 - accuracy: 0.8748 - val_loss: 1.0702 - val_accuracy: 0.6933\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 40s 567ms/step - loss: 0.1546 - accuracy: 0.9446 - val_loss: 1.2152 - val_accuracy: 0.6860\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 39s 551ms/step - loss: 0.1560 - accuracy: 0.9407 - val_loss: 1.2711 - val_accuracy: 0.6878\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 39s 545ms/step - loss: 2.2986 - accuracy: 0.2471 - val_loss: 1.5901 - val_accuracy: 0.3267\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 32s 544ms/step - loss: 1.5723 - accuracy: 0.2800 - val_loss: 1.4042 - val_accuracy: 0.4138\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 29s 534ms/step - loss: 1.2855 - accuracy: 0.4558 - val_loss: 1.0174 - val_accuracy: 0.6134\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 40s 547ms/step - loss: 0.8450 - accuracy: 0.6816 - val_loss: 0.7900 - val_accuracy: 0.6860\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 37s 561ms/step - loss: 0.6957 - accuracy: 0.7244 - val_loss: 1.1188 - val_accuracy: 0.5880\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 40s 547ms/step - loss: 0.6307 - accuracy: 0.7653 - val_loss: 0.8620 - val_accuracy: 0.7187\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 38s 545ms/step - loss: 0.5576 - accuracy: 0.8035 - val_loss: 0.9451 - val_accuracy: 0.7005\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 36s 538ms/step - loss: 0.4072 - accuracy: 0.8466 - val_loss: 0.8894 - val_accuracy: 0.6987\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 36s 545ms/step - loss: 0.3551 - accuracy: 0.8643 - val_loss: 1.0438 - val_accuracy: 0.6751\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 36s 559ms/step - loss: 0.3170 - accuracy: 0.8812 - val_loss: 1.0330 - val_accuracy: 0.6897\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 39s 577ms/step - loss: 2.3900 - accuracy: 0.2337 - val_loss: 1.5754 - val_accuracy: 0.2432\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 40s 535ms/step - loss: 1.5334 - accuracy: 0.3083 - val_loss: 1.1458 - val_accuracy: 0.5172\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 32s 559ms/step - loss: 1.1926 - accuracy: 0.5319 - val_loss: 0.9183 - val_accuracy: 0.6171\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 32s 520ms/step - loss: 0.8123 - accuracy: 0.6874 - val_loss: 0.9012 - val_accuracy: 0.6189\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 40s 536ms/step - loss: 0.6468 - accuracy: 0.7486 - val_loss: 0.8851 - val_accuracy: 0.6515\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 34s 526ms/step - loss: 0.6284 - accuracy: 0.7603 - val_loss: 1.0130 - val_accuracy: 0.6897\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 30s 543ms/step - loss: 0.4276 - accuracy: 0.8452 - val_loss: 0.9481 - val_accuracy: 0.6969\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 40s 537ms/step - loss: 0.2789 - accuracy: 0.8977 - val_loss: 0.8804 - val_accuracy: 0.7151\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 39s 551ms/step - loss: 0.2262 - accuracy: 0.9200 - val_loss: 1.2891 - val_accuracy: 0.6443\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 28s 547ms/step - loss: 0.2453 - accuracy: 0.9153 - val_loss: 1.1283 - val_accuracy: 0.7314\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 51s 734ms/step - loss: 0.0298 - accuracy: 0.9880 - val_loss: 2.2341 - val_accuracy: 0.6770\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 38s 711ms/step - loss: 0.0153 - accuracy: 0.9930 - val_loss: 2.4373 - val_accuracy: 0.6624\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 41s 697ms/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 2.5389 - val_accuracy: 0.6860\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 42s 723ms/step - loss: 8.0469e-04 - accuracy: 0.9998 - val_loss: 2.9173 - val_accuracy: 0.6770\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 43s 734ms/step - loss: 0.0271 - accuracy: 0.9877 - val_loss: 1.9926 - val_accuracy: 0.6751\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 40s 716ms/step - loss: 0.0318 - accuracy: 0.9917 - val_loss: 1.6079 - val_accuracy: 0.7005\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 43s 718ms/step - loss: 0.0030 - accuracy: 0.9982 - val_loss: 1.9472 - val_accuracy: 0.6987\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 35s 717ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 2.1022 - val_accuracy: 0.6897\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 45s 720ms/step - loss: 5.8367e-04 - accuracy: 0.9999 - val_loss: 2.0500 - val_accuracy: 0.6951\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 44s 707ms/step - loss: 7.0665e-04 - accuracy: 0.9999 - val_loss: 2.1793 - val_accuracy: 0.6770\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 52s 732ms/step - loss: 0.0414 - accuracy: 0.9853 - val_loss: 1.4776 - val_accuracy: 0.6951\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 44s 718ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 2.0492 - val_accuracy: 0.6788\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 43s 746ms/step - loss: 0.0105 - accuracy: 0.9948 - val_loss: 1.8969 - val_accuracy: 0.6915\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 40s 720ms/step - loss: 7.1802e-04 - accuracy: 0.9997 - val_loss: 1.9054 - val_accuracy: 0.7096\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 43s 724ms/step - loss: 6.2288e-04 - accuracy: 0.9998 - val_loss: 1.8869 - val_accuracy: 0.7060\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 43s 719ms/step - loss: 4.9915e-04 - accuracy: 0.9998 - val_loss: 1.8641 - val_accuracy: 0.7151\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 46s 743ms/step - loss: 3.5634e-04 - accuracy: 0.9996 - val_loss: 1.8790 - val_accuracy: 0.7132\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 40s 713ms/step - loss: 5.3392e-04 - accuracy: 0.9997 - val_loss: 1.9011 - val_accuracy: 0.7114\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 44s 732ms/step - loss: 7.7207e-04 - accuracy: 0.9996 - val_loss: 1.9244 - val_accuracy: 0.7187\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 39s 718ms/step - loss: 2.5233e-04 - accuracy: 0.9998 - val_loss: 1.9488 - val_accuracy: 0.7132\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 56s 734ms/step - loss: 0.0376 - accuracy: 0.9886 - val_loss: 1.9998 - val_accuracy: 0.6987\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 733ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 2.2093 - val_accuracy: 0.6624\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 40s 714ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 2.2961 - val_accuracy: 0.6878\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 41s 704ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 2.3901 - val_accuracy: 0.6824\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 38s 700ms/step - loss: 0.0150 - accuracy: 0.9944 - val_loss: 1.9411 - val_accuracy: 0.7005\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 42s 724ms/step - loss: 0.0031 - accuracy: 0.9983 - val_loss: 2.2021 - val_accuracy: 0.7060\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 43s 705ms/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 2.0725 - val_accuracy: 0.6860\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 46s 725ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 2.0087 - val_accuracy: 0.6751\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 38s 714ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 1.8953 - val_accuracy: 0.6751\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 44s 712ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 2.1682 - val_accuracy: 0.6987\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 47s 722ms/step - loss: 0.0679 - accuracy: 0.9731 - val_loss: 1.5315 - val_accuracy: 0.7078\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 47s 721ms/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 2.2291 - val_accuracy: 0.6788\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 47s 711ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 1.7689 - val_accuracy: 0.7078\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 48s 732ms/step - loss: 0.0015 - accuracy: 0.9989 - val_loss: 1.8582 - val_accuracy: 0.7096\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 47s 710ms/step - loss: 7.2017e-04 - accuracy: 0.9998 - val_loss: 1.8991 - val_accuracy: 0.7132\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 46s 701ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.8809 - val_accuracy: 0.7187\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 43s 722ms/step - loss: 0.0011 - accuracy: 0.9988 - val_loss: 1.8881 - val_accuracy: 0.7132\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 46s 719ms/step - loss: 7.3284e-04 - accuracy: 0.9996 - val_loss: 1.9068 - val_accuracy: 0.7169\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 36s 714ms/step - loss: 2.0974e-04 - accuracy: 1.0000 - val_loss: 1.9324 - val_accuracy: 0.7187\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 38s 737ms/step - loss: 1.2563e-04 - accuracy: 0.9999 - val_loss: 1.9371 - val_accuracy: 0.7187\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 56s 744ms/step - loss: 0.1740 - accuracy: 0.9414 - val_loss: 1.7632 - val_accuracy: 0.6407\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 38s 705ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 2.1240 - val_accuracy: 0.6661\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 37s 714ms/step - loss: 0.0065 - accuracy: 0.9975 - val_loss: 2.2310 - val_accuracy: 0.6370\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 47s 715ms/step - loss: 0.0258 - accuracy: 0.9901 - val_loss: 2.1459 - val_accuracy: 0.6461\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 46s 724ms/step - loss: 0.0079 - accuracy: 0.9961 - val_loss: 2.2262 - val_accuracy: 0.6152\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 44s 708ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 2.2004 - val_accuracy: 0.6497\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 42s 707ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 2.2734 - val_accuracy: 0.6606\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 36s 712ms/step - loss: 0.0078 - accuracy: 0.9965 - val_loss: 1.9995 - val_accuracy: 0.6751\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 44s 704ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 2.1430 - val_accuracy: 0.6497\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 46s 712ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 2.2380 - val_accuracy: 0.6806\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 55s 737ms/step - loss: 0.1205 - accuracy: 0.9604 - val_loss: 1.9269 - val_accuracy: 0.6370\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 34s 692ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 2.2052 - val_accuracy: 0.6171\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 37s 722ms/step - loss: 0.0934 - accuracy: 0.9820 - val_loss: 1.8624 - val_accuracy: 0.6751\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 47s 709ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 2.2102 - val_accuracy: 0.6642\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 41s 723ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 2.1053 - val_accuracy: 0.6842\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 39s 725ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 2.2324 - val_accuracy: 0.6697\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 46s 726ms/step - loss: 9.1571e-04 - accuracy: 0.9998 - val_loss: 2.2714 - val_accuracy: 0.6715\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 46s 705ms/step - loss: 1.8676e-04 - accuracy: 1.0000 - val_loss: 2.3174 - val_accuracy: 0.6697\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 47s 717ms/step - loss: 0.0013 - accuracy: 0.9986 - val_loss: 2.3414 - val_accuracy: 0.6733\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 47s 713ms/step - loss: 1.8192e-04 - accuracy: 0.9998 - val_loss: 2.3901 - val_accuracy: 0.6733\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 52s 756ms/step - loss: 0.1975 - accuracy: 0.9391 - val_loss: 1.5283 - val_accuracy: 0.6570\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 41s 698ms/step - loss: 0.0081 - accuracy: 0.9969 - val_loss: 1.9614 - val_accuracy: 0.6679\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 46s 694ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 1.8550 - val_accuracy: 0.6715\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 43s 697ms/step - loss: 8.3650e-04 - accuracy: 0.9997 - val_loss: 1.9563 - val_accuracy: 0.6770\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 45s 699ms/step - loss: 6.5315e-04 - accuracy: 0.9998 - val_loss: 2.0094 - val_accuracy: 0.6733\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 42s 703ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 2.0686 - val_accuracy: 0.6697\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 46s 697ms/step - loss: 6.2421e-04 - accuracy: 0.9997 - val_loss: 2.1102 - val_accuracy: 0.6751\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 42s 708ms/step - loss: 5.2083e-04 - accuracy: 0.9996 - val_loss: 2.1341 - val_accuracy: 0.6733\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 42s 703ms/step - loss: 3.2195e-04 - accuracy: 0.9998 - val_loss: 2.1554 - val_accuracy: 0.6679\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 42s 715ms/step - loss: 7.3160e-04 - accuracy: 0.9993 - val_loss: 2.1451 - val_accuracy: 0.6751\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 57s 742ms/step - loss: 0.1822 - accuracy: 0.9467 - val_loss: 1.5955 - val_accuracy: 0.6479\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 43s 716ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 2.0807 - val_accuracy: 0.6860\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 47s 719ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 2.1446 - val_accuracy: 0.6697\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 41s 724ms/step - loss: 8.4011e-04 - accuracy: 0.9999 - val_loss: 2.2147 - val_accuracy: 0.6751\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 39s 717ms/step - loss: 3.9544e-04 - accuracy: 1.0000 - val_loss: 2.2809 - val_accuracy: 0.6715\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 44s 726ms/step - loss: 2.1791e-04 - accuracy: 0.9999 - val_loss: 2.3209 - val_accuracy: 0.6733\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 47s 713ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 2.3672 - val_accuracy: 0.6788\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 46s 701ms/step - loss: 6.7905e-04 - accuracy: 0.9999 - val_loss: 2.3668 - val_accuracy: 0.6733\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 41s 702ms/step - loss: 0.0011 - accuracy: 0.9988 - val_loss: 2.3693 - val_accuracy: 0.6697\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 41s 727ms/step - loss: 2.9811e-04 - accuracy: 0.9999 - val_loss: 2.4031 - val_accuracy: 0.6733\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 54s 750ms/step - loss: 0.1746 - accuracy: 0.9432 - val_loss: 1.7766 - val_accuracy: 0.6534\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 35s 712ms/step - loss: 0.0201 - accuracy: 0.9950 - val_loss: 1.5539 - val_accuracy: 0.6715\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 45s 716ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 2.2180 - val_accuracy: 0.6515\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 47s 723ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 2.2429 - val_accuracy: 0.6443\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 39s 717ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 2.2695 - val_accuracy: 0.6606\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 43s 731ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 1.7107 - val_accuracy: 0.6388\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 42s 706ms/step - loss: 0.0274 - accuracy: 0.9883 - val_loss: 2.0609 - val_accuracy: 0.6334\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 45s 716ms/step - loss: 0.1439 - accuracy: 0.9533 - val_loss: 1.6354 - val_accuracy: 0.6715\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 44s 697ms/step - loss: 0.0326 - accuracy: 0.9910 - val_loss: 2.4881 - val_accuracy: 0.6679\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 44s 698ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 2.7824 - val_accuracy: 0.6443\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 52s 748ms/step - loss: 0.1755 - accuracy: 0.9479 - val_loss: 2.0997 - val_accuracy: 0.6770\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 47s 709ms/step - loss: 0.0384 - accuracy: 0.9886 - val_loss: 1.6296 - val_accuracy: 0.6951\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 46s 705ms/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: 2.1853 - val_accuracy: 0.6588\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 40s 711ms/step - loss: 0.1288 - accuracy: 0.9543 - val_loss: 2.1699 - val_accuracy: 0.6534\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 40s 703ms/step - loss: 0.0109 - accuracy: 0.9984 - val_loss: 2.5558 - val_accuracy: 0.6025\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 36s 718ms/step - loss: 0.0215 - accuracy: 0.9919 - val_loss: 2.4469 - val_accuracy: 0.6624\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 47s 717ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 2.3896 - val_accuracy: 0.6515\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 34s 700ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 2.3691 - val_accuracy: 0.6443\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 38s 679ms/step - loss: 0.0296 - accuracy: 0.9904 - val_loss: 2.0951 - val_accuracy: 0.6443\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 47s 725ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 2.6458 - val_accuracy: 0.6715\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 53s 750ms/step - loss: 0.2053 - accuracy: 0.9462 - val_loss: 2.0548 - val_accuracy: 0.6715\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 698ms/step - loss: 0.0277 - accuracy: 0.9907 - val_loss: 1.5865 - val_accuracy: 0.6606\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 43s 715ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 2.7450 - val_accuracy: 0.6425\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 44s 717ms/step - loss: 0.0325 - accuracy: 0.9870 - val_loss: 1.8178 - val_accuracy: 0.6479\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 38s 712ms/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 2.1500 - val_accuracy: 0.6515\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 40s 704ms/step - loss: 0.0394 - accuracy: 0.9859 - val_loss: 2.2193 - val_accuracy: 0.6661\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 45s 696ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 1.9688 - val_accuracy: 0.6661\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 44s 708ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 2.1340 - val_accuracy: 0.6642\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 40s 719ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 2.4271 - val_accuracy: 0.6697\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 44s 727ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 2.3858 - val_accuracy: 0.6552\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 53s 748ms/step - loss: 0.2112 - accuracy: 0.9366 - val_loss: 2.0624 - val_accuracy: 0.6334\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 45s 717ms/step - loss: 0.0587 - accuracy: 0.9819 - val_loss: 1.8344 - val_accuracy: 0.6588\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 46s 707ms/step - loss: 0.0365 - accuracy: 0.9868 - val_loss: 2.0403 - val_accuracy: 0.6588\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 41s 699ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 1.7086 - val_accuracy: 0.6770\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 44s 722ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 2.0229 - val_accuracy: 0.6606\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 40s 703ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 2.1333 - val_accuracy: 0.6715\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 41s 712ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 1.8224 - val_accuracy: 0.6788\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 46s 718ms/step - loss: 6.4442e-04 - accuracy: 0.9999 - val_loss: 1.9831 - val_accuracy: 0.6788\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 44s 725ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 1.9786 - val_accuracy: 0.6788\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 40s 692ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 1.9032 - val_accuracy: 0.6770\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### beans models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 39s 2s/step - loss: 11.7111 - accuracy: 0.3637 - val_loss: 1.5792 - val_accuracy: 0.3759\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.3878 - accuracy: 0.3591 - val_loss: 1.1111 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.1124 - accuracy: 0.3157 - val_loss: 1.1037 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0996 - accuracy: 0.3424 - val_loss: 1.1018 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.1012 - accuracy: 0.3434 - val_loss: 1.1000 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0995 - accuracy: 0.3327 - val_loss: 1.0995 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.1003 - accuracy: 0.3208 - val_loss: 1.0991 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0995 - accuracy: 0.3367 - val_loss: 1.0990 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0994 - accuracy: 0.3278 - val_loss: 1.0989 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0985 - accuracy: 0.3392 - val_loss: 1.0989 - val_accuracy: 0.3308\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 40s 2s/step - loss: 13.1270 - accuracy: 0.3340 - val_loss: 1.3130 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.2249 - accuracy: 0.3384 - val_loss: 1.1171 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.1131 - accuracy: 0.3263 - val_loss: 1.1005 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0995 - accuracy: 0.3316 - val_loss: 1.0995 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.1000 - accuracy: 0.3272 - val_loss: 1.0993 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0989 - accuracy: 0.3325 - val_loss: 1.0990 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0989 - accuracy: 0.3210 - val_loss: 1.0989 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0998 - accuracy: 0.3162 - val_loss: 1.0988 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0984 - accuracy: 0.3400 - val_loss: 1.0988 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0989 - accuracy: 0.3261 - val_loss: 1.0987 - val_accuracy: 0.3308\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 42s 2s/step - loss: 9.7134 - accuracy: 0.4126 - val_loss: 1.3204 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.2603 - accuracy: 0.3665 - val_loss: 1.1434 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.1240 - accuracy: 0.3378 - val_loss: 1.0923 - val_accuracy: 0.3383\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0903 - accuracy: 0.3556 - val_loss: 1.0808 - val_accuracy: 0.4662\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0868 - accuracy: 0.4335 - val_loss: 1.0679 - val_accuracy: 0.4436\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0726 - accuracy: 0.4048 - val_loss: 1.0485 - val_accuracy: 0.4060\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0668 - accuracy: 0.4020 - val_loss: 1.0235 - val_accuracy: 0.4135\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0417 - accuracy: 0.4120 - val_loss: 1.0026 - val_accuracy: 0.4511\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0110 - accuracy: 0.4740 - val_loss: 0.9633 - val_accuracy: 0.4737\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0005 - accuracy: 0.4816 - val_loss: 0.9280 - val_accuracy: 0.5188\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 39s 2s/step - loss: 10.5365 - accuracy: 0.4055 - val_loss: 1.3383 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.2495 - accuracy: 0.3316 - val_loss: 1.1165 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.1069 - accuracy: 0.3412 - val_loss: 1.1029 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.1001 - accuracy: 0.3407 - val_loss: 1.1013 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.1010 - accuracy: 0.3272 - val_loss: 1.1002 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0985 - accuracy: 0.3362 - val_loss: 1.0992 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0988 - accuracy: 0.3427 - val_loss: 1.0986 - val_accuracy: 0.3383\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0988 - accuracy: 0.3294 - val_loss: 1.0985 - val_accuracy: 0.3383\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0987 - accuracy: 0.3378 - val_loss: 1.0986 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0992 - accuracy: 0.3088 - val_loss: 1.0985 - val_accuracy: 0.3534\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 39s 2s/step - loss: 4.2068 - accuracy: 0.3074 - val_loss: 1.0969 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0968 - accuracy: 0.3527 - val_loss: 1.0959 - val_accuracy: 0.4060\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0971 - accuracy: 0.3674 - val_loss: 1.0902 - val_accuracy: 0.3459\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 1.0866 - accuracy: 0.3838 - val_loss: 1.0625 - val_accuracy: 0.3835\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0599 - accuracy: 0.4243 - val_loss: 1.0497 - val_accuracy: 0.4060\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 1.0665 - accuracy: 0.3822 - val_loss: 1.0255 - val_accuracy: 0.5038\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0169 - accuracy: 0.4973 - val_loss: 1.0379 - val_accuracy: 0.4812\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.9639 - accuracy: 0.5113 - val_loss: 0.9807 - val_accuracy: 0.5414\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.9249 - accuracy: 0.5794 - val_loss: 1.0122 - val_accuracy: 0.4737\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.9896 - accuracy: 0.5257 - val_loss: 0.8765 - val_accuracy: 0.6241\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 41s 2s/step - loss: 4.8890 - accuracy: 0.3156 - val_loss: 1.0974 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0929 - accuracy: 0.3459 - val_loss: 1.0740 - val_accuracy: 0.4436\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0822 - accuracy: 0.3996 - val_loss: 1.0553 - val_accuracy: 0.4211\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0558 - accuracy: 0.4298 - val_loss: 1.0318 - val_accuracy: 0.4361\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0515 - accuracy: 0.3928 - val_loss: 0.9636 - val_accuracy: 0.4962\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0084 - accuracy: 0.4803 - val_loss: 1.0251 - val_accuracy: 0.5113\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0326 - accuracy: 0.4889 - val_loss: 1.0038 - val_accuracy: 0.4887\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0081 - accuracy: 0.4861 - val_loss: 0.9825 - val_accuracy: 0.4586\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.9493 - accuracy: 0.5207 - val_loss: 0.7987 - val_accuracy: 0.6241\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.7958 - accuracy: 0.6243 - val_loss: 0.7369 - val_accuracy: 0.6767\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 43s 2s/step - loss: 3.9838 - accuracy: 0.3164 - val_loss: 1.0993 - val_accuracy: 0.3083\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.1014 - accuracy: 0.3340 - val_loss: 1.0987 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0983 - accuracy: 0.3324 - val_loss: 1.0970 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0970 - accuracy: 0.3354 - val_loss: 1.0951 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0949 - accuracy: 0.3456 - val_loss: 1.0886 - val_accuracy: 0.3609\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0867 - accuracy: 0.3453 - val_loss: 1.0589 - val_accuracy: 0.4211\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0641 - accuracy: 0.4090 - val_loss: 1.0189 - val_accuracy: 0.4511\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0074 - accuracy: 0.5023 - val_loss: 0.9590 - val_accuracy: 0.5263\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.9611 - accuracy: 0.5298 - val_loss: 0.9142 - val_accuracy: 0.5639\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.8858 - accuracy: 0.5798 - val_loss: 1.2021 - val_accuracy: 0.4586\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 39s 2s/step - loss: 4.7372 - accuracy: 0.3109 - val_loss: 1.1014 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0983 - accuracy: 0.3487 - val_loss: 1.0955 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0936 - accuracy: 0.3760 - val_loss: 1.0758 - val_accuracy: 0.4211\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0755 - accuracy: 0.4063 - val_loss: 1.0431 - val_accuracy: 0.4361\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0332 - accuracy: 0.4540 - val_loss: 0.9800 - val_accuracy: 0.4586\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.9570 - accuracy: 0.4745 - val_loss: 0.9273 - val_accuracy: 0.5338\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.9452 - accuracy: 0.5101 - val_loss: 0.8666 - val_accuracy: 0.5338\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.8376 - accuracy: 0.5508 - val_loss: 0.7679 - val_accuracy: 0.5789\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.7800 - accuracy: 0.5932 - val_loss: 0.6810 - val_accuracy: 0.6692\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.6901 - accuracy: 0.7000 - val_loss: 0.6767 - val_accuracy: 0.6692\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 40s 2s/step - loss: 1.2143 - accuracy: 0.3291 - val_loss: 1.1001 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0959 - accuracy: 0.3395 - val_loss: 1.0986 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0987 - accuracy: 0.3128 - val_loss: 1.0986 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0984 - accuracy: 0.3608 - val_loss: 1.0988 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0982 - accuracy: 0.3495 - val_loss: 1.0988 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0987 - accuracy: 0.3319 - val_loss: 1.0987 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0984 - accuracy: 0.3446 - val_loss: 1.0987 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0992 - accuracy: 0.3124 - val_loss: 1.0987 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0985 - accuracy: 0.3396 - val_loss: 1.0987 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0990 - accuracy: 0.3161 - val_loss: 1.0987 - val_accuracy: 0.3308\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 40s 2s/step - loss: 1.2462 - accuracy: 0.3455 - val_loss: 1.0970 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0911 - accuracy: 0.3835 - val_loss: 1.1015 - val_accuracy: 0.3383\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.1050 - accuracy: 0.3287 - val_loss: 1.0986 - val_accuracy: 0.3383\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0992 - accuracy: 0.3292 - val_loss: 1.0986 - val_accuracy: 0.3383\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0984 - accuracy: 0.3452 - val_loss: 1.0986 - val_accuracy: 0.3383\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0988 - accuracy: 0.3412 - val_loss: 1.0986 - val_accuracy: 0.3383\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0985 - accuracy: 0.3448 - val_loss: 1.0986 - val_accuracy: 0.3383\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0984 - accuracy: 0.3461 - val_loss: 1.0986 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0985 - accuracy: 0.3397 - val_loss: 1.0986 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 1.0986 - accuracy: 0.3265 - val_loss: 1.0986 - val_accuracy: 0.3308\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 42s 2s/step - loss: 1.2279 - accuracy: 0.3469 - val_loss: 1.1016 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.1000 - accuracy: 0.3353 - val_loss: 1.0985 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0987 - accuracy: 0.3228 - val_loss: 1.0977 - val_accuracy: 0.3609\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0930 - accuracy: 0.4115 - val_loss: 1.0990 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 36s 2s/step - loss: 1.1000 - accuracy: 0.3273 - val_loss: 1.0991 - val_accuracy: 0.3383\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 36s 2s/step - loss: 1.0988 - accuracy: 0.3444 - val_loss: 1.0986 - val_accuracy: 0.3383\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 36s 2s/step - loss: 1.0986 - accuracy: 0.3289 - val_loss: 1.0988 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0988 - accuracy: 0.3318 - val_loss: 1.0987 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0984 - accuracy: 0.3438 - val_loss: 1.0987 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 36s 2s/step - loss: 1.0989 - accuracy: 0.3231 - val_loss: 1.0987 - val_accuracy: 0.3308\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus32.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 41s 2s/step - loss: 1.2877 - accuracy: 0.3407 - val_loss: 1.1005 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0995 - accuracy: 0.3174 - val_loss: 1.0986 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0989 - accuracy: 0.2977 - val_loss: 1.0987 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 36s 2s/step - loss: 1.0986 - accuracy: 0.3357 - val_loss: 1.0987 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0986 - accuracy: 0.3367 - val_loss: 1.0986 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0987 - accuracy: 0.3238 - val_loss: 1.0986 - val_accuracy: 0.3383\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 36s 2s/step - loss: 1.0987 - accuracy: 0.3313 - val_loss: 1.0986 - val_accuracy: 0.3383\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0985 - accuracy: 0.3486 - val_loss: 1.0986 - val_accuracy: 0.3383\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0987 - accuracy: 0.3268 - val_loss: 1.0985 - val_accuracy: 0.3383\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0987 - accuracy: 0.3264 - val_loss: 1.0985 - val_accuracy: 0.3383\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity50.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-93aaa5aa4025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity50.h5', \n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mds_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mds_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRUNING_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5c99d32a386c>\u001b[0m in \u001b[0;36mweight_cluster_model\u001b[0;34m(model_path, batch_size, epochs, ds_train, ds_validation, number_of_clusters)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity50.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay50.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6372cc77c289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay50.h5', \n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mds_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mds_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRUNING_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5c99d32a386c>\u001b[0m in \u001b[0;36mweight_cluster_model\u001b[0;34m(model_path, batch_size, epochs, ds_train, ds_validation, number_of_clusters)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay50.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity75.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-cb4ac11bb5a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity75.h5', \n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mds_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mds_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRUNING_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5c99d32a386c>\u001b[0m in \u001b[0;36mweight_cluster_model\u001b[0;34m(model_path, batch_size, epochs, ds_train, ds_validation, number_of_clusters)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity75.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay75.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-789f54122569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay75.h5', \n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mds_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mds_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRUNING_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5c99d32a386c>\u001b[0m in \u001b[0;36mweight_cluster_model\u001b[0;34m(model_path, batch_size, epochs, ds_train, ds_validation, number_of_clusters)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay75.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity90.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-720c3a1a9659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity90.h5', \n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mds_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mds_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRUNING_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5c99d32a386c>\u001b[0m in \u001b[0;36mweight_cluster_model\u001b[0;34m(model_path, batch_size, epochs, ds_train, ds_validation, number_of_clusters)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity90.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay90.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c787facf1320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay90.h5', \n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mds_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mds_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRUNING_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5c99d32a386c>\u001b[0m in \u001b[0;36mweight_cluster_model\u001b[0;34m(model_path, batch_size, epochs, ds_train, ds_validation, number_of_clusters)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay90.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all models paths\n",
    "model_paths = []\n",
    "import os\n",
    "for file in os.listdir(\"beans_models/\"):\n",
    "    if file.endswith(\".h5\"):\n",
    "        model_paths.append(str(os.path.join(\"beans_models/\", file)))\n",
    "for file in os.listdir(\"beans_models_optimized/\"):\n",
    "    if file.endswith(\".h5\"):\n",
    "        model_paths.append(str(os.path.join(\"beans_models_optimized/\", file)))\n",
    "for file in os.listdir(\"flowers_models/\"):\n",
    "    if file.endswith(\".h5\"):\n",
    "        model_paths.append(str(os.path.join(\"flowers_models/\", file)))\n",
    "for file in os.listdir(\"flowers_models_optimized/\"):\n",
    "    if file.endswith(\".h5\"):\n",
    "        model_paths.append(str(os.path.join(\"flowers_models_optimized/\", file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beans_models/EfficentNetB0_beans_model.h5',\n",
       " 'beans_models/MobileNetV2_beans_model.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus32.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus32.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus128.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus128.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus32.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus128.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus32.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus32.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus128.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus32.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus128.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus128.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50.h5',\n",
       " 'flowers_models/EfficentNetB0_flowers_model.h5',\n",
       " 'flowers_models/MobileNetV2_flowers_model.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus128.h5']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpn4ftvqq3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpn4ftvqq3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16044956 Bytes) saved to: beans_models_optimized/EfficentNetB0_beans_model.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpkzgwetic/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkzgwetic/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4789504 Bytes) saved to: beans_models_optimized/EfficentNetB0_beans_model_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp3j3k4_nk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3j3k4_nk/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5160800 Bytes) saved to: beans_models_optimized/EfficentNetB0_beans_model_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpt4wly5be/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpt4wly5be/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpg7w82_gf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpg7w82_gf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8096720 Bytes) saved to: beans_models_optimized/EfficentNetB0_beans_model_float16_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpz76c1i1b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz76c1i1b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpzjl2_6bd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzjl2_6bd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpdb4v474u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdb4v474u/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpjben00wh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjben00wh/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpz9f9uv0w/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz9f9uv0w/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0hn_66hp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0hn_66hp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp3y8y37i4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3y8y37i4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpmlvoh4ef/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmlvoh4ef/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpl1e3b0so/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpl1e3b0so/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpk0bungmq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpk0bungmq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbzdp3yx_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbzdp3yx_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpb4jbv7kc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpb4jbv7kc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpotekg5yp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpotekg5yp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpgh8r_9a9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgh8r_9a9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpijhmwpy9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpijhmwpy9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpx5u4m0kb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpx5u4m0kb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpiatl0rnh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiatl0rnh/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpw73u9yob/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw73u9yob/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpxhvb3gk5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxhvb3gk5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp3cx1aw5z/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3cx1aw5z/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5lfloglo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5lfloglo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp6gf85mx5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6gf85mx5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpusgvmwan/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpusgvmwan/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp2ayr_naq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2ayr_naq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmplp969t24/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplp969t24/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqtq_9d1g/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqtq_9d1g/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpveqvysmu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpveqvysmu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpp1go4ylt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp1go4ylt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpoedflgby/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpoedflgby/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7250i7zg/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7250i7zg/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp77aoud5z/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp77aoud5z/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpibpoosog/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpibpoosog/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpukf5ny2c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpukf5ny2c/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmplqtepmcn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplqtepmcn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpdwcfknxl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdwcfknxl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpczgojx06/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpczgojx06/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp160ykbdr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp160ykbdr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpeuv1zehq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpeuv1zehq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmppe0d1plx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppe0d1plx/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpnjmh9327/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnjmh9327/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpv6qjb1l0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpv6qjb1l0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpxhvwntba/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxhvwntba/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp1dmwsgoo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1dmwsgoo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpnhu2bjud/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnhu2bjud/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpp0z1x1_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp0z1x1_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpep3cfwdc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpep3cfwdc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpnne82czz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnne82czz/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp5oo3kia9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5oo3kia9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp9x26fh_w/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9x26fh_w/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp574xmfdl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp574xmfdl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7blg1cij/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7blg1cij/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpwmbut7d6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwmbut7d6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpvsldji18/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvsldji18/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4m3ld2ux/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4m3ld2ux/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpxonyczft/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxonyczft/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5weyfq67/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5weyfq67/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmptwoqt76y/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptwoqt76y/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpocgmqnba/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpocgmqnba/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpe6gr6be2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe6gr6be2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmphcm1gelw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphcm1gelw/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplzzvej2k/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplzzvej2k/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpzdln7v57/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzdln7v57/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7nyxlywg/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7nyxlywg/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpwze7duyn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwze7duyn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_j4usf0a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_j4usf0a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpggy6zndc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpggy6zndc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpj06y_ybj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpj06y_ybj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpto8h6yfd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpto8h6yfd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpfxqujn_a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfxqujn_a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpyd_fg9bc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyd_fg9bc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3mor9sy4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3mor9sy4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7v2_infs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7v2_infs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp707oyerc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp707oyerc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpd5m7jz33/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd5m7jz33/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpi1o9cgs7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpi1o9cgs7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq0en_avu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq0en_avu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp6lpts3gt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6lpts3gt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_t70hgmt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_t70hgmt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpbnfaegbf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbnfaegbf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpvubnzd4w/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvubnzd4w/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpaq20yt93/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpaq20yt93/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpgxaphuv1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgxaphuv1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp0xx_cn8t/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0xx_cn8t/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp8vd2_isd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8vd2_isd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpmak2ghzi/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmak2ghzi/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpshu6p6f0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpshu6p6f0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpzsgz61u6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzsgz61u6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp0wn9703i/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0wn9703i/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpayxokd7a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpayxokd7a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpmakfxfe3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmakfxfe3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjmo_q1jc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjmo_q1jc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpb8l1xjdw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpb8l1xjdw/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpvum5h855/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvum5h855/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpy7i3nktw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpy7i3nktw/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpqgmyxgpd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqgmyxgpd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpv66dkbxj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpv66dkbxj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmptjq6cao3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptjq6cao3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpxk2zoyuf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxk2zoyuf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpampn93jk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpampn93jk/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpijtzvj4o/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpijtzvj4o/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphyxh__1b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphyxh__1b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpk8uj8bk0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpk8uj8bk0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpyiokp4ba/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyiokp4ba/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpveo6x331/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpveo6x331/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4sp_i7ml/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4sp_i7ml/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_float16_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4eofxa2n/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4eofxa2n/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpjnjlnj54/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjnjlnj54/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp5tgyamyu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5tgyamyu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp2r74wnpv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2r74wnpv/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp0744pmii/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0744pmii/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_float16_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpftqo7rqt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpftqo7rqt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp20zoyb75/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp20zoyb75/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp66yvsvm3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp66yvsvm3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpjc3a3rng/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjc3a3rng/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp0xamgm9s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0xamgm9s/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxp9zujzb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxp9zujzb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpq53ybq2y/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq53ybq2y/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpqbn4t3my/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqbn4t3my/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpwwg9t719/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwwg9t719/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp61mpkirf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp61mpkirf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpu4dc6rfi/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpu4dc6rfi/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpav9vwkzh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpav9vwkzh/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpbs0gbui4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbs0gbui4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp51hhshyw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp51hhshyw/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp57xe4ndv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp57xe4ndv/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfzcw36_i/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfzcw36_i/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7ktub_t9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7ktub_t9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp1g7h7rwt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1g7h7rwt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpdzlcylkd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdzlcylkd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_5fuh124/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_5fuh124/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3r3v92hs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3r3v92hs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpmmjs8feh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmmjs8feh/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpzhc9hae0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzhc9hae0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp8de2be8_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8de2be8_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpdi0x33oh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdi0x33oh/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1pkwilt3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1pkwilt3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpco_fx5xy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpco_fx5xy/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_aqt9i7b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_aqt9i7b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpiw3bf7_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiw3bf7_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpj77wylqu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpj77wylqu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp39v92uq5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp39v92uq5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp89dc1ibv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp89dc1ibv/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpqgk22n0z/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqgk22n0z/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpd3snjp5g/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd3snjp5g/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmphkmciufo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphkmciufo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpntr53pch/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpntr53pch/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpulxcvi0l/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpulxcvi0l/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpukr7622u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpukr7622u/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmphdud_9fd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphdud_9fd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp3ymoajdk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3ymoajdk/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbea0itnr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbea0itnr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp3vq7q50v/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3vq7q50v/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpg123qv8g/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpg123qv8g/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp5vwipt0p/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5vwipt0p/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpxc75vy1a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxc75vy1a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp09618bzo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp09618bzo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp2e28gmp1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2e28gmp1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp1xz0onj3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1xz0onj3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp6olqqij2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6olqqij2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpmk5aa0je/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmk5aa0je/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnqty6s2f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnqty6s2f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpvjgvmhda/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvjgvmhda/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpr4jl2m3m/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpr4jl2m3m/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7x6vo464/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7x6vo464/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp6cn5opd_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6cn5opd_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpf198gazm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpf198gazm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpf8zvxq7s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpf8zvxq7s/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpj7qqaare/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpj7qqaare/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp5rz2i7w6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5rz2i7w6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_gptddjp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_gptddjp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmparbg25_k/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmparbg25_k/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpongce_c5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpongce_c5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp45k6c_ok/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp45k6c_ok/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpyuuaqp4l/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyuuaqp4l/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp9y9dp6nl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9y9dp6nl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiwifqvnh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiwifqvnh/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpi80s61ls/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpi80s61ls/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7pjmqtrf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7pjmqtrf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7dgwths3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7dgwths3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpk6s43laz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpk6s43laz/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpr3yyn642/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpr3yyn642/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4punimnj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4punimnj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpxoy00isp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxoy00isp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp1yj09x0c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1yj09x0c/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp29qa9ca5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp29qa9ca5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe6gwhqkj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe6gwhqkj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpylkx8oa8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpylkx8oa8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp88h8tflb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp88h8tflb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpqtro07ev/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqtro07ev/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpm3vvq96s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpm3vvq96s/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz5c23xsn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz5c23xsn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp1votkwqg/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1votkwqg/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpsxarkskp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsxarkskp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmppuzqdyde/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppuzqdyde/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpabho2k1c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpabho2k1c/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp298a_2w4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp298a_2w4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpafruhj7g/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpafruhj7g/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpd2d0yxny/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd2d0yxny/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpna8be11z/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpna8be11z/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_8_icaq6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_8_icaq6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfxi4wkm1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfxi4wkm1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpq69qis5a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq69qis5a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpe_sydoyc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe_sydoyc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp65yblera/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp65yblera/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpuvy5xpz9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpuvy5xpz9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzyxa9lr5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzyxa9lr5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp9b_ri6c6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9b_ri6c6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4zcsuc9s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4zcsuc9s/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmptrcbf1ku/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptrcbf1ku/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpo3pxsh7h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpo3pxsh7h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7scngg5j/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7scngg5j/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp3u905j9k/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3u905j9k/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpaju6jpf0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpaju6jpf0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmplntj9hgv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplntj9hgv/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpux_pufo4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpux_pufo4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpt43_ptf_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpt43_ptf_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp11usfzqi/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp11usfzqi/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpgym8i5ce/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgym8i5ce/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpedg71yne/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpedg71yne/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpug_sn8ex/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpug_sn8ex/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpk411pxap/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpk411pxap/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpgw0gduv7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgw0gduv7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpz9r65dg5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz9r65dg5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpz3ni4mz4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz3ni4mz4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpxrodk_s_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxrodk_s_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdtx87eca/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdtx87eca/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpco65yvrk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpco65yvrk/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpiu7vi9ep/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiu7vi9ep/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp67qfzsl1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp67qfzsl1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmplzzm3oj3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplzzm3oj3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2ig86e0a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2ig86e0a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpgikobnw9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgikobnw9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp6u4_8lbr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6u4_8lbr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmptrylj0_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptrylj0_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp18ypxg5d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp18ypxg5d/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9e_mocjx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9e_mocjx/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpy6f3iums/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpy6f3iums/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpqg61ru03/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqg61ru03/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpjx7j5nn4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjx7j5nn4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpnv4mqp6t/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnv4mqp6t/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpu7rpi7h8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpu7rpi7h8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4f5knjmw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4f5knjmw/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpcafm4i3_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcafm4i3_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmptwb3m0yb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptwb3m0yb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpegi4m0u7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpegi4m0u7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjg8ohhql/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjg8ohhql/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpz4rhw_7n/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz4rhw_7n/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpyhjnjogh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyhjnjogh/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmprstxx097/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprstxx097/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp9qc8jcq6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9qc8jcq6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0d4f_cm1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0d4f_cm1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpzv0uc62h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzv0uc62h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpmbwrzr9k/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmbwrzr9k/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp37uyp7d4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp37uyp7d4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpabm04b9z/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpabm04b9z/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3xvk2354/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3xvk2354/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp1gr9cbaz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1gr9cbaz/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpg3u2rj_q/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpg3u2rj_q/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmprax0ggpf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprax0ggpf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpame1muki/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpame1muki/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptlz1h818/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptlz1h818/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmptgnyj5tr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptgnyj5tr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpw5tx6xv4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw5tx6xv4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpkv3ulubj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkv3ulubj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpcr2tuqn0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcr2tuqn0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7080l_1b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7080l_1b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp64p4l1dc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp64p4l1dc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpbcscxp1q/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbcscxp1q/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpb2c49bif/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpb2c49bif/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp6p8_ab8n/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6p8_ab8n/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnq3_rm8u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnq3_rm8u/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp343ptamf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp343ptamf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpie5ozg_h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpie5ozg_h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmprllc8gdd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprllc8gdd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmplukvi3uq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplukvi3uq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6x1gsyjs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6x1gsyjs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpkl39bn5a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkl39bn5a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpwvzyryuc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwvzyryuc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp8qdybpq6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8qdybpq6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp1itlaybq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1itlaybq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpy1w98aj6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpy1w98aj6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpwdhgwwz3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwdhgwwz3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpqwgdb3g4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqwgdb3g4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpaax2_s17/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpaax2_s17/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpvzthfbw9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvzthfbw9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpafljs7md/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpafljs7md/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmprbkz19a_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprbkz19a_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpxcxbmqky/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxcxbmqky/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpd66aoo9k/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd66aoo9k/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp2t9kvbr3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2t9kvbr3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpb2d1sg06/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpb2d1sg06/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpjri4ucqm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjri4ucqm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpgkgsk7hk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgkgsk7hk/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp6yn7wy5m/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6yn7wy5m/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpcgjeo_nu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcgjeo_nu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw5nkx7jf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw5nkx7jf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpb2k3twe8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpb2k3twe8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4_gtrlpg/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4_gtrlpg/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpsmf_jc_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsmf_jc_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpdkgdx0pl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdkgdx0pl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpadv07bj6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpadv07bj6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp83yoaqy3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp83yoaqy3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmppk5enzze/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppk5enzze/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpkb677hxt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkb677hxt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpg9qnrrhs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpg9qnrrhs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp68o_kegm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp68o_kegm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpx5y791h6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpx5y791h6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmps454skb3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmps454skb3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpumm5axzk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpumm5axzk/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4y2f_3tk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4y2f_3tk/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmps56ku1gn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmps56ku1gn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmplcg3h_a8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplcg3h_a8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4wq4q16s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4wq4q16s/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpboiylcqw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpboiylcqw/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpms5ff05y/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpms5ff05y/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_KMeansPlusPlus128_float16_quantization.tflite\n"
     ]
    }
   ],
   "source": [
    "for model_path in model_paths:\n",
    "    if \"flowers\" in model_path:\n",
    "        model_quantization(model_path=model_path, ds=flowers_datasets[0])\n",
    "    if \"beans\" in model_path:\n",
    "        model_quantization(model_path=model_path, ds=beans_datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
