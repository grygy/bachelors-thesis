{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from os import path\n",
    "import pathlib\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the images to [0, 1]\n",
    "def normalize(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "def random_crop(image):\n",
    "    cropped_image = tf.image.random_crop(\n",
    "        image, size=[256, 256, 3])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def random_jitter(image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    image = random_crop(image)\n",
    "\n",
    "    # random mirroring\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def preprocess_flowers_train(image, label):\n",
    "    image = random_jitter(image)\n",
    "    return image, label\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "def preprocess_flowers(image, label):\n",
    "    image = tf.image.resize(image, [256, 256],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return image, label\n",
    "\n",
    "def load_flowers_dataset():  \n",
    "    (ds_train, ds_validation, ds_test), ds_info = tfds.load(name=\"tf_flowers\", \n",
    "                                             with_info=True,\n",
    "                                             split=['train[:70%]', 'train[70%:85%]', 'train[85%:]'],  #70/15/15 split\n",
    "                                             as_supervised=True)\n",
    "\n",
    "    ds_train = ds_train.map(normalize)    \n",
    "    ds_train = ds_train.map(preprocess_flowers)\n",
    "    ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "    \n",
    "    ds_validation = ds_validation.map(normalize)\n",
    "    ds_validation = ds_validation.map(preprocess_flowers)\n",
    "    \n",
    "    ds_test = ds_test.map(normalize)\n",
    "    ds_test = ds_test.map(preprocess_flowers)\n",
    "    \n",
    "    return ds_train, ds_validation, ds_test\n",
    "\n",
    "def load_beans_datasets():\n",
    "    (ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
    "        'beans',\n",
    "        split=['train', 'validation', 'test'],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "    \n",
    "    ds_train = ds_train.map(normalize)\n",
    "    ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "    \n",
    "    ds_validation = ds_validation.map(normalize)\n",
    "    \n",
    "    ds_test = ds_test.map(normalize)\n",
    "    \n",
    "    return ds_train, ds_validation, ds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization after training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization after training\n",
    "\n",
    "1. Dynamic range quantization\n",
    "2. Full integer quantization\n",
    "3. Float16 quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dynamic range quantization\n",
    "\n",
    "Only the weights are converted from float to 8 bit int. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Full integer quantization\n",
    "\n",
    "Weights and activation outputs are quantizated. Good for microcontrolers and TPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_quantization(model_path, ds):\n",
    "    # check if model was already in optimization folder\n",
    "    if (len(model_path.split('/')[0].split('_')) == 3):\n",
    "        optimized_dir = pathlib.Path(model_path.split('/')[0] + '/')\n",
    "    else:\n",
    "        optimized_dir = pathlib.Path(model_path.split('/')[0] + '_optimized/')\n",
    "    model_name = model_path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    # save converted tflite model\n",
    "    tf_model_path = optimized_dir/(model_name + '.tflite')\n",
    "    size = tf_model_path.write_bytes(tflite_model)\n",
    "    print('Converted TFLite model ('+ str(size) +' Bytes) saved to: ' + str(tf_model_path))\n",
    "    \n",
    "    # 1. optimize model using dynamic range quantization\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model_quant = converter.convert()\n",
    "    \n",
    "    tf_quant_model_path = optimized_dir/(model_name + '_dynamic_rage_quantization.tflite')\n",
    "    size = tf_quant_model_path.write_bytes(tflite_model_quant)\n",
    "    print('Dynamic range quantizatized TFLite model ('+ str(size) +' Bytes) saved to: ' + str(tf_quant_model_path))\n",
    "    \n",
    "    # 2. Full integer quantization\n",
    "    def representative_data_gen():\n",
    "        for input_value, _ in ds.batch(1).take(100):\n",
    "            # Model has only one input so each data point has one element.\n",
    "            yield [input_value]\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "\n",
    "    tflite_model_quant = converter.convert()\n",
    "    tf_quant_model_path = optimized_dir/(model_name + '_full_integer_quantization.tflite')\n",
    "    size = tf_quant_model_path.write_bytes(tflite_model_quant)\n",
    "    print('Full integer quantizatized TFLite model ('+ str(size) +' Bytes) saved to: ' + str(tf_quant_model_path))\n",
    "    \n",
    "    # 2.1 Full integer quantization with input and output in integer too\n",
    "    try:\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_data_gen\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.uint8\n",
    "        converter.inference_output_type = tf.uint8\n",
    "\n",
    "        tflite_model_quant = converter.convert()\n",
    "        tf_quant_model_path = optimized_dir/(model_name + '_full_integer_quantization_integer_io.tflite')\n",
    "        size = tf_quant_model_path.write_bytes(tflite_model_quant)\n",
    "        print('Full integer quantizatized with integer io TFLite model ('+ str(size) +' Bytes) saved to: ' + str(tf_quant_model_path))\n",
    "    except:\n",
    "        print('ERROR: Failed Full integer quantizatized with integer io TFLite model')\n",
    "        \n",
    "    # 3. float16 quantization\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "    \n",
    "    tflite_model_quant = converter.convert()\n",
    "    tf_quant_model_path = optimized_dir/(model_name + '_float16_quantization.tflite')\n",
    "    size = tf_quant_model_path.write_bytes(tflite_model_quant)\n",
    "    print('float16 quantizatized TFLite model ('+ str(size) +' Bytes) saved to: ' + str(tf_quant_model_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning and fine-tuning\n",
    "\n",
    "1. Prune model to different sparsity  ( tf uses magnitude-based pruning )\n",
    "    1. ConstantSparsity - sparsity is kept constant during training.\n",
    "    2. PolynomialDecay - the degree of sparsity is changed during training.\n",
    "2. Fine-tune model\n",
    "\n",
    "https://www.machinecurve.com/index.php/2020/09/29/tensorflow-pruning-schedules-constantsparsity-and-polynomialdecay/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "PRUNING_EPOCHS = 10\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some layers cannot be pruned\n",
    "\n",
    "def prune_prunable_layers(model, pruning_params):\n",
    "    \"\"\"returns model for pruning with avoided non prunable layers\"\"\"\n",
    "    \n",
    "    # Rescaling layer cannot be pruned\n",
    "    def apply_pruning_to_prunable(layer):\n",
    "        if isinstance(layer, tf.keras.layers.experimental.preprocessing.Rescaling) or isinstance(layer, tf.keras.layers.experimental.preprocessing.Normalization):\n",
    "            return layer\n",
    "        return prune_low_magnitude(layer, **pruning_params)\n",
    "    model_for_pruning = tf.keras.models.clone_model(\n",
    "                                model,\n",
    "                                clone_function=apply_pruning_to_prunable,\n",
    "                            )\n",
    "    return model_for_pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model_path, batch_size, pruning_epochs, ds_train, ds_validation, sparsity):\n",
    "     # check if model was already in optimization folder\n",
    "    if (len(model_path.split('/')[0].split('_')) == 3):\n",
    "        optimized_dir = pathlib.Path(model_path.split('/')[0] + '/')\n",
    "    else:\n",
    "        optimized_dir = pathlib.Path(model_path.split('/')[0] + '_optimized/')\n",
    "    model_name = model_path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    sparsities = [0.5, 0.75, 0.9]\n",
    "    \n",
    "    ds_train = ds_train.batch(batch_size)\n",
    "    ds_validation = ds_validation.batch(batch_size)\n",
    "    \n",
    "    ds_train.cache()\n",
    "    ds_validation.cache()\n",
    "    \n",
    "    # get number of images\n",
    "    num_images = 0\n",
    "    for i in ds_train.as_numpy_iterator():\n",
    "        num_images+=1\n",
    "\n",
    "    end_step = np.ceil(num_images / batch_size).astype(np.int32) * pruning_epochs\n",
    "\n",
    "    # Define pruning configuration\n",
    "    pruning_params_constant = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=sparsity,\n",
    "                                                                    begin_step=0,\n",
    "                                                                    end_step=end_step)\n",
    "    }\n",
    "\n",
    "    pruning_params_polynomial = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0,\n",
    "                                                                final_sparsity=sparsity,\n",
    "                                                                begin_step=0,\n",
    "                                                                end_step=end_step)\n",
    "    }\n",
    "\n",
    "    # Rescaling layer cannot be wrapped in prune low magnitude\n",
    "    try:\n",
    "        model_for_pruning_constant = prune_low_magnitude(model, **pruning_params_constant)\n",
    "        model_for_pruning_polynomial = prune_low_magnitude(model, **pruning_params_polynomial)\n",
    "    except:\n",
    "        model_for_pruning_constant = prune_prunable_layers(model, pruning_params_constant) \n",
    "        model_for_pruning_polynomial = prune_prunable_layers(model, pruning_params_polynomial)\n",
    "\n",
    "\n",
    "    # Compile models for pruning\n",
    "    model_for_pruning_constant.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "    model_for_pruning_polynomial.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    constant_log_dir = pathlib.Path(\"./tmp/\" + model_name + '_ConstantSparsity' + str(int(sparsity*100)))\n",
    "    constant_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    polynomial_log_dir = pathlib.Path(\"./tmp/\" + model_name + '_PolynomialDecay' + str(int(sparsity*100)))\n",
    "    polynomial_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Model callbacks\n",
    "    constant_callbacks = [\n",
    "        tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "        tfmot.sparsity.keras.PruningSummaries(log_dir=str(constant_log_dir))\n",
    "    ]\n",
    "    polynomial_callbacks = [\n",
    "        tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "        tfmot.sparsity.keras.PruningSummaries(log_dir=str(polynomial_log_dir))\n",
    "    ]\n",
    "\n",
    "    # Fitting data\n",
    "    model_for_pruning_constant.fit(ds_train,\n",
    "                              validation_data=ds_validation,\n",
    "                              epochs=pruning_epochs,\n",
    "                              callbacks=constant_callbacks)\n",
    "\n",
    "    model_for_pruning_polynomial.fit(ds_train,\n",
    "                              validation_data=ds_validation,\n",
    "                              epochs=pruning_epochs,\n",
    "                              callbacks=polynomial_callbacks)\n",
    "\n",
    "    # Save pruned models\n",
    "    model_constant_path = optimized_dir/(model_name + '_ConstantSparsity' + str(int(sparsity*100)) + '.h5')\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning_constant)\n",
    "    model_for_export.save(str(model_constant_path))\n",
    "    print('saved ' + str(model_constant_path))\n",
    "\n",
    "    model_polynomial_path = optimized_dir/(model_name + '_PolynomialDecay' + str(int(sparsity*100)) + '.h5')\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning_polynomial)\n",
    "    model_for_export.save(str(model_polynomial_path))\n",
    "    print('saved ' + str(model_polynomial_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some layers cannot be weight clustered\n",
    "\n",
    "def cluster_clustred_layers(model, cluster_params):    \n",
    "    # Rescaling layer cannot be pruned\n",
    "    def apply_clustering_to_clusterable(layer):\n",
    "        if model.layers[0] == layer or  model.layers[-1] == layer:\n",
    "            return layer\n",
    "        try:\n",
    "            x = cluster_weights(layer, **cluster_params)\n",
    "            return x\n",
    "        except:\n",
    "            return layer\n",
    "\n",
    "    model_for_clustering = tf.keras.models.clone_model(\n",
    "                                model,\n",
    "                                clone_function=apply_clustering_to_clusterable,\n",
    "                            )\n",
    "    return model_for_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_cluster_model(model_path, batch_size, epochs, ds_train, ds_validation, number_of_clusters):\n",
    "    \"\"\" Weight clustering on given moodel \n",
    "    note: cannot use for cycle in this function to do different number of clusters because of compatibility issues\"\"\"\n",
    "     # check if model was already in optimization folder\n",
    "    if (len(model_path.split('/')[0].split('_')) == 3):\n",
    "        optimized_dir = pathlib.Path(model_path.split('/')[0] + '/')\n",
    "    else:\n",
    "        optimized_dir = pathlib.Path(model_path.split('/')[0] + '_optimized/')\n",
    "    model_name = model_path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    ds_train = ds_train.batch(batch_size)\n",
    "    ds_validation = ds_validation.batch(batch_size)\n",
    "    \n",
    "    ds_train.cache()\n",
    "    ds_validation.cache()\n",
    "    \n",
    "    # get number of images\n",
    "    num_images = 0\n",
    "    for i in ds_train.as_numpy_iterator():\n",
    "        num_images+=1\n",
    "\n",
    "    end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "    # Define weight clustering configuration\n",
    "    cluster_params_kmeans = {\n",
    "                                  'number_of_clusters': number_of_clusters,\n",
    "                                  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS\n",
    "                                }\n",
    "\n",
    "    # Rescaling layer cannot be wrapped in prune low magnitude\n",
    "    try:\n",
    "        model_for_clustering_kmeans = cluster_weights(model, **cluster_params_kmeans)\n",
    "    except:\n",
    "        model_for_clustering_kmeans = cluster_clustred_layers(model, cluster_params_kmeans)\n",
    "\n",
    "    # Compile models for clustering\n",
    "    model_for_clustering_kmeans.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    # Fitting data        \n",
    "    model_for_clustering_kmeans.fit(ds_train,\n",
    "                              validation_data=ds_validation,\n",
    "                              epochs=epochs)\n",
    "\n",
    "    # Save pruned models\n",
    "    model_kmeans_path = optimized_dir/(model_name + '_KMeansPlusPlus' + str(number_of_clusters) + '.h5')\n",
    "    model_for_export = tfmot.clustering.keras.strip_clustering(model_for_clustering_kmeans)\n",
    "    model_for_export.save(str(model_kmeans_path))\n",
    "    print('saved ' + str(model_kmeans_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimze models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "flowers_datasets = load_flowers_dataset()\n",
    "beans_datasets = load_beans_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "Due to bad tensorflow optimization of calling fit function in a loop, calling prune_model in a loop is unusable.\n",
    "Solution: don't use for loops\n",
    "Issue: https://github.com/tensorflow/tensorflow/issues/34025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prune base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macenpav/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 20s - loss: 0.3910 - accuracy: 0.8870WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1501s vs `on_train_batch_end` time: 0.3413s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1501s vs `on_train_batch_end` time: 0.3413s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 53s 602ms/step - loss: 0.3764 - accuracy: 0.8853 - val_loss: 4.8429 - val_accuracy: 0.3648\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 38s 521ms/step - loss: 0.1317 - accuracy: 0.9549 - val_loss: 5.1772 - val_accuracy: 0.3339\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 36s 504ms/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 5.2955 - val_accuracy: 0.3285\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 38s 542ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 5.2196 - val_accuracy: 0.3249\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 35s 514ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.9734 - val_accuracy: 0.3466\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 32s 510ms/step - loss: 0.0156 - accuracy: 0.9983 - val_loss: 4.1645 - val_accuracy: 0.3811\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 35s 513ms/step - loss: 0.0663 - accuracy: 0.9779 - val_loss: 2.1195 - val_accuracy: 0.6189\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 34s 536ms/step - loss: 0.0642 - accuracy: 0.9781 - val_loss: 1.6304 - val_accuracy: 0.6497\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 38s 539ms/step - loss: 0.0798 - accuracy: 0.9732 - val_loss: 1.6778 - val_accuracy: 0.6116\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 37s 537ms/step - loss: 0.0792 - accuracy: 0.9686 - val_loss: 6.4816 - val_accuracy: 0.4247\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 30s - loss: 0.0706 - accuracy: 0.9724WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1448s vs `on_train_batch_end` time: 0.6069s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1448s vs `on_train_batch_end` time: 0.6069s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 55s 584ms/step - loss: 0.1297 - accuracy: 0.9544 - val_loss: 3.9216 - val_accuracy: 0.6134\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 33s 509ms/step - loss: 0.1730 - accuracy: 0.9408 - val_loss: 5.0273 - val_accuracy: 0.5318\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 37s 534ms/step - loss: 0.1029 - accuracy: 0.9661 - val_loss: 7.6865 - val_accuracy: 0.4900\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 36s 523ms/step - loss: 0.0559 - accuracy: 0.9817 - val_loss: 8.5656 - val_accuracy: 0.4628\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 35s 526ms/step - loss: 0.0334 - accuracy: 0.9883 - val_loss: 7.2760 - val_accuracy: 0.4701\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 35s 535ms/step - loss: 0.0483 - accuracy: 0.9872 - val_loss: 7.6444 - val_accuracy: 0.5390\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 34s 531ms/step - loss: 0.2076 - accuracy: 0.9316 - val_loss: 10.9768 - val_accuracy: 0.4374\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 35s 538ms/step - loss: 0.1933 - accuracy: 0.9405 - val_loss: 13.8945 - val_accuracy: 0.4192\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 38s 531ms/step - loss: 0.0888 - accuracy: 0.9701 - val_loss: 10.1349 - val_accuracy: 0.5009\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 37s 525ms/step - loss: 0.0406 - accuracy: 0.9868 - val_loss: 10.2703 - val_accuracy: 0.5118\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50.h5\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50.h5\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 29s - loss: 1.5794 - accuracy: 0.5813WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1510s vs `on_train_batch_end` time: 0.5708s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1510s vs `on_train_batch_end` time: 0.5708s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 55s 577ms/step - loss: 1.2790 - accuracy: 0.6239 - val_loss: 4.0899 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 35s 524ms/step - loss: 0.4252 - accuracy: 0.8521 - val_loss: 4.0015 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 37s 539ms/step - loss: 0.2112 - accuracy: 0.9382 - val_loss: 4.3952 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 35s 521ms/step - loss: 0.1263 - accuracy: 0.9717 - val_loss: 4.6068 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 31s 521ms/step - loss: 0.0764 - accuracy: 0.9828 - val_loss: 4.8142 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 37s 518ms/step - loss: 0.1036 - accuracy: 0.9668 - val_loss: 5.1166 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 35s 522ms/step - loss: 0.0861 - accuracy: 0.9786 - val_loss: 5.4248 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 37s 498ms/step - loss: 0.1092 - accuracy: 0.9628 - val_loss: 5.2092 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 34s 519ms/step - loss: 0.0936 - accuracy: 0.9676 - val_loss: 5.2051 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 34s 518ms/step - loss: 0.0932 - accuracy: 0.9673 - val_loss: 5.2677 - val_accuracy: 0.2668\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 29s - loss: 0.0881 - accuracy: 0.9654WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1457s vs `on_train_batch_end` time: 0.5874s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1457s vs `on_train_batch_end` time: 0.5874s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 55s 577ms/step - loss: 0.2679 - accuracy: 0.9001 - val_loss: 5.4509 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 36s 520ms/step - loss: 0.3834 - accuracy: 0.8663 - val_loss: 5.1140 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 39s 532ms/step - loss: 0.1610 - accuracy: 0.9438 - val_loss: 6.4651 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 38s 533ms/step - loss: 0.1836 - accuracy: 0.9404 - val_loss: 6.5695 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 34s 530ms/step - loss: 0.2594 - accuracy: 0.9056 - val_loss: 6.2420 - val_accuracy: 0.2704\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 38s 532ms/step - loss: 0.2473 - accuracy: 0.9135 - val_loss: 6.1559 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 32s 528ms/step - loss: 0.1162 - accuracy: 0.9621 - val_loss: 4.9250 - val_accuracy: 0.2759\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 33s 540ms/step - loss: 0.0409 - accuracy: 0.9898 - val_loss: 5.4903 - val_accuracy: 0.2722\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 38s 531ms/step - loss: 0.0594 - accuracy: 0.9776 - val_loss: 4.3369 - val_accuracy: 0.3158\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 35s 532ms/step - loss: 0.0477 - accuracy: 0.9836 - val_loss: 4.2890 - val_accuracy: 0.3285\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75.h5\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75.h5\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 27s - loss: 3.7414 - accuracy: 0.2833WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1489s vs `on_train_batch_end` time: 0.5418s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1489s vs `on_train_batch_end` time: 0.5418s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 56s 601ms/step - loss: 2.7673 - accuracy: 0.3752 - val_loss: 3.1433 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 32s 514ms/step - loss: 1.0685 - accuracy: 0.6097 - val_loss: 2.8787 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 34s 520ms/step - loss: 0.8042 - accuracy: 0.7108 - val_loss: 2.7986 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 32s 503ms/step - loss: 0.6412 - accuracy: 0.7744 - val_loss: 2.7680 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 36s 521ms/step - loss: 0.5351 - accuracy: 0.8205 - val_loss: 2.8150 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 33s 528ms/step - loss: 0.4259 - accuracy: 0.8666 - val_loss: 2.8502 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 36s 529ms/step - loss: 0.3123 - accuracy: 0.9010 - val_loss: 2.9318 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 37s 545ms/step - loss: 0.2961 - accuracy: 0.9068 - val_loss: 3.0229 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 33s 538ms/step - loss: 0.2988 - accuracy: 0.8994 - val_loss: 3.0124 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 38s 521ms/step - loss: 0.2514 - accuracy: 0.9204 - val_loss: 3.0757 - val_accuracy: 0.2668\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 31s - loss: 0.5752 - accuracy: 0.8376WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1472s vs `on_train_batch_end` time: 0.6238s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1472s vs `on_train_batch_end` time: 0.6238s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 54s 602ms/step - loss: 0.8792 - accuracy: 0.6979 - val_loss: 2.8131 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 38s 513ms/step - loss: 0.6928 - accuracy: 0.7385 - val_loss: 3.1451 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 36s 528ms/step - loss: 0.4705 - accuracy: 0.8324 - val_loss: 4.1212 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 35s 522ms/step - loss: 0.4333 - accuracy: 0.8397 - val_loss: 3.4174 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 34s 512ms/step - loss: 0.3453 - accuracy: 0.8701 - val_loss: 4.0426 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 37s 522ms/step - loss: 0.3129 - accuracy: 0.8894 - val_loss: 4.0601 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 35s 526ms/step - loss: 0.2169 - accuracy: 0.9296 - val_loss: 4.5391 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 33s 530ms/step - loss: 0.1414 - accuracy: 0.9477 - val_loss: 4.4371 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 37s 523ms/step - loss: 0.1253 - accuracy: 0.9604 - val_loss: 4.5669 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 37s 541ms/step - loss: 0.3978 - accuracy: 0.8666 - val_loss: 5.5749 - val_accuracy: 0.2668\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90.h5\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90.h5\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 44s - loss: 0.9455 - accuracy: 0.7294WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2466s vs `on_train_batch_end` time: 0.8284s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2466s vs `on_train_batch_end` time: 0.8284s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 79s 867ms/step - loss: 0.6724 - accuracy: 0.7865 - val_loss: 1.9406 - val_accuracy: 0.4610\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 48s 769ms/step - loss: 0.1662 - accuracy: 0.9445 - val_loss: 1.9345 - val_accuracy: 0.4864\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 46s 767ms/step - loss: 0.0666 - accuracy: 0.9820 - val_loss: 1.0696 - val_accuracy: 0.6897\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 48s 751ms/step - loss: 0.0559 - accuracy: 0.9819 - val_loss: 1.1471 - val_accuracy: 0.6987\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 46s 750ms/step - loss: 0.0459 - accuracy: 0.9837 - val_loss: 1.1430 - val_accuracy: 0.7024\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 45s 763ms/step - loss: 0.0581 - accuracy: 0.9850 - val_loss: 1.3263 - val_accuracy: 0.6715\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 45s 762ms/step - loss: 0.0308 - accuracy: 0.9889 - val_loss: 1.4992 - val_accuracy: 0.6733\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 42s 760ms/step - loss: 0.0587 - accuracy: 0.9776 - val_loss: 1.3758 - val_accuracy: 0.6951\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 45s 766ms/step - loss: 0.0687 - accuracy: 0.9801 - val_loss: 2.5744 - val_accuracy: 0.5753\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 45s 764ms/step - loss: 0.1025 - accuracy: 0.9630 - val_loss: 1.6949 - val_accuracy: 0.6642\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 52s - loss: 0.0601 - accuracy: 0.9747 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2500s vs `on_train_batch_end` time: 1.0364s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2500s vs `on_train_batch_end` time: 1.0364s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 80s 896ms/step - loss: 0.0971 - accuracy: 0.9636 - val_loss: 2.5507 - val_accuracy: 0.6207\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 43s 738ms/step - loss: 0.0985 - accuracy: 0.9630 - val_loss: 2.8862 - val_accuracy: 0.6116\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 48s 762ms/step - loss: 0.1622 - accuracy: 0.9485 - val_loss: 2.7197 - val_accuracy: 0.6062\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 46s 748ms/step - loss: 0.0768 - accuracy: 0.9758 - val_loss: 1.7427 - val_accuracy: 0.6770\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 47s 762ms/step - loss: 0.0416 - accuracy: 0.9840 - val_loss: 1.5539 - val_accuracy: 0.7042\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 46s 772ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 1.4259 - val_accuracy: 0.7205\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 44s 771ms/step - loss: 0.0270 - accuracy: 0.9907 - val_loss: 1.5866 - val_accuracy: 0.6933\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 44s 763ms/step - loss: 0.1203 - accuracy: 0.9626 - val_loss: 1.5518 - val_accuracy: 0.6951\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 46s 772ms/step - loss: 0.1064 - accuracy: 0.9606 - val_loss: 1.9700 - val_accuracy: 0.6661\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 44s 755ms/step - loss: 0.1125 - accuracy: 0.9600 - val_loss: 2.2627 - val_accuracy: 0.6733\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50.h5\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50.h5\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 43s - loss: 1.4746 - accuracy: 0.4427WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2476s vs `on_train_batch_end` time: 0.8370s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2476s vs `on_train_batch_end` time: 0.8370s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 75s 886ms/step - loss: 1.2346 - accuracy: 0.5257 - val_loss: 1.7721 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 781ms/step - loss: 0.8428 - accuracy: 0.6856 - val_loss: 1.8009 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 44s 761ms/step - loss: 0.5879 - accuracy: 0.8060 - val_loss: 1.7687 - val_accuracy: 0.2777\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 45s 769ms/step - loss: 0.3840 - accuracy: 0.8961 - val_loss: 1.5808 - val_accuracy: 0.4537\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 46s 773ms/step - loss: 0.2851 - accuracy: 0.9189 - val_loss: 2.1422 - val_accuracy: 0.4283\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 45s 777ms/step - loss: 0.2061 - accuracy: 0.9514 - val_loss: 1.7510 - val_accuracy: 0.4864\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 47s 768ms/step - loss: 0.1700 - accuracy: 0.9548 - val_loss: 1.1124 - val_accuracy: 0.6298\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 45s 780ms/step - loss: 0.1678 - accuracy: 0.9538 - val_loss: 1.3668 - val_accuracy: 0.6152\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 48s 768ms/step - loss: 0.1137 - accuracy: 0.9692 - val_loss: 1.8554 - val_accuracy: 0.5554\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 46s 774ms/step - loss: 0.1278 - accuracy: 0.9639 - val_loss: 1.2842 - val_accuracy: 0.6388\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 44s - loss: 0.1000 - accuracy: 0.9751WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2472s vs `on_train_batch_end` time: 0.8719s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2472s vs `on_train_batch_end` time: 0.8719s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 82s 880ms/step - loss: 0.2492 - accuracy: 0.9228 - val_loss: 1.9910 - val_accuracy: 0.6007\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 760ms/step - loss: 0.2585 - accuracy: 0.9144 - val_loss: 1.5362 - val_accuracy: 0.6733\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 44s 765ms/step - loss: 0.2258 - accuracy: 0.9209 - val_loss: 3.0452 - val_accuracy: 0.5118\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 46s 763ms/step - loss: 0.1388 - accuracy: 0.9537 - val_loss: 2.2102 - val_accuracy: 0.5753\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 47s 762ms/step - loss: 0.2086 - accuracy: 0.9362 - val_loss: 1.6509 - val_accuracy: 0.6497\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 44s 753ms/step - loss: 0.1366 - accuracy: 0.9580 - val_loss: 2.3810 - val_accuracy: 0.5445\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 42s 744ms/step - loss: 0.2244 - accuracy: 0.9337 - val_loss: 2.3801 - val_accuracy: 0.5989\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 46s 752ms/step - loss: 0.1499 - accuracy: 0.9518 - val_loss: 2.3294 - val_accuracy: 0.5336\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 46s 746ms/step - loss: 0.0989 - accuracy: 0.9652 - val_loss: 1.8973 - val_accuracy: 0.6316\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 46s 752ms/step - loss: 0.1174 - accuracy: 0.9661 - val_loss: 1.5374 - val_accuracy: 0.6878\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75.h5\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75.h5\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 45s - loss: 1.7408 - accuracy: 0.2496WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2418s vs `on_train_batch_end` time: 0.8723s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2418s vs `on_train_batch_end` time: 0.8723s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 78s 874ms/step - loss: 1.6751 - accuracy: 0.2735 - val_loss: 2.8595 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 45s 765ms/step - loss: 1.5953 - accuracy: 0.3367 - val_loss: 2.3068 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 47s 755ms/step - loss: 1.5582 - accuracy: 0.3937 - val_loss: 1.9514 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 45s 757ms/step - loss: 1.5252 - accuracy: 0.4294 - val_loss: 1.7501 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 47s 754ms/step - loss: 1.4947 - accuracy: 0.4343 - val_loss: 1.6474 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 39s 757ms/step - loss: 1.4575 - accuracy: 0.4570 - val_loss: 1.6124 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 45s 751ms/step - loss: 1.4254 - accuracy: 0.4946 - val_loss: 1.5455 - val_accuracy: 0.2777\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 45s 757ms/step - loss: 1.3937 - accuracy: 0.5054 - val_loss: 1.4932 - val_accuracy: 0.3212\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 46s 750ms/step - loss: 1.3538 - accuracy: 0.5538 - val_loss: 1.4998 - val_accuracy: 0.2849\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 39s 740ms/step - loss: 1.3248 - accuracy: 0.5335 - val_loss: 1.4737 - val_accuracy: 0.3757\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 45s - loss: 1.2881 - accuracy: 0.5370WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2424s vs `on_train_batch_end` time: 0.8944s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2424s vs `on_train_batch_end` time: 0.8944s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 81s 862ms/step - loss: 1.1764 - accuracy: 0.5292 - val_loss: 4.7785 - val_accuracy: 0.4011\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 43s 742ms/step - loss: 0.8423 - accuracy: 0.6613 - val_loss: 1.7942 - val_accuracy: 0.5118\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 48s 756ms/step - loss: 0.6695 - accuracy: 0.7291 - val_loss: 3.5444 - val_accuracy: 0.4773\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 46s 746ms/step - loss: 0.5278 - accuracy: 0.8037 - val_loss: 1.9098 - val_accuracy: 0.5989\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 44s 749ms/step - loss: 0.4292 - accuracy: 0.8467 - val_loss: 2.3211 - val_accuracy: 0.5408\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 44s 754ms/step - loss: 0.2868 - accuracy: 0.8968 - val_loss: 1.5575 - val_accuracy: 0.6225\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 43s 736ms/step - loss: 0.2703 - accuracy: 0.9011 - val_loss: 1.8320 - val_accuracy: 0.6207\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 46s 751ms/step - loss: 0.3124 - accuracy: 0.9053 - val_loss: 1.9576 - val_accuracy: 0.6642\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 46s 746ms/step - loss: 0.3196 - accuracy: 0.8895 - val_loss: 1.7632 - val_accuracy: 0.6552\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 45s 753ms/step - loss: 0.1766 - accuracy: 0.9356 - val_loss: 1.7566 - val_accuracy: 0.6007\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90.h5\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90.h5\n"
     ]
    }
   ],
   "source": [
    "prune_model(model_path='flowers_models/MobileNetV2_flowers_model.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='flowers_models/MobileNetV2_flowers_model.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='flowers_models/MobileNetV2_flowers_model.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)\n",
    "\n",
    "prune_model(model_path='flowers_models/EfficentNetB0_flowers_model.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1], \n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='flowers_models/EfficentNetB0_flowers_model.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1], \n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='flowers_models/EfficentNetB0_flowers_model.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1], \n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 23s - loss: 0.7109 - accuracy: 0.8349WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4215s vs `on_train_batch_end` time: 1.4311s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4215s vs `on_train_batch_end` time: 1.4311s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 58s 2s/step - loss: 0.6173 - accuracy: 0.8374 - val_loss: 2.2560 - val_accuracy: 0.4962\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1355 - accuracy: 0.9450 - val_loss: 2.7642 - val_accuracy: 0.5414\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0654 - accuracy: 0.9780 - val_loss: 3.6966 - val_accuracy: 0.4361\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0332 - accuracy: 0.9900 - val_loss: 3.5461 - val_accuracy: 0.4812\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 4.0588 - val_accuracy: 0.4211\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 3.4860 - val_accuracy: 0.5865\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 3.0434 - val_accuracy: 0.5263\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0087 - accuracy: 0.9959 - val_loss: 3.6630 - val_accuracy: 0.4662\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 2.9491 - val_accuracy: 0.4962\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 6.0953 - val_accuracy: 0.4511\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 24s - loss: 0.0774 - accuracy: 0.9724WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4170s vs `on_train_batch_end` time: 1.7146s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4170s vs `on_train_batch_end` time: 1.7146s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 56s 2s/step - loss: 0.1104 - accuracy: 0.9569 - val_loss: 8.9401 - val_accuracy: 0.4737\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1979 - accuracy: 0.9341 - val_loss: 10.1109 - val_accuracy: 0.3985\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0802 - accuracy: 0.9695 - val_loss: 15.9307 - val_accuracy: 0.3985\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0927 - accuracy: 0.9715 - val_loss: 25.5463 - val_accuracy: 0.4211\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1106 - accuracy: 0.9579 - val_loss: 6.4101 - val_accuracy: 0.5113\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1690 - accuracy: 0.9528 - val_loss: 17.1670 - val_accuracy: 0.3609\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0573 - accuracy: 0.9834 - val_loss: 11.3339 - val_accuracy: 0.5038\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 15.9450 - val_accuracy: 0.4737\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0412 - accuracy: 0.9866 - val_loss: 14.4699 - val_accuracy: 0.4060\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0477 - accuracy: 0.9830 - val_loss: 18.4419 - val_accuracy: 0.3910\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50.h5\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50.h5\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 23s - loss: 1.9363 - accuracy: 0.5283WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4079s vs `on_train_batch_end` time: 1.6248s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4079s vs `on_train_batch_end` time: 1.6248s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 54s 2s/step - loss: 1.5089 - accuracy: 0.5947 - val_loss: 1.2537 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.4702 - accuracy: 0.8179 - val_loss: 1.2996 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2334 - accuracy: 0.9313 - val_loss: 1.4627 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1495 - accuracy: 0.9627 - val_loss: 1.6062 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0921 - accuracy: 0.9761 - val_loss: 1.7679 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0511 - accuracy: 0.9932 - val_loss: 1.8862 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0446 - accuracy: 0.9915 - val_loss: 1.9919 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.0393 - accuracy: 0.9952 - val_loss: 2.0872 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.0328 - accuracy: 0.9950 - val_loss: 2.3578 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0230 - accuracy: 0.9946 - val_loss: 2.1743 - val_accuracy: 0.3308\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 23s - loss: 0.0781 - accuracy: 0.9701WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4171s vs `on_train_batch_end` time: 1.6550s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4171s vs `on_train_batch_end` time: 1.6550s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 55s 2s/step - loss: 0.1570 - accuracy: 0.9459 - val_loss: 1.8077 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.3782 - accuracy: 0.8765 - val_loss: 3.6830 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1604 - accuracy: 0.9366 - val_loss: 3.1757 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1130 - accuracy: 0.9609 - val_loss: 3.1177 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1461 - accuracy: 0.9433 - val_loss: 3.3786 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1281 - accuracy: 0.9591 - val_loss: 3.3704 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1252 - accuracy: 0.9551 - val_loss: 3.2827 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1242 - accuracy: 0.9588 - val_loss: 5.2309 - val_accuracy: 0.3383\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0500 - accuracy: 0.9885 - val_loss: 4.4848 - val_accuracy: 0.3459\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0230 - accuracy: 0.9967 - val_loss: 4.2971 - val_accuracy: 0.3534\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75.h5\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75.h5\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 24s - loss: 1.5712 - accuracy: 0.4355WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4273s vs `on_train_batch_end` time: 1.6909s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4273s vs `on_train_batch_end` time: 1.6909s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 52s 2s/step - loss: 1.3020 - accuracy: 0.4931 - val_loss: 1.1042 - val_accuracy: 0.3383\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.6675 - accuracy: 0.7117 - val_loss: 1.1023 - val_accuracy: 0.3383\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.4820 - accuracy: 0.8027 - val_loss: 1.1055 - val_accuracy: 0.3383\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.3557 - accuracy: 0.8892 - val_loss: 1.1102 - val_accuracy: 0.3383\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2281 - accuracy: 0.9470 - val_loss: 1.1101 - val_accuracy: 0.3383\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1793 - accuracy: 0.9487 - val_loss: 1.1108 - val_accuracy: 0.3383\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1624 - accuracy: 0.9655 - val_loss: 1.1069 - val_accuracy: 0.3383\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1429 - accuracy: 0.9659 - val_loss: 1.1099 - val_accuracy: 0.3383\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.1137 - accuracy: 0.9731 - val_loss: 1.1141 - val_accuracy: 0.3383\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0801 - accuracy: 0.9855 - val_loss: 1.1169 - val_accuracy: 0.3383\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 23s - loss: 0.4782 - accuracy: 0.8415WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4200s vs `on_train_batch_end` time: 1.6031s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4200s vs `on_train_batch_end` time: 1.6031s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 54s 2s/step - loss: 0.5742 - accuracy: 0.7934 - val_loss: 1.1280 - val_accuracy: 0.3383\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.5205 - accuracy: 0.8057 - val_loss: 1.0991 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.3294 - accuracy: 0.8848 - val_loss: 1.1504 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2145 - accuracy: 0.9261 - val_loss: 1.1187 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2005 - accuracy: 0.9215 - val_loss: 1.1686 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2014 - accuracy: 0.9217 - val_loss: 1.1359 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2323 - accuracy: 0.9159 - val_loss: 1.1177 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2440 - accuracy: 0.9059 - val_loss: 1.2549 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1629 - accuracy: 0.9400 - val_loss: 1.1211 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1192 - accuracy: 0.9640 - val_loss: 1.0992 - val_accuracy: 0.3308\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90.h5\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90.h5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[64,480,32,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_1/prune_low_magnitude_block4c_dwconv/depthwise (defined at /home/macenpav/.conda/envs/ml/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:270) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_2364702]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-90ad8dd043fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             sparsity=0.9)\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m prune_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mds_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mds_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a3166338c0d5>\u001b[0m in \u001b[0;36mprune_model\u001b[0;34m(model_path, batch_size, pruning_epochs, ds_train, ds_validation, sparsity)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Fitting data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     model_for_pruning_constant.fit(ds_train,\n\u001b[0m\u001b[1;32m     75\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpruning_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[64,480,32,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_1/prune_low_magnitude_block4c_dwconv/depthwise (defined at /home/macenpav/.conda/envs/ml/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:270) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_2364702]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "prune_model(model_path='beans_models/MobileNetV2_beans_model.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='beans_models/MobileNetV2_beans_model.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='beans_models/MobileNetV2_beans_model.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)\n",
    "\n",
    "prune_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1], \n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1], \n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1], \n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Weight cluster base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 44s 559ms/step - loss: 0.2976 - accuracy: 0.9421 - val_loss: 1.2797 - val_accuracy: 0.6915\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 36s 532ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 1.8917 - val_accuracy: 0.6969\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 33s 538ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 1.8013 - val_accuracy: 0.7078\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 36s 541ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.8918 - val_accuracy: 0.6897\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 36s 523ms/step - loss: 8.3424e-04 - accuracy: 0.9998 - val_loss: 1.8506 - val_accuracy: 0.7169\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 36s 532ms/step - loss: 5.2407e-04 - accuracy: 0.9998 - val_loss: 1.9298 - val_accuracy: 0.7169\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 35s 533ms/step - loss: 9.5425e-04 - accuracy: 0.9991 - val_loss: 1.8869 - val_accuracy: 0.7296\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 35s 524ms/step - loss: 4.6404e-04 - accuracy: 0.9998 - val_loss: 1.8869 - val_accuracy: 0.7187\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 37s 522ms/step - loss: 2.9091e-04 - accuracy: 0.9999 - val_loss: 1.8904 - val_accuracy: 0.7223\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 37s 530ms/step - loss: 4.7859e-04 - accuracy: 0.9999 - val_loss: 1.8833 - val_accuracy: 0.7205\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32.h5\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 42s 563ms/step - loss: 0.2804 - accuracy: 0.9243 - val_loss: 1.3654 - val_accuracy: 0.6751\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 35s 536ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 1.7509 - val_accuracy: 0.6951\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 35s 539ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.6863 - val_accuracy: 0.7060\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 36s 523ms/step - loss: 0.0047 - accuracy: 0.9977 - val_loss: 1.8388 - val_accuracy: 0.6915\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 38s 527ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 1.7491 - val_accuracy: 0.7114\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 34s 527ms/step - loss: 3.9356e-04 - accuracy: 0.9999 - val_loss: 1.8391 - val_accuracy: 0.7205\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 33s 541ms/step - loss: 0.0013 - accuracy: 0.9987 - val_loss: 1.7846 - val_accuracy: 0.7114\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 37s 543ms/step - loss: 8.4117e-04 - accuracy: 0.9999 - val_loss: 1.8710 - val_accuracy: 0.7205\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 39s 544ms/step - loss: 6.2004e-04 - accuracy: 0.9993 - val_loss: 1.8073 - val_accuracy: 0.7187\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 37s 547ms/step - loss: 0.0017 - accuracy: 0.9980 - val_loss: 1.8077 - val_accuracy: 0.7169\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128.h5\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 55s 747ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 1.8768 - val_accuracy: 0.6806\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 45s 724ms/step - loss: 0.0139 - accuracy: 0.9943 - val_loss: 3.3468 - val_accuracy: 0.6461\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 41s 717ms/step - loss: 0.0197 - accuracy: 0.9929 - val_loss: 1.9728 - val_accuracy: 0.6842\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 45s 716ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 2.4089 - val_accuracy: 0.6606\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 41s 740ms/step - loss: 8.1928e-04 - accuracy: 0.9993 - val_loss: 2.3370 - val_accuracy: 0.7078\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 42s 733ms/step - loss: 4.1467e-04 - accuracy: 0.9998 - val_loss: 2.3414 - val_accuracy: 0.7024\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 46s 723ms/step - loss: 3.7177e-04 - accuracy: 1.0000 - val_loss: 2.3353 - val_accuracy: 0.7042\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 45s 733ms/step - loss: 0.0015 - accuracy: 0.9986 - val_loss: 2.2443 - val_accuracy: 0.7060\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 44s 729ms/step - loss: 3.4725e-04 - accuracy: 0.9999 - val_loss: 2.2317 - val_accuracy: 0.7024\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 42s 725ms/step - loss: 5.0896e-04 - accuracy: 0.9997 - val_loss: 2.2164 - val_accuracy: 0.7042\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32.h5\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 55s 752ms/step - loss: 0.0389 - accuracy: 0.9851 - val_loss: 1.7941 - val_accuracy: 0.6624\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 45s 719ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 1.5448 - val_accuracy: 0.6987\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 45s 731ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 1.5711 - val_accuracy: 0.7078\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 43s 702ms/step - loss: 8.9074e-04 - accuracy: 0.9996 - val_loss: 1.5816 - val_accuracy: 0.7169\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 44s 718ms/step - loss: 6.8938e-04 - accuracy: 0.9999 - val_loss: 1.5973 - val_accuracy: 0.7132\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 44s 717ms/step - loss: 3.4123e-04 - accuracy: 0.9999 - val_loss: 1.6096 - val_accuracy: 0.7114\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 42s 723ms/step - loss: 3.2834e-04 - accuracy: 0.9996 - val_loss: 1.6098 - val_accuracy: 0.7132\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 42s 707ms/step - loss: 8.4514e-04 - accuracy: 0.9990 - val_loss: 1.6157 - val_accuracy: 0.7132\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 41s 719ms/step - loss: 5.5210e-04 - accuracy: 0.9995 - val_loss: 1.6163 - val_accuracy: 0.7132\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 43s 719ms/step - loss: 1.4302e-04 - accuracy: 1.0000 - val_loss: 1.6345 - val_accuracy: 0.7151\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128.h5\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='flowers_models/MobileNetV2_flowers_model.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models/MobileNetV2_flowers_model.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='flowers_models/EfficentNetB0_flowers_model.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models/EfficentNetB0_flowers_model.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 40s 2s/step - loss: 6.5026 - accuracy: 0.7062 - val_loss: 1.0236 - val_accuracy: 0.5188\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.9987 - accuracy: 0.4653 - val_loss: 0.9118 - val_accuracy: 0.5489\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.7917 - accuracy: 0.6053 - val_loss: 0.7014 - val_accuracy: 0.6692\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.5710 - accuracy: 0.7508 - val_loss: 0.9609 - val_accuracy: 0.6466\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.5487 - accuracy: 0.7576 - val_loss: 0.8500 - val_accuracy: 0.6617\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.4149 - accuracy: 0.8378 - val_loss: 1.1032 - val_accuracy: 0.6617\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.3102 - accuracy: 0.8811 - val_loss: 0.9017 - val_accuracy: 0.6917\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.1672 - accuracy: 0.9407 - val_loss: 1.0566 - val_accuracy: 0.6917\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.0826 - accuracy: 0.9743 - val_loss: 1.3572 - val_accuracy: 0.6917\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.0405 - accuracy: 0.9908 - val_loss: 2.5785 - val_accuracy: 0.5865\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32.h5\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 39s 2s/step - loss: 7.3363 - accuracy: 0.5765 - val_loss: 1.0281 - val_accuracy: 0.4211\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0415 - accuracy: 0.4343 - val_loss: 1.0738 - val_accuracy: 0.4586\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0535 - accuracy: 0.4271 - val_loss: 0.9219 - val_accuracy: 0.5639\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.9190 - accuracy: 0.5485 - val_loss: 0.8320 - val_accuracy: 0.5940\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.8515 - accuracy: 0.5916 - val_loss: 0.7818 - val_accuracy: 0.5865\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.7374 - accuracy: 0.6934 - val_loss: 0.8487 - val_accuracy: 0.6090\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.8554 - accuracy: 0.6183 - val_loss: 0.8234 - val_accuracy: 0.6391\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.7153 - accuracy: 0.6636 - val_loss: 0.9267 - val_accuracy: 0.5940\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.6081 - accuracy: 0.7469 - val_loss: 1.0319 - val_accuracy: 0.5865\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.4707 - accuracy: 0.8002 - val_loss: 0.8855 - val_accuracy: 0.6165\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128.h5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[64,480,32,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_1/cluster_block4c_dwconv/depthwise (defined at /home/macenpav/.conda/envs/ml/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster_wrapper.py:265) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_2563251]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6d02965b01da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                      number_of_clusters=128)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m weight_cluster_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n\u001b[0m\u001b[1;32m     15\u001b[0m                      \u001b[0mds_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                      \u001b[0mds_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5c99d32a386c>\u001b[0m in \u001b[0;36mweight_cluster_model\u001b[0;34m(model_path, batch_size, epochs, ds_train, ds_validation, number_of_clusters)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Fitting data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     model_for_clustering_kmeans.fit(ds_train,\n\u001b[0m\u001b[1;32m     45\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                               epochs=epochs)\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[64,480,32,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_1/cluster_block4c_dwconv/depthwise (defined at /home/macenpav/.conda/envs/ml/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster_wrapper.py:265) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_2563251]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "weight_cluster_model(model_path='beans_models/MobileNetV2_beans_model.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models/MobileNetV2_beans_model.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models/EfficentNetB0_beans_model.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. prune weight clustered models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 1:03 - loss: 0.2037 - accuracy: 0.9411WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1570s vs `on_train_batch_end` time: 1.3921s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1570s vs `on_train_batch_end` time: 1.3921s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 63s 729ms/step - loss: 0.2918 - accuracy: 0.9147 - val_loss: 6.7682 - val_accuracy: 0.2995\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 37s 521ms/step - loss: 0.1070 - accuracy: 0.9646 - val_loss: 5.7078 - val_accuracy: 0.3103\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 35s 520ms/step - loss: 0.0534 - accuracy: 0.9814 - val_loss: 5.7805 - val_accuracy: 0.2958\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 36s 527ms/step - loss: 0.0520 - accuracy: 0.9814 - val_loss: 4.6590 - val_accuracy: 0.3666\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 35s 555ms/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 4.1447 - val_accuracy: 0.4755\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 37s 551ms/step - loss: 0.0594 - accuracy: 0.9847 - val_loss: 2.7174 - val_accuracy: 0.5735\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 36s 532ms/step - loss: 0.0286 - accuracy: 0.9886 - val_loss: 2.7004 - val_accuracy: 0.5590\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 38s 537ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 2.7282 - val_accuracy: 0.6007\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 33s 534ms/step - loss: 0.0138 - accuracy: 0.9945 - val_loss: 2.2841 - val_accuracy: 0.6225\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 35s 531ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 1.7632 - val_accuracy: 0.6624\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 29s - loss: 0.0676 - accuracy: 0.9833WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1505s vs `on_train_batch_end` time: 0.5907s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1505s vs `on_train_batch_end` time: 0.5907s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 56s 600ms/step - loss: 0.1022 - accuracy: 0.9689 - val_loss: 6.2461 - val_accuracy: 0.5045\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 34s 515ms/step - loss: 0.2067 - accuracy: 0.9333 - val_loss: 7.6332 - val_accuracy: 0.4428\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 34s 519ms/step - loss: 0.2349 - accuracy: 0.9161 - val_loss: 4.6868 - val_accuracy: 0.5681\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 34s 519ms/step - loss: 0.0876 - accuracy: 0.9679 - val_loss: 6.5540 - val_accuracy: 0.4791\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 33s 523ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 6.4091 - val_accuracy: 0.5191\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 32s 541ms/step - loss: 0.0695 - accuracy: 0.9773 - val_loss: 6.4849 - val_accuracy: 0.5209\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 38s 535ms/step - loss: 0.0281 - accuracy: 0.9935 - val_loss: 6.6971 - val_accuracy: 0.5699\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 35s 526ms/step - loss: 0.0799 - accuracy: 0.9700 - val_loss: 7.4937 - val_accuracy: 0.4991\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 34s 525ms/step - loss: 0.0753 - accuracy: 0.9735 - val_loss: 8.4351 - val_accuracy: 0.4991\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 37s 536ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 11.5429 - val_accuracy: 0.3829\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity50.h5\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay50.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 30s - loss: 2.3102 - accuracy: 0.5066WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1482s vs `on_train_batch_end` time: 0.5934s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1482s vs `on_train_batch_end` time: 0.5934s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 56s 616ms/step - loss: 1.5135 - accuracy: 0.6039 - val_loss: 4.7603 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 35s 536ms/step - loss: 0.4117 - accuracy: 0.8448 - val_loss: 5.0208 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 38s 522ms/step - loss: 0.2011 - accuracy: 0.9379 - val_loss: 5.3697 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 32s 516ms/step - loss: 0.0889 - accuracy: 0.9809 - val_loss: 5.9941 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 37s 544ms/step - loss: 0.0868 - accuracy: 0.9751 - val_loss: 6.5041 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 38s 533ms/step - loss: 0.0616 - accuracy: 0.9825 - val_loss: 6.4043 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 36s 529ms/step - loss: 0.0523 - accuracy: 0.9853 - val_loss: 6.8116 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 36s 512ms/step - loss: 0.0628 - accuracy: 0.9803 - val_loss: 7.0299 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 38s 522ms/step - loss: 0.0620 - accuracy: 0.9814 - val_loss: 6.9853 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 36s 530ms/step - loss: 0.0425 - accuracy: 0.9884 - val_loss: 6.8322 - val_accuracy: 0.2668\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 29s - loss: 0.0746 - accuracy: 0.9806WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1553s vs `on_train_batch_end` time: 0.5736s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1553s vs `on_train_batch_end` time: 0.5736s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 58s 583ms/step - loss: 0.2740 - accuracy: 0.9153 - val_loss: 9.0045 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 36s 538ms/step - loss: 0.3112 - accuracy: 0.8902 - val_loss: 7.4351 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 33s 541ms/step - loss: 0.1983 - accuracy: 0.9271 - val_loss: 7.1770 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 32s 532ms/step - loss: 0.1256 - accuracy: 0.9540 - val_loss: 6.6440 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 36s 518ms/step - loss: 0.1865 - accuracy: 0.9346 - val_loss: 6.9399 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 36s 534ms/step - loss: 0.0962 - accuracy: 0.9668 - val_loss: 7.7387 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 34s 536ms/step - loss: 0.0930 - accuracy: 0.9652 - val_loss: 8.4444 - val_accuracy: 0.2686\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 37s 520ms/step - loss: 0.0794 - accuracy: 0.9762 - val_loss: 6.9254 - val_accuracy: 0.2704\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 34s 522ms/step - loss: 0.0747 - accuracy: 0.9738 - val_loss: 6.4320 - val_accuracy: 0.2795\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 36s 533ms/step - loss: 0.0489 - accuracy: 0.9823 - val_loss: 5.6726 - val_accuracy: 0.3249\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity75.h5\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay75.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 31s - loss: 3.8083 - accuracy: 0.2921WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1499s vs `on_train_batch_end` time: 0.6230s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1499s vs `on_train_batch_end` time: 0.6230s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 57s 593ms/step - loss: 2.9328 - accuracy: 0.3858 - val_loss: 3.2039 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 34s 526ms/step - loss: 1.1670 - accuracy: 0.6057 - val_loss: 2.9366 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 37s 513ms/step - loss: 0.7582 - accuracy: 0.7790 - val_loss: 2.8737 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 32s 533ms/step - loss: 0.5645 - accuracy: 0.8508 - val_loss: 2.8854 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 33s 528ms/step - loss: 0.4049 - accuracy: 0.9026 - val_loss: 2.9358 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 38s 542ms/step - loss: 0.3225 - accuracy: 0.9180 - val_loss: 2.9942 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 36s 526ms/step - loss: 0.3660 - accuracy: 0.8878 - val_loss: 3.0925 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 37s 535ms/step - loss: 0.3260 - accuracy: 0.8964 - val_loss: 3.1235 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 36s 523ms/step - loss: 0.2449 - accuracy: 0.9313 - val_loss: 3.2108 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 36s 526ms/step - loss: 0.2243 - accuracy: 0.9363 - val_loss: 3.2822 - val_accuracy: 0.2668\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 29s - loss: 0.3262 - accuracy: 0.8964WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1470s vs `on_train_batch_end` time: 0.5724s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1470s vs `on_train_batch_end` time: 0.5724s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 58s 588ms/step - loss: 0.6987 - accuracy: 0.7573 - val_loss: 2.7752 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 38s 536ms/step - loss: 0.6009 - accuracy: 0.7669 - val_loss: 2.9616 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 37s 542ms/step - loss: 0.3535 - accuracy: 0.8749 - val_loss: 3.6924 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 36s 528ms/step - loss: 0.4213 - accuracy: 0.8413 - val_loss: 3.6046 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 36s 527ms/step - loss: 0.3910 - accuracy: 0.8708 - val_loss: 4.3064 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 35s 526ms/step - loss: 0.1948 - accuracy: 0.9331 - val_loss: 4.5002 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 38s 511ms/step - loss: 0.1685 - accuracy: 0.9419 - val_loss: 5.1116 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 38s 529ms/step - loss: 0.3015 - accuracy: 0.8927 - val_loss: 5.2567 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 34s 534ms/step - loss: 0.1966 - accuracy: 0.9362 - val_loss: 5.1481 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 35s 532ms/step - loss: 0.2018 - accuracy: 0.9341 - val_loss: 5.9561 - val_accuracy: 0.2668\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity90.h5\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay90.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 30s - loss: 0.2502 - accuracy: 0.9176WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1442s vs `on_train_batch_end` time: 0.5998s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1442s vs `on_train_batch_end` time: 0.5998s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 57s 602ms/step - loss: 0.2990 - accuracy: 0.9059 - val_loss: 5.7268 - val_accuracy: 0.3049\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 34s 520ms/step - loss: 0.0743 - accuracy: 0.9711 - val_loss: 4.9653 - val_accuracy: 0.3593\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 34s 528ms/step - loss: 0.0287 - accuracy: 0.9939 - val_loss: 4.6273 - val_accuracy: 0.3666\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 36s 543ms/step - loss: 0.0315 - accuracy: 0.9904 - val_loss: 2.8592 - val_accuracy: 0.5045\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 35s 529ms/step - loss: 0.0204 - accuracy: 0.9947 - val_loss: 2.1644 - val_accuracy: 0.5971\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 36s 510ms/step - loss: 0.1096 - accuracy: 0.9640 - val_loss: 4.4119 - val_accuracy: 0.4828\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 35s 533ms/step - loss: 0.0398 - accuracy: 0.9869 - val_loss: 2.4177 - val_accuracy: 0.6171\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 32s 517ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 2.5679 - val_accuracy: 0.5880\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 35s 528ms/step - loss: 0.0316 - accuracy: 0.9892 - val_loss: 1.9061 - val_accuracy: 0.6606\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 36s 522ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 1.8267 - val_accuracy: 0.6842\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 29s - loss: 0.0393 - accuracy: 0.9829WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1486s vs `on_train_batch_end` time: 0.5745s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1486s vs `on_train_batch_end` time: 0.5745s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 58s 598ms/step - loss: 0.0890 - accuracy: 0.9671 - val_loss: 4.9899 - val_accuracy: 0.4719\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 38s 526ms/step - loss: 0.1947 - accuracy: 0.9403 - val_loss: 6.2481 - val_accuracy: 0.4846\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 37s 536ms/step - loss: 0.1346 - accuracy: 0.9469 - val_loss: 6.2936 - val_accuracy: 0.5281\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 34s 529ms/step - loss: 0.1248 - accuracy: 0.9618 - val_loss: 11.1783 - val_accuracy: 0.3848\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 37s 524ms/step - loss: 0.0678 - accuracy: 0.9746 - val_loss: 6.8088 - val_accuracy: 0.4592\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 35s 518ms/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 10.8093 - val_accuracy: 0.3793\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 34s 527ms/step - loss: 0.0462 - accuracy: 0.9859 - val_loss: 6.6752 - val_accuracy: 0.5082\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 34s 526ms/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 10.7081 - val_accuracy: 0.4828\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 37s 546ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 7.0628 - val_accuracy: 0.4791\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 37s 521ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 5.9734 - val_accuracy: 0.5463\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity50.h5\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay50.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 33s - loss: 2.3118 - accuracy: 0.5120WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1487s vs `on_train_batch_end` time: 0.6571s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1487s vs `on_train_batch_end` time: 0.6571s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 58s 612ms/step - loss: 1.4717 - accuracy: 0.6168 - val_loss: 4.1522 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 39s 530ms/step - loss: 0.3961 - accuracy: 0.8595 - val_loss: 4.3703 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 37s 513ms/step - loss: 0.1990 - accuracy: 0.9403 - val_loss: 4.8923 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 36s 542ms/step - loss: 0.0880 - accuracy: 0.9787 - val_loss: 4.9811 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 38s 530ms/step - loss: 0.1161 - accuracy: 0.9629 - val_loss: 5.0804 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 37s 525ms/step - loss: 0.1254 - accuracy: 0.9594 - val_loss: 5.2594 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 36s 541ms/step - loss: 0.0886 - accuracy: 0.9711 - val_loss: 5.3527 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 36s 533ms/step - loss: 0.0727 - accuracy: 0.9755 - val_loss: 5.5317 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 37s 544ms/step - loss: 0.0576 - accuracy: 0.9815 - val_loss: 5.9075 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 37s 524ms/step - loss: 0.0405 - accuracy: 0.9905 - val_loss: 6.0704 - val_accuracy: 0.2668\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 29s - loss: 0.1251 - accuracy: 0.9587WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1488s vs `on_train_batch_end` time: 0.5879s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1488s vs `on_train_batch_end` time: 0.5879s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 60s 596ms/step - loss: 0.2907 - accuracy: 0.9019 - val_loss: 5.8156 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 37s 518ms/step - loss: 0.3132 - accuracy: 0.8880 - val_loss: 5.4414 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 34s 530ms/step - loss: 0.1103 - accuracy: 0.9699 - val_loss: 6.0225 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 34s 528ms/step - loss: 0.1993 - accuracy: 0.9299 - val_loss: 5.1587 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 31s 496ms/step - loss: 0.1458 - accuracy: 0.9495 - val_loss: 5.2064 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 34s 523ms/step - loss: 0.1505 - accuracy: 0.9491 - val_loss: 5.3006 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 33s 530ms/step - loss: 0.1024 - accuracy: 0.9615 - val_loss: 6.1317 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 35s 551ms/step - loss: 0.0959 - accuracy: 0.9659 - val_loss: 6.1910 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 36s 534ms/step - loss: 0.0617 - accuracy: 0.9801 - val_loss: 5.9346 - val_accuracy: 0.2795\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 39s 532ms/step - loss: 0.0539 - accuracy: 0.9822 - val_loss: 5.1897 - val_accuracy: 0.3013\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity75.h5\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay75.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 33s - loss: 3.1624 - accuracy: 0.3177WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1472s vs `on_train_batch_end` time: 0.6667s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1472s vs `on_train_batch_end` time: 0.6667s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 61s 621ms/step - loss: 2.5697 - accuracy: 0.3578 - val_loss: 3.0008 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 38s 520ms/step - loss: 1.0176 - accuracy: 0.6212 - val_loss: 2.7795 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 36s 523ms/step - loss: 0.7897 - accuracy: 0.7218 - val_loss: 2.7164 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 35s 520ms/step - loss: 0.6019 - accuracy: 0.7827 - val_loss: 2.7294 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 34s 527ms/step - loss: 0.4742 - accuracy: 0.8437 - val_loss: 2.7758 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 33s 537ms/step - loss: 0.3768 - accuracy: 0.8864 - val_loss: 2.8305 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 38s 528ms/step - loss: 0.3465 - accuracy: 0.8922 - val_loss: 2.8924 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 36s 525ms/step - loss: 0.2887 - accuracy: 0.9048 - val_loss: 2.9658 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 37s 530ms/step - loss: 0.2544 - accuracy: 0.9249 - val_loss: 3.0392 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 32s 527ms/step - loss: 0.2395 - accuracy: 0.9218 - val_loss: 3.1512 - val_accuracy: 0.2668\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 29s - loss: 0.7313 - accuracy: 0.7759WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1499s vs `on_train_batch_end` time: 0.5798s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1499s vs `on_train_batch_end` time: 0.5798s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 57s 610ms/step - loss: 1.0107 - accuracy: 0.6699 - val_loss: 2.3222 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 36s 529ms/step - loss: 0.6749 - accuracy: 0.7484 - val_loss: 2.6017 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 33s 528ms/step - loss: 0.4234 - accuracy: 0.8473 - val_loss: 3.1961 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 35s 531ms/step - loss: 0.4384 - accuracy: 0.8337 - val_loss: 3.2069 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 37s 532ms/step - loss: 0.4121 - accuracy: 0.8581 - val_loss: 3.6333 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 34s 526ms/step - loss: 0.3055 - accuracy: 0.8874 - val_loss: 4.0033 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 37s 516ms/step - loss: 0.2575 - accuracy: 0.9084 - val_loss: 4.0617 - val_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 33s 524ms/step - loss: 0.3848 - accuracy: 0.8664 - val_loss: 4.5516 - val_accuracy: 0.2668\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 36s 534ms/step - loss: 0.3181 - accuracy: 0.8790 - val_loss: 5.2699 - val_accuracy: 0.2668\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 39s 544ms/step - loss: 0.2465 - accuracy: 0.9166 - val_loss: 5.6638 - val_accuracy: 0.2668\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity90.h5\n",
      "saved flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay90.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 45s - loss: 0.6166 - accuracy: 0.7677WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2374s vs `on_train_batch_end` time: 0.8806s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2374s vs `on_train_batch_end` time: 0.8806s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 83s 881ms/step - loss: 0.5043 - accuracy: 0.8191 - val_loss: 1.3990 - val_accuracy: 0.5681\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 757ms/step - loss: 0.1648 - accuracy: 0.9422 - val_loss: 1.4017 - val_accuracy: 0.6116\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 44s 756ms/step - loss: 0.0570 - accuracy: 0.9838 - val_loss: 1.2777 - val_accuracy: 0.6697\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 44s 752ms/step - loss: 0.0652 - accuracy: 0.9790 - val_loss: 1.2270 - val_accuracy: 0.7024\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 47s 758ms/step - loss: 0.0795 - accuracy: 0.9724 - val_loss: 1.3802 - val_accuracy: 0.6897\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 44s 755ms/step - loss: 0.0361 - accuracy: 0.9873 - val_loss: 1.3104 - val_accuracy: 0.6897\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 44s 765ms/step - loss: 0.0867 - accuracy: 0.9699 - val_loss: 1.4287 - val_accuracy: 0.6969\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 45s 754ms/step - loss: 0.0515 - accuracy: 0.9781 - val_loss: 1.5552 - val_accuracy: 0.6788\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 45s 755ms/step - loss: 0.0403 - accuracy: 0.9858 - val_loss: 1.2699 - val_accuracy: 0.7132\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 45s 762ms/step - loss: 0.0399 - accuracy: 0.9896 - val_loss: 1.4649 - val_accuracy: 0.6806\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 44s - loss: 0.0529 - accuracy: 0.9829WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2418s vs `on_train_batch_end` time: 0.8618s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2418s vs `on_train_batch_end` time: 0.8618s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 80s 876ms/step - loss: 0.0676 - accuracy: 0.9755 - val_loss: 2.4087 - val_accuracy: 0.6407\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 748ms/step - loss: 0.1883 - accuracy: 0.9379 - val_loss: 2.8664 - val_accuracy: 0.5227\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 47s 754ms/step - loss: 0.1023 - accuracy: 0.9615 - val_loss: 1.8636 - val_accuracy: 0.6860\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 46s 763ms/step - loss: 0.0553 - accuracy: 0.9829 - val_loss: 1.5725 - val_accuracy: 0.6878\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 44s 747ms/step - loss: 0.0418 - accuracy: 0.9849 - val_loss: 1.8210 - val_accuracy: 0.6479\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 42s 750ms/step - loss: 0.0264 - accuracy: 0.9902 - val_loss: 2.1850 - val_accuracy: 0.6334\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 45s 740ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 1.6984 - val_accuracy: 0.7042\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 43s 747ms/step - loss: 0.1557 - accuracy: 0.9549 - val_loss: 2.4759 - val_accuracy: 0.6134\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 46s 737ms/step - loss: 0.1333 - accuracy: 0.9564 - val_loss: 1.8728 - val_accuracy: 0.6588\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 42s 753ms/step - loss: 0.0674 - accuracy: 0.9795 - val_loss: 1.9439 - val_accuracy: 0.6134\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_ConstantSparsity50.h5\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay50.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 46s - loss: 1.5025 - accuracy: 0.3921WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2426s vs `on_train_batch_end` time: 0.8991s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2426s vs `on_train_batch_end` time: 0.8991s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 86s 885ms/step - loss: 1.2793 - accuracy: 0.4828 - val_loss: 1.8307 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 43s 752ms/step - loss: 0.8197 - accuracy: 0.6885 - val_loss: 1.8442 - val_accuracy: 0.2722\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 45s 755ms/step - loss: 0.5812 - accuracy: 0.8068 - val_loss: 1.8212 - val_accuracy: 0.3303\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 45s 752ms/step - loss: 0.3428 - accuracy: 0.9033 - val_loss: 1.6319 - val_accuracy: 0.4283\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 44s 768ms/step - loss: 0.2346 - accuracy: 0.9372 - val_loss: 1.2492 - val_accuracy: 0.5554\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 45s 752ms/step - loss: 0.1717 - accuracy: 0.9525 - val_loss: 1.3095 - val_accuracy: 0.5681\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 45s 765ms/step - loss: 0.1388 - accuracy: 0.9616 - val_loss: 1.3319 - val_accuracy: 0.5971\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 41s 729ms/step - loss: 0.1303 - accuracy: 0.9603 - val_loss: 1.5988 - val_accuracy: 0.5735\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 44s 772ms/step - loss: 0.1060 - accuracy: 0.9700 - val_loss: 1.5044 - val_accuracy: 0.6279\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 48s 771ms/step - loss: 0.0905 - accuracy: 0.9749 - val_loss: 1.2676 - val_accuracy: 0.6407\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 45s - loss: 0.1165 - accuracy: 0.9650WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2408s vs `on_train_batch_end` time: 0.8829s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2408s vs `on_train_batch_end` time: 0.8829s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 79s 866ms/step - loss: 0.2886 - accuracy: 0.9080 - val_loss: 1.7640 - val_accuracy: 0.6225\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 44s 753ms/step - loss: 0.3052 - accuracy: 0.8943 - val_loss: 2.2631 - val_accuracy: 0.5572\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 44s 757ms/step - loss: 0.1643 - accuracy: 0.9427 - val_loss: 1.4238 - val_accuracy: 0.6642\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 44s 759ms/step - loss: 0.2287 - accuracy: 0.9237 - val_loss: 2.2463 - val_accuracy: 0.6062\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 45s 754ms/step - loss: 0.1698 - accuracy: 0.9450 - val_loss: 2.0099 - val_accuracy: 0.6171\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 42s 748ms/step - loss: 0.0825 - accuracy: 0.9719 - val_loss: 1.8003 - val_accuracy: 0.6715\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 46s 746ms/step - loss: 0.1019 - accuracy: 0.9668 - val_loss: 2.4999 - val_accuracy: 0.5009\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 45s 769ms/step - loss: 0.0778 - accuracy: 0.9724 - val_loss: 1.7715 - val_accuracy: 0.6062\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 45s 753ms/step - loss: 0.1492 - accuracy: 0.9552 - val_loss: 2.5225 - val_accuracy: 0.5917\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 43s 742ms/step - loss: 0.1996 - accuracy: 0.9269 - val_loss: 1.6538 - val_accuracy: 0.6661\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_ConstantSparsity75.h5\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay75.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 49s - loss: 1.7900 - accuracy: 0.3077WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2492s vs `on_train_batch_end` time: 0.9607s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2492s vs `on_train_batch_end` time: 0.9607s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 86s 904ms/step - loss: 1.6580 - accuracy: 0.3356 - val_loss: 2.7560 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 760ms/step - loss: 1.4205 - accuracy: 0.4635 - val_loss: 2.1627 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 41s 751ms/step - loss: 1.3184 - accuracy: 0.4984 - val_loss: 1.8337 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 47s 765ms/step - loss: 1.2196 - accuracy: 0.5328 - val_loss: 1.7415 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 48s 773ms/step - loss: 1.1610 - accuracy: 0.5285 - val_loss: 1.7682 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 46s 775ms/step - loss: 1.0689 - accuracy: 0.5890 - val_loss: 1.5993 - val_accuracy: 0.3158\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 44s 759ms/step - loss: 1.0205 - accuracy: 0.5818 - val_loss: 1.6185 - val_accuracy: 0.3394\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 47s 768ms/step - loss: 0.9683 - accuracy: 0.6053 - val_loss: 1.3881 - val_accuracy: 0.4374\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 47s 768ms/step - loss: 0.9703 - accuracy: 0.5842 - val_loss: 1.6128 - val_accuracy: 0.4156\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 42s 752ms/step - loss: 0.9247 - accuracy: 0.5987 - val_loss: 1.8535 - val_accuracy: 0.3122\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 46s - loss: 1.0264 - accuracy: 0.6078WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2464s vs `on_train_batch_end` time: 0.8976s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2464s vs `on_train_batch_end` time: 0.8976s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 82s 883ms/step - loss: 1.0942 - accuracy: 0.5599 - val_loss: 3.1307 - val_accuracy: 0.3902\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 765ms/step - loss: 0.8804 - accuracy: 0.6264 - val_loss: 1.6099 - val_accuracy: 0.5318\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 44s 758ms/step - loss: 0.6865 - accuracy: 0.7426 - val_loss: 1.8884 - val_accuracy: 0.5372\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 44s 750ms/step - loss: 0.5445 - accuracy: 0.7860 - val_loss: 2.6163 - val_accuracy: 0.4809\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 45s 764ms/step - loss: 0.3880 - accuracy: 0.8631 - val_loss: 2.0944 - val_accuracy: 0.5681\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 47s 764ms/step - loss: 0.2648 - accuracy: 0.9090 - val_loss: 2.0900 - val_accuracy: 0.5245\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 43s 762ms/step - loss: 0.2583 - accuracy: 0.9021 - val_loss: 3.3709 - val_accuracy: 0.4265\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 42s 769ms/step - loss: 0.2079 - accuracy: 0.9358 - val_loss: 1.7397 - val_accuracy: 0.6425\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 47s 778ms/step - loss: 0.1751 - accuracy: 0.9406 - val_loss: 1.8397 - val_accuracy: 0.5771\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 45s 757ms/step - loss: 0.2342 - accuracy: 0.9213 - val_loss: 2.3114 - val_accuracy: 0.6171\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_ConstantSparsity90.h5\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay90.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 47s - loss: 0.8524 - accuracy: 0.7610WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2400s vs `on_train_batch_end` time: 0.9145s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2400s vs `on_train_batch_end` time: 0.9145s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 78s 889ms/step - loss: 0.6163 - accuracy: 0.8103 - val_loss: 1.6005 - val_accuracy: 0.4864\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 47s 768ms/step - loss: 0.1599 - accuracy: 0.9525 - val_loss: 1.4613 - val_accuracy: 0.5626\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 43s 751ms/step - loss: 0.0777 - accuracy: 0.9757 - val_loss: 1.3846 - val_accuracy: 0.6316\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 43s 748ms/step - loss: 0.0483 - accuracy: 0.9868 - val_loss: 1.1165 - val_accuracy: 0.6842\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 46s 764ms/step - loss: 0.0478 - accuracy: 0.9861 - val_loss: 1.2631 - val_accuracy: 0.6788\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 48s 760ms/step - loss: 0.0604 - accuracy: 0.9830 - val_loss: 1.8133 - val_accuracy: 0.5808\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 41s 743ms/step - loss: 0.0416 - accuracy: 0.9881 - val_loss: 1.4431 - val_accuracy: 0.6897\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 47s 759ms/step - loss: 0.0428 - accuracy: 0.9885 - val_loss: 1.6794 - val_accuracy: 0.6479\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 45s 771ms/step - loss: 0.0694 - accuracy: 0.9781 - val_loss: 1.6884 - val_accuracy: 0.6570\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 46s 759ms/step - loss: 0.0509 - accuracy: 0.9849 - val_loss: 1.4535 - val_accuracy: 0.6697\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 45s - loss: 0.0325 - accuracy: 0.9842WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2492s vs `on_train_batch_end` time: 0.8820s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2492s vs `on_train_batch_end` time: 0.8820s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 81s 872ms/step - loss: 0.0742 - accuracy: 0.9724 - val_loss: 1.9216 - val_accuracy: 0.6606\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 49s 769ms/step - loss: 0.1041 - accuracy: 0.9699 - val_loss: 1.8954 - val_accuracy: 0.6425\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 48s 750ms/step - loss: 0.1314 - accuracy: 0.9598 - val_loss: 1.8042 - val_accuracy: 0.6842\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 45s 753ms/step - loss: 0.0702 - accuracy: 0.9761 - val_loss: 1.6981 - val_accuracy: 0.6806\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 46s 765ms/step - loss: 0.0781 - accuracy: 0.9749 - val_loss: 2.2214 - val_accuracy: 0.5862\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 42s 761ms/step - loss: 0.0838 - accuracy: 0.9742 - val_loss: 2.3743 - val_accuracy: 0.6261\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 45s 758ms/step - loss: 0.0351 - accuracy: 0.9881 - val_loss: 1.6249 - val_accuracy: 0.6951\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 45s 770ms/step - loss: 0.0626 - accuracy: 0.9818 - val_loss: 2.5074 - val_accuracy: 0.5771\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 47s 770ms/step - loss: 0.0918 - accuracy: 0.9701 - val_loss: 2.2226 - val_accuracy: 0.6407\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 42s 760ms/step - loss: 0.0553 - accuracy: 0.9853 - val_loss: 1.6204 - val_accuracy: 0.6534\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity50.h5\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay50.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 50s - loss: 1.5877 - accuracy: 0.3658WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2451s vs `on_train_batch_end` time: 0.9800s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2451s vs `on_train_batch_end` time: 0.9800s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 86s 904ms/step - loss: 1.2873 - accuracy: 0.4884 - val_loss: 1.8194 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 49s 782ms/step - loss: 0.8221 - accuracy: 0.7076 - val_loss: 1.9122 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 48s 757ms/step - loss: 0.5850 - accuracy: 0.8096 - val_loss: 1.8176 - val_accuracy: 0.2922\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 43s 767ms/step - loss: 0.3702 - accuracy: 0.8996 - val_loss: 1.3227 - val_accuracy: 0.4846\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 45s 739ms/step - loss: 0.2879 - accuracy: 0.9202 - val_loss: 1.2966 - val_accuracy: 0.5354\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 42s 760ms/step - loss: 0.2363 - accuracy: 0.9333 - val_loss: 1.0902 - val_accuracy: 0.5808\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 47s 760ms/step - loss: 0.1639 - accuracy: 0.9573 - val_loss: 1.2420 - val_accuracy: 0.5808\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 48s 785ms/step - loss: 0.1382 - accuracy: 0.9648 - val_loss: 1.1264 - val_accuracy: 0.6116\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 43s 758ms/step - loss: 0.1106 - accuracy: 0.9693 - val_loss: 1.2684 - val_accuracy: 0.6352\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 47s 753ms/step - loss: 0.1166 - accuracy: 0.9636 - val_loss: 1.3684 - val_accuracy: 0.6025\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 46s - loss: 0.1078 - accuracy: 0.9689WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2404s vs `on_train_batch_end` time: 0.8902s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2404s vs `on_train_batch_end` time: 0.8902s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 82s 873ms/step - loss: 0.2153 - accuracy: 0.9301 - val_loss: 2.4173 - val_accuracy: 0.5644\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 47s 754ms/step - loss: 0.3196 - accuracy: 0.8997 - val_loss: 1.7740 - val_accuracy: 0.6352\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 44s 757ms/step - loss: 0.2157 - accuracy: 0.9305 - val_loss: 1.6498 - val_accuracy: 0.6388\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 45s 758ms/step - loss: 0.1482 - accuracy: 0.9463 - val_loss: 1.6274 - val_accuracy: 0.6225\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 46s 765ms/step - loss: 0.2197 - accuracy: 0.9281 - val_loss: 1.6120 - val_accuracy: 0.6134\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 43s 758ms/step - loss: 0.1910 - accuracy: 0.9358 - val_loss: 1.7658 - val_accuracy: 0.6298\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 42s 742ms/step - loss: 0.1251 - accuracy: 0.9541 - val_loss: 1.8327 - val_accuracy: 0.6588\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 48s 766ms/step - loss: 0.1510 - accuracy: 0.9527 - val_loss: 2.3351 - val_accuracy: 0.5989\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 42s 751ms/step - loss: 0.1181 - accuracy: 0.9613 - val_loss: 1.6379 - val_accuracy: 0.6407\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 45s 757ms/step - loss: 0.0896 - accuracy: 0.9742 - val_loss: 2.1552 - val_accuracy: 0.5535\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity75.h5\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay75.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 46s - loss: 1.7451 - accuracy: 0.2647WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2458s vs `on_train_batch_end` time: 0.8952s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2458s vs `on_train_batch_end` time: 0.8952s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 80s 865ms/step - loss: 1.6654 - accuracy: 0.2989 - val_loss: 2.7387 - val_accuracy: 0.2668\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 45s 773ms/step - loss: 1.5503 - accuracy: 0.3850 - val_loss: 2.1709 - val_accuracy: 0.2668\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 45s 758ms/step - loss: 1.5051 - accuracy: 0.4404 - val_loss: 1.8549 - val_accuracy: 0.2668\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 46s 759ms/step - loss: 1.4487 - accuracy: 0.4825 - val_loss: 1.6975 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 43s 760ms/step - loss: 1.4075 - accuracy: 0.5006 - val_loss: 1.6277 - val_accuracy: 0.2668\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 47s 757ms/step - loss: 1.3677 - accuracy: 0.5190 - val_loss: 1.6101 - val_accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 45s 761ms/step - loss: 1.3283 - accuracy: 0.5158 - val_loss: 1.5590 - val_accuracy: 0.3049\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 46s 761ms/step - loss: 1.2703 - accuracy: 0.5472 - val_loss: 1.4237 - val_accuracy: 0.4682\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 48s 762ms/step - loss: 1.2364 - accuracy: 0.5613 - val_loss: 1.3524 - val_accuracy: 0.4882\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 47s 760ms/step - loss: 1.2249 - accuracy: 0.5475 - val_loss: 1.3705 - val_accuracy: 0.4955\n",
      "Epoch 1/10\n",
      " 6/41 [===>..........................] - ETA: 45s - loss: 1.2072 - accuracy: 0.5233WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2475s vs `on_train_batch_end` time: 0.8696s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2475s vs `on_train_batch_end` time: 0.8696s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 80s 875ms/step - loss: 1.1534 - accuracy: 0.5191 - val_loss: 3.2734 - val_accuracy: 0.3557\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 752ms/step - loss: 0.8468 - accuracy: 0.6466 - val_loss: 3.8845 - val_accuracy: 0.4083\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 44s 748ms/step - loss: 0.7729 - accuracy: 0.6852 - val_loss: 2.2636 - val_accuracy: 0.5245\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 47s 757ms/step - loss: 0.5431 - accuracy: 0.7885 - val_loss: 2.2428 - val_accuracy: 0.5735\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 47s 757ms/step - loss: 0.3797 - accuracy: 0.8592 - val_loss: 2.4718 - val_accuracy: 0.5299\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 46s 752ms/step - loss: 0.2857 - accuracy: 0.8950 - val_loss: 3.1802 - val_accuracy: 0.5445\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 45s 767ms/step - loss: 0.3924 - accuracy: 0.8535 - val_loss: 2.2447 - val_accuracy: 0.5989\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 45s 768ms/step - loss: 0.3030 - accuracy: 0.8900 - val_loss: 1.7102 - val_accuracy: 0.6552\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 43s 767ms/step - loss: 0.2173 - accuracy: 0.9320 - val_loss: 1.9673 - val_accuracy: 0.5608\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 41s 766ms/step - loss: 0.1867 - accuracy: 0.9393 - val_loss: 2.0974 - val_accuracy: 0.5608\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity90.h5\n",
      "saved flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay90.h5\n"
     ]
    }
   ],
   "source": [
    "prune_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)\n",
    "\n",
    "prune_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)\n",
    "\n",
    "# ---------- EfficentNet ---------\n",
    "\n",
    "prune_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)\n",
    "\n",
    "prune_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128.h5', \n",
    "            ds_train=flowers_datasets[0], \n",
    "            ds_validation=flowers_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 24s - loss: 0.5572 - accuracy: 0.8424WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4165s vs `on_train_batch_end` time: 1.6982s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4165s vs `on_train_batch_end` time: 1.6982s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 57s 2s/step - loss: 0.6024 - accuracy: 0.8292 - val_loss: 1.5216 - val_accuracy: 0.3835\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.2121 - accuracy: 0.9311 - val_loss: 3.6439 - val_accuracy: 0.3835\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1485 - accuracy: 0.9434 - val_loss: 1.2939 - val_accuracy: 0.4737\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0854 - accuracy: 0.9729 - val_loss: 2.4903 - val_accuracy: 0.3910\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0522 - accuracy: 0.9851 - val_loss: 2.3708 - val_accuracy: 0.4286\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0417 - accuracy: 0.9893 - val_loss: 3.2931 - val_accuracy: 0.4135\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0324 - accuracy: 0.9922 - val_loss: 2.1208 - val_accuracy: 0.4511\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0534 - accuracy: 0.9806 - val_loss: 2.2412 - val_accuracy: 0.4887\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0478 - accuracy: 0.9801 - val_loss: 2.0428 - val_accuracy: 0.4586\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0282 - accuracy: 0.9924 - val_loss: 1.3971 - val_accuracy: 0.5789\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 24s - loss: 0.0244 - accuracy: 0.9973WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4130s vs `on_train_batch_end` time: 1.7090s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4130s vs `on_train_batch_end` time: 1.7090s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 58s 2s/step - loss: 0.0678 - accuracy: 0.9815 - val_loss: 2.5701 - val_accuracy: 0.5263\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1952 - accuracy: 0.9320 - val_loss: 23.1212 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1899 - accuracy: 0.9389 - val_loss: 4.3996 - val_accuracy: 0.5414\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1332 - accuracy: 0.9534 - val_loss: 15.7003 - val_accuracy: 0.5414\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0732 - accuracy: 0.9726 - val_loss: 16.7299 - val_accuracy: 0.4135\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0321 - accuracy: 0.9858 - val_loss: 10.0233 - val_accuracy: 0.4436\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0170 - accuracy: 0.9955 - val_loss: 13.7104 - val_accuracy: 0.4737\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 14.7073 - val_accuracy: 0.4436\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 10.8723 - val_accuracy: 0.4662\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0083 - accuracy: 0.9991 - val_loss: 7.2661 - val_accuracy: 0.5639\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity50.h5\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay50.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 26s - loss: 1.4813 - accuracy: 0.5956WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4185s vs `on_train_batch_end` time: 1.7910s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4185s vs `on_train_batch_end` time: 1.7910s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 59s 2s/step - loss: 1.2926 - accuracy: 0.6172 - val_loss: 1.6039 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.3628 - accuracy: 0.8666 - val_loss: 1.6120 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2315 - accuracy: 0.9360 - val_loss: 1.7327 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1236 - accuracy: 0.9652 - val_loss: 1.8903 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0639 - accuracy: 0.9863 - val_loss: 2.0397 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0328 - accuracy: 0.9965 - val_loss: 2.0226 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0460 - accuracy: 0.9893 - val_loss: 2.1514 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0308 - accuracy: 0.9945 - val_loss: 2.2408 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0280 - accuracy: 0.9942 - val_loss: 2.2458 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0345 - accuracy: 0.9909 - val_loss: 2.3254 - val_accuracy: 0.3308\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 24s - loss: 0.1425 - accuracy: 0.9584WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4153s vs `on_train_batch_end` time: 1.6686s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4153s vs `on_train_batch_end` time: 1.6686s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 55s 2s/step - loss: 0.2093 - accuracy: 0.9336 - val_loss: 3.0522 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1998 - accuracy: 0.9326 - val_loss: 3.4831 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1737 - accuracy: 0.9285 - val_loss: 4.7815 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1071 - accuracy: 0.9643 - val_loss: 3.5476 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1169 - accuracy: 0.9590 - val_loss: 4.0583 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0825 - accuracy: 0.9709 - val_loss: 3.6323 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0418 - accuracy: 0.9861 - val_loss: 4.1617 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0492 - accuracy: 0.9861 - val_loss: 3.7798 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1287 - accuracy: 0.9587 - val_loss: 4.4054 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1377 - accuracy: 0.9429 - val_loss: 3.9120 - val_accuracy: 0.3609\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity75.h5\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay75.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 25s - loss: 1.6865 - accuracy: 0.3885WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4243s vs `on_train_batch_end` time: 1.7258s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4243s vs `on_train_batch_end` time: 1.7258s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 57s 2s/step - loss: 1.3488 - accuracy: 0.4689 - val_loss: 1.1291 - val_accuracy: 0.3383\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.6441 - accuracy: 0.7545 - val_loss: 1.1281 - val_accuracy: 0.3383\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.4082 - accuracy: 0.8684 - val_loss: 1.1327 - val_accuracy: 0.3383\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2802 - accuracy: 0.9268 - val_loss: 1.1403 - val_accuracy: 0.3383\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1814 - accuracy: 0.9530 - val_loss: 1.1458 - val_accuracy: 0.3383\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0886 - accuracy: 0.9865 - val_loss: 1.1461 - val_accuracy: 0.3383\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1144 - accuracy: 0.9705 - val_loss: 1.1609 - val_accuracy: 0.3383\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1476 - accuracy: 0.9569 - val_loss: 1.1766 - val_accuracy: 0.3383\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1390 - accuracy: 0.9559 - val_loss: 1.1889 - val_accuracy: 0.3383\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1114 - accuracy: 0.9691 - val_loss: 1.1854 - val_accuracy: 0.3383\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 24s - loss: 0.3254 - accuracy: 0.9016WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4148s vs `on_train_batch_end` time: 1.6692s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4148s vs `on_train_batch_end` time: 1.6692s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 55s 2s/step - loss: 0.4811 - accuracy: 0.8289 - val_loss: 1.2144 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.5017 - accuracy: 0.8021 - val_loss: 1.1702 - val_accuracy: 0.3383\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.3094 - accuracy: 0.8944 - val_loss: 1.2844 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1548 - accuracy: 0.9433 - val_loss: 1.4558 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.1642 - accuracy: 0.9359 - val_loss: 1.4239 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2216 - accuracy: 0.9147 - val_loss: 1.4014 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1892 - accuracy: 0.9200 - val_loss: 1.2258 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2549 - accuracy: 0.8998 - val_loss: 1.6472 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2163 - accuracy: 0.9170 - val_loss: 1.6592 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1072 - accuracy: 0.9663 - val_loss: 1.4663 - val_accuracy: 0.3308\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity90.h5\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay90.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 34s - loss: 0.9181 - accuracy: 0.7711WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4325s vs `on_train_batch_end` time: 2.4084s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4325s vs `on_train_batch_end` time: 2.4084s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 56s 2s/step - loss: 0.7780 - accuracy: 0.7949 - val_loss: 1.1334 - val_accuracy: 0.3910\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1804 - accuracy: 0.9416 - val_loss: 1.0840 - val_accuracy: 0.4060\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0850 - accuracy: 0.9711 - val_loss: 1.3201 - val_accuracy: 0.3233\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0217 - accuracy: 0.9995 - val_loss: 1.5509 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.6870 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 1.7050 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0689 - accuracy: 0.9719 - val_loss: 2.0192 - val_accuracy: 0.4135\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0756 - accuracy: 0.9717 - val_loss: 1.8512 - val_accuracy: 0.3534\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0607 - accuracy: 0.9786 - val_loss: 2.1891 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0735 - accuracy: 0.9788 - val_loss: 2.0388 - val_accuracy: 0.3609\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 25s - loss: 0.0685 - accuracy: 0.9806WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4207s vs `on_train_batch_end` time: 1.7626s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4207s vs `on_train_batch_end` time: 1.7626s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 57s 2s/step - loss: 0.1412 - accuracy: 0.9530 - val_loss: 1.7270 - val_accuracy: 0.4361\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1459 - accuracy: 0.9504 - val_loss: 1.9032 - val_accuracy: 0.4361\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0958 - accuracy: 0.9617 - val_loss: 5.6619 - val_accuracy: 0.3910\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0690 - accuracy: 0.9741 - val_loss: 2.2647 - val_accuracy: 0.3835\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0813 - accuracy: 0.9744 - val_loss: 8.7040 - val_accuracy: 0.4662\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0674 - accuracy: 0.9783 - val_loss: 9.7032 - val_accuracy: 0.4135\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0577 - accuracy: 0.9813 - val_loss: 21.7984 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1488 - accuracy: 0.9453 - val_loss: 23.7976 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0873 - accuracy: 0.9676 - val_loss: 19.4523 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0423 - accuracy: 0.9856 - val_loss: 20.7856 - val_accuracy: 0.3308\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity50.h5\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay50.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 25s - loss: 1.7161 - accuracy: 0.5577WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4164s vs `on_train_batch_end` time: 1.7726s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4164s vs `on_train_batch_end` time: 1.7726s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 58s 2s/step - loss: 1.4116 - accuracy: 0.5967 - val_loss: 1.1909 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.4618 - accuracy: 0.8192 - val_loss: 1.2130 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2798 - accuracy: 0.9052 - val_loss: 1.4458 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1627 - accuracy: 0.9554 - val_loss: 1.5053 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0753 - accuracy: 0.9872 - val_loss: 1.4092 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0793 - accuracy: 0.9779 - val_loss: 1.4802 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0594 - accuracy: 0.9881 - val_loss: 1.6697 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0304 - accuracy: 0.9967 - val_loss: 1.7147 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0142 - accuracy: 0.9995 - val_loss: 1.7757 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0800 - accuracy: 0.9738 - val_loss: 1.8377 - val_accuracy: 0.3308\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 24s - loss: 0.1463 - accuracy: 0.9420WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4133s vs `on_train_batch_end` time: 1.6820s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4133s vs `on_train_batch_end` time: 1.6820s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 54s 2s/step - loss: 0.2627 - accuracy: 0.9025 - val_loss: 2.0635 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.3049 - accuracy: 0.8982 - val_loss: 2.3688 - val_accuracy: 0.3759\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1858 - accuracy: 0.9245 - val_loss: 2.3991 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0915 - accuracy: 0.9702 - val_loss: 2.3278 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1278 - accuracy: 0.9607 - val_loss: 3.6762 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0778 - accuracy: 0.9726 - val_loss: 4.6009 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0320 - accuracy: 0.9935 - val_loss: 4.3399 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.0708 - accuracy: 0.9781 - val_loss: 2.4754 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1514 - accuracy: 0.9546 - val_loss: 2.7342 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1472 - accuracy: 0.9396 - val_loss: 2.8314 - val_accuracy: 0.3233\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity75.h5\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay75.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 24s - loss: 1.6406 - accuracy: 0.3660WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4130s vs `on_train_batch_end` time: 1.6642s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4130s vs `on_train_batch_end` time: 1.6642s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 53s 2s/step - loss: 1.3877 - accuracy: 0.4288 - val_loss: 1.1055 - val_accuracy: 0.3383\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.6365 - accuracy: 0.7508 - val_loss: 1.1088 - val_accuracy: 0.3383\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.4780 - accuracy: 0.8362 - val_loss: 1.1159 - val_accuracy: 0.3383\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.3623 - accuracy: 0.8765 - val_loss: 1.1287 - val_accuracy: 0.3383\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2439 - accuracy: 0.9539 - val_loss: 1.1395 - val_accuracy: 0.3383\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1793 - accuracy: 0.9617 - val_loss: 1.1403 - val_accuracy: 0.3383\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1381 - accuracy: 0.9699 - val_loss: 1.1377 - val_accuracy: 0.3383\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1004 - accuracy: 0.9785 - val_loss: 1.1399 - val_accuracy: 0.3383\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.0952 - accuracy: 0.9817 - val_loss: 1.1468 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1167 - accuracy: 0.9700 - val_loss: 1.1569 - val_accuracy: 0.3308\n",
      "Epoch 1/10\n",
      " 6/17 [=========>....................] - ETA: 23s - loss: 0.4785 - accuracy: 0.8336WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4230s vs `on_train_batch_end` time: 1.6257s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4230s vs `on_train_batch_end` time: 1.6257s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 54s 2s/step - loss: 0.5990 - accuracy: 0.7756 - val_loss: 1.1104 - val_accuracy: 0.3308\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.4952 - accuracy: 0.8079 - val_loss: 1.1175 - val_accuracy: 0.3308\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2781 - accuracy: 0.9077 - val_loss: 1.1149 - val_accuracy: 0.3308\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1641 - accuracy: 0.9472 - val_loss: 1.1327 - val_accuracy: 0.3308\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2472 - accuracy: 0.9140 - val_loss: 1.1319 - val_accuracy: 0.3308\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2451 - accuracy: 0.9023 - val_loss: 1.1489 - val_accuracy: 0.3308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.1729 - accuracy: 0.9310 - val_loss: 1.2398 - val_accuracy: 0.3308\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.1632 - accuracy: 0.9411 - val_loss: 1.2836 - val_accuracy: 0.3308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 33s 2s/step - loss: 0.2196 - accuracy: 0.9200 - val_loss: 1.2738 - val_accuracy: 0.3308\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.2689 - accuracy: 0.9009 - val_loss: 1.1488 - val_accuracy: 0.3308\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity90.h5\n",
      "saved beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay90.h5\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_KMeansPlusPlus32.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e78768eb1383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# ---------- EfficentNet ---------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m prune_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_KMeansPlusPlus32.h5', \n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mds_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mds_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a3166338c0d5>\u001b[0m in \u001b[0;36mprune_model\u001b[0;34m(model_path, batch_size, pruning_epochs, ds_train, ds_validation, sparsity)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msparsities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.9/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: beans_models_optimized/EfficentNetB0_beans_model_KMeansPlusPlus32.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "prune_model(model_path='beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)\n",
    "\n",
    "prune_model(model_path='beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)\n",
    "\n",
    "# ---------- EfficentNet ---------\n",
    "\n",
    "prune_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_KMeansPlusPlus32.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_KMeansPlusPlus32.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_KMeansPlusPlus32.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)\n",
    "\n",
    "prune_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_KMeansPlusPlus128.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.5)\n",
    "prune_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_KMeansPlusPlus128.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.75)\n",
    "prune_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_KMeansPlusPlus128.h5', \n",
    "            ds_train=beans_datasets[0], \n",
    "            ds_validation=beans_datasets[1],\n",
    "            batch_size=BATCH_SIZE, \n",
    "            pruning_epochs=PRUNING_EPOCHS,\n",
    "            sparsity=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. weight cluster prunned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90.h5', \n",
    "                     ds_train=flowers_datasets[0], \n",
    "                     ds_validation=flowers_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### beans models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay50.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay75.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_ConstantSparsity90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)\n",
    "\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=32)\n",
    "weight_cluster_model(model_path='beans_models_optimized/EfficentNetB0_beans_model_PolynomialDecay90.h5', \n",
    "                     ds_train=beans_datasets[0], \n",
    "                     ds_validation=beans_datasets[1], \n",
    "                     batch_size=BATCH_SIZE, \n",
    "                     epochs=PRUNING_EPOCHS, \n",
    "                     number_of_clusters=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all models paths\n",
    "model_paths = []\n",
    "import os\n",
    "for file in os.listdir(\"beans_models/\"):\n",
    "    if file.endswith(\".h5\"):\n",
    "        model_paths.append(str(os.path.join(\"beans_models/\", file)))\n",
    "for file in os.listdir(\"beans_models_optimized/\"):\n",
    "    if file.endswith(\".h5\"):\n",
    "        model_paths.append(str(os.path.join(\"beans_models_optimized/\", file)))\n",
    "for file in os.listdir(\"flowers_models/\"):\n",
    "    if file.endswith(\".h5\"):\n",
    "        model_paths.append(str(os.path.join(\"flowers_models/\", file)))\n",
    "for file in os.listdir(\"flowers_models_optimized/\"):\n",
    "    if file.endswith(\".h5\"):\n",
    "        model_paths.append(str(os.path.join(\"flowers_models_optimized/\", file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beans_models/MobileNetV2_beans_model.h5',\n",
       " 'beans_models/EfficentNetB0_beans_model.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity90.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay75.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay50.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay90.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity90.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity75.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay75.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay50.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity50.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity75.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay90.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90.h5',\n",
       " 'beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity50.h5',\n",
       " 'flowers_models/MobileNetV2_flowers_model.h5',\n",
       " 'flowers_models/EfficentNetB0_flowers_model.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay50.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_ConstantSparsity90.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay75.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay50.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity90.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay50.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay75.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity90.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity90.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay90.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay75.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay50.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity75.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity50.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity50.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity75.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity75.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity50.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay90.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay75.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay90.h5',\n",
       " 'flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay75.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_ConstantSparsity50.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_ConstantSparsity75.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity90.h5',\n",
       " 'flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay90.h5']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpnd_a_qrd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpnd_a_qrd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpcxlpw9j4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpcxlpw9j4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp8k2_ebr9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp8k2_ebr9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpc4eyk30l/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpc4eyk30l/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7wliopb2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7wliopb2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_float16_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphmxeki48/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphmxeki48/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16044956 Bytes) saved to: beans_models_optimized/EfficentNetB0_beans_model.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmprn3xitkm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmprn3xitkm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4789504 Bytes) saved to: beans_models_optimized/EfficentNetB0_beans_model_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp3bo0lteu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp3bo0lteu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5160800 Bytes) saved to: beans_models_optimized/EfficentNetB0_beans_model_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpc9vixlp9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpc9vixlp9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp0tc91j8c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp0tc91j8c/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8096720 Bytes) saved to: beans_models_optimized/EfficentNetB0_beans_model_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpm49tol3f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpm49tol3f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkrsfiakx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkrsfiakx/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpc3ffjepa/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpc3ffjepa/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpb193j2ol/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpb193j2ol/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpmj1pr6a4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpmj1pr6a4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjlv5t1os/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjlv5t1os/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpa6h0la9s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpa6h0la9s/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfht6card/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfht6card/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjdd6h6yg/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjdd6h6yg/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpzd39v_9o/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpzd39v_9o/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpbf0jrs78/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpbf0jrs78/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7a8cik_q/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7a8cik_q/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpqr9km3as/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpqr9km3as/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpeh84as54/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpeh84as54/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4hs73gb8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4hs73gb8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp1pjctlgy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp1pjctlgy/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptgkbdntm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptgkbdntm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjwu2q2j9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjwu2q2j9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmps4wf7_a4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmps4wf7_a4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmplct3b678/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmplct3b678/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptz5p24pn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptz5p24pn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpk2oc977v/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpk2oc977v/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphqbo9q03/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphqbo9q03/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp54bonkbk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp54bonkbk/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpp3oeoiyf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpp3oeoiyf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjbs2j5uw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjbs2j5uw/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpb7ohit0u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpb7ohit0u/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptu_c3gd8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptu_c3gd8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4sh4ahrw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4sh4ahrw/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpo0goa65s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpo0goa65s/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpzzx6mq60/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpzzx6mq60/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7_fbq6y0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7_fbq6y0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp5gpjtvl3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp5gpjtvl3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpi6cob3hm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpi6cob3hm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpog2q67ut/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpog2q67ut/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmph18k2n4h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmph18k2n4h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpiz1ig9i3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpiz1ig9i3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfujoyvgp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfujoyvgp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpuu2qghon/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpuu2qghon/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpmuwu_27v/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpmuwu_27v/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpdz2rp85m/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpdz2rp85m/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpp9ds4rm4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpp9ds4rm4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphrp94qtq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphrp94qtq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp2_iiu6u6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp2_iiu6u6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpapu7nghs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpapu7nghs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgyoavt0l/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgyoavt0l/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpu_isu0vu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpu_isu0vu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjhygohsu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjhygohsu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpe9jq3cct/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpe9jq3cct/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4nfzed_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4nfzed_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfns7_1dt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfns7_1dt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpngxbxvje/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpngxbxvje/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpv2rde45u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpv2rde45u/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpvstm7kst/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpvstm7kst/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp9pkrg5gv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp9pkrg5gv/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpsuo2ibyr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpsuo2ibyr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpqy1nfc6u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpqy1nfc6u/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp2yjr_qcd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp2yjr_qcd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgm2y894y/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgm2y894y/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpu8zuv8g4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpu8zuv8g4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpga3td5ij/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpga3td5ij/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpoxkjgzb8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpoxkjgzb8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkcgpmu0k/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkcgpmu0k/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpe64dhojs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpe64dhojs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjq_7y541/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjq_7y541/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphp3cl4ln/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphp3cl4ln/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6yj6u1oq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6yj6u1oq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp43xv0w3s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp43xv0w3s/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgone51rw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgone51rw/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7nbgwr7e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7nbgwr7e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_PolynomialDecay50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp_fejd4pj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp_fejd4pj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6qi2fzts/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6qi2fzts/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpk9ikyjf8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpk9ikyjf8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpvds0ydhx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpvds0ydhx/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpa5ah1ch1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpa5ah1ch1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_ConstantSparsity50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpp2nrzzig/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpp2nrzzig/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphyvq6_0c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphyvq6_0c/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp00rsn0r_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp00rsn0r_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4okusq3a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4okusq3a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphj90t6kx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphj90t6kx/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_ConstantSparsity90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp8dhbz3gw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp8dhbz3gw/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmprev4foxv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmprev4foxv/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpo5ug5tg7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpo5ug5tg7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpl2uan9yj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpl2uan9yj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpsepiiboa/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpsepiiboa/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpnczxg0zb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpnczxg0zb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp40c4butn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp40c4butn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7qufhmoa/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7qufhmoa/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpnux01rc8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpnux01rc8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpys1yrg1e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpys1yrg1e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus128_PolynomialDecay90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpddrt17j5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpddrt17j5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptb5hot2j/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptb5hot2j/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpf75g9i0f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpf75g9i0f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpc9n3bh7x/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpc9n3bh7x/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpd5ln9y7g/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpd5ln9y7g/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_PolynomialDecay90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp8wamxivg/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp8wamxivg/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (8873924 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmprb7mat5i/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmprb7mat5i/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2641872 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp2fghevyv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp2fghevyv/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2848144 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp2vaxh1tz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp2vaxh1tz/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2846896 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmprjvfahsm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmprjvfahsm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4469136 Bytes) saved to: beans_models_optimized/MobileNetV2_beans_model_KMeansPlusPlus32_ConstantSparsity50_float16_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6tzl8ywb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6tzl8ywb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpp4nc_40l/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpp4nc_40l/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpk5ru9_59/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpk5ru9_59/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkbs13l8x/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkbs13l8x/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp1y_7w8zk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp1y_7w8zk/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_float16_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgwwfjboi/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgwwfjboi/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpg1_yd1s2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpg1_yd1s2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp3nacrypo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp3nacrypo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpsnygin5q/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpsnygin5q/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjuwrjco7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjuwrjco7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpwj2jq8jq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpwj2jq8jq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphxaqeheg/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmphxaqeheg/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpzw2l87un/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpzw2l87un/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjms404z2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjms404z2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp78l26duc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp78l26duc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpj_0y2t_i/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpj_0y2t_i/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfefukgwy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfefukgwy/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpegwgj8_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpegwgj8_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmplxhmvn1_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmplxhmvn1_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp_og6m2mt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp_og6m2mt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp_oxslzy8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp_oxslzy8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpai9dn3qz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpai9dn3qz/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6unl0dss/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6unl0dss/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpmy4fsvhr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpmy4fsvhr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpixf_wlys/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpixf_wlys/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_ConstantSparsity75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpz57q4nln/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpz57q4nln/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_ConstantSparsity90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7yb1tnm9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7yb1tnm9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_ConstantSparsity90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6xne8xaj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6xne8xaj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_ConstantSparsity90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4b9lehzt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4b9lehzt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp2frzvn1f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp2frzvn1f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_ConstantSparsity90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp9ir79mz_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp9ir79mz_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6sk4k7cf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6sk4k7cf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpx1nwgixz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpx1nwgixz/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp62da9721/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp62da9721/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpvau_uj2j/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpvau_uj2j/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_PolynomialDecay75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpszzv0e75/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpszzv0e75/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmph7xrqk4a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmph7xrqk4a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp0tt6zysx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp0tt6zysx/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptjy939u0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptjy939u0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpdh9pft5p/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpdh9pft5p/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp96dq_ywj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp96dq_ywj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp0p_ze37v/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp0p_ze37v/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp5u7w3jwc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp5u7w3jwc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpae48j7jg/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpae48j7jg/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpxv41ncua/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpxv41ncua/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkihy7mbd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkihy7mbd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp1ahcop1y/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp1ahcop1y/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpros_ao5f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpros_ao5f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpixw5cjpj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpixw5cjpj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpc66eqcma/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpc66eqcma/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpr1fqwfvn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpr1fqwfvn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpccx3z6f6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpccx3z6f6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpoezanegh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpoezanegh/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptjnldwhw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptjnldwhw/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpv5xm71ha/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpv5xm71ha/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp432378zv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp432378zv/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjzfgjzz4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjzfgjzz4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp5xpkpv10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp5xpkpv10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp_v9bpc52/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp_v9bpc52/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpw7hd3tre/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpw7hd3tre/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptao57a6u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptao57a6u/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpsivuq4g0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpsivuq4g0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpg48sktr0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpg48sktr0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4pwawg1e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4pwawg1e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpzq8speut/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpzq8speut/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpu6i09etp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpu6i09etp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4vl2a0ur/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4vl2a0ur/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpinxy6jaa/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpinxy6jaa/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp3h8bncdb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp3h8bncdb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpasbj6s8w/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpasbj6s8w/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp76pvcf10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp76pvcf10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp66bahs71/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp66bahs71/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpy43pcwjc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpy43pcwjc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgx35hi9g/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgx35hi9g/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpyqe45mnc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpyqe45mnc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpopndobf0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpopndobf0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpskv4yns3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpskv4yns3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmppry6b6yx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmppry6b6yx/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpprovymx0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpprovymx0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp9wvedr9a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp9wvedr9a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpaz81kxii/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpaz81kxii/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpprqkejxu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpprqkejxu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmped8txajj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmped8txajj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpayts2ew2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpayts2ew2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpmemwlt54/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpmemwlt54/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpukxbsx88/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpukxbsx88/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptdgmljz4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmptdgmljz4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpvo8qhhyy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpvo8qhhyy/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp59kxrgdq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp59kxrgdq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpd3w8ymk_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpd3w8ymk_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp934kd2oq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp934kd2oq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpxpsh7gpz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpxpsh7gpz/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpi4_qo1vr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpi4_qo1vr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp144cj0bu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp144cj0bu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmplp196k3n/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmplp196k3n/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfdn7jhay/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfdn7jhay/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpnlfmurc4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpnlfmurc4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7hknyyk5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7hknyyk5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp008qpsh_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp008qpsh_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpqj0jm0vy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpqj0jm0vy/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmplz0fgw21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmplz0fgw21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpsjxfavus/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpsjxfavus/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpcxubf4c5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpcxubf4c5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpwdakt5q4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpwdakt5q4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpqw25i9np/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpqw25i9np/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_PolynomialDecay75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpuzs4ci2v/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpuzs4ci2v/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpz_dh5gcd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpz_dh5gcd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpsyq0b4ps/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpsyq0b4ps/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpibn5jolz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpibn5jolz/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpi848xtti/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpi848xtti/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_PolynomialDecay50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpo01b7k0t/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpo01b7k0t/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpbmpzh_sq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpbmpzh_sq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7c7mflxk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp7c7mflxk/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpt40898io/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpt40898io/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpslht5tfl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpslht5tfl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpselxlxrr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpselxlxrr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpms_x8y90/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpms_x8y90/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpnuxh5ape/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpnuxh5ape/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfvzllbwu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfvzllbwu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp8qragcb7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp8qragcb7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_PolynomialDecay50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp5opq6wys/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp5opq6wys/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgk6a09n_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgk6a09n_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjq8vpvt6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjq8vpvt6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpeylk1141/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpeylk1141/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpcpi_1z8t/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpcpi_1z8t/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6ctq468m/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp6ctq468m/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjh9punz9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpjh9punz9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp8vk0abxu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp8vk0abxu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp66ka4o_i/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp66ka4o_i/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp0uzv0025/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp0uzv0025/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp89ajyzjl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp89ajyzjl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpy758wp6u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpy758wp6u/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfulgt9tc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpfulgt9tc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpiuyesjhq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpiuyesjhq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpi9w4jd4h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpi9w4jd4h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4tqd7iak/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp4tqd7iak/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpecijrgyi/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpecijrgyi/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpn0i427xc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpn0i427xc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp3h8vpfm6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp3h8vpfm6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp5b8no3q6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp5b8no3q6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpus3g9tvu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpus3g9tvu/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpk4a2vcon/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpk4a2vcon/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp15pv4690/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp15pv4690/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmprjqb476v/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmprjqb476v/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpn_79xx81/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpn_79xx81/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_PolynomialDecay90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpme_f61k2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpme_f61k2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp0l3k2ejd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp0l3k2ejd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpqikmntez/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpqikmntez/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpvonzgf51/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpvonzgf51/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpxpdde4tl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpxpdde4tl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus128_ConstantSparsity75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpv5jrxsly/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpv5jrxsly/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpukdz4sgd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpukdz4sgd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp3c5oe4rt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp3c5oe4rt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpyczirts_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpyczirts_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmprlnurvsq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmprlnurvsq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpqjb685to/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpqjb685to/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity75.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpana3uz77/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpana3uz77/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity75_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpb7wkfdrc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpb7wkfdrc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity75_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpoxyqcnkw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpoxyqcnkw/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity75_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpbep2juzi/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpbep2juzi/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus32_ConstantSparsity75_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp2hnpzvni/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp2hnpzvni/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp91kah1sd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp91kah1sd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpr1cjo99l/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpr1cjo99l/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpc6kn4pft/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpc6kn4pft/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity50_full_integer_quantization_integer_io.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkn0n6xch/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkn0n6xch/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (4723808 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_KMeansPlusPlus128_ConstantSparsity50_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgfdaxit_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpgfdaxit_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (16551964 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay90.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkbqujpj8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkbqujpj8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (4916336 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay90_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpu3sg7msn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpu3sg7msn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (5287664 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay90_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp0ys4zjk3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp0ys4zjk3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Failed Full integer quantizatized with integer io TFLite model\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpp_hqqrrf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpp_hqqrrf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 quantizatized TFLite model (8350080 Bytes) saved to: flowers_models_optimized/EfficentNetB0_flowers_model_KMeansPlusPlus32_PolynomialDecay90_float16_quantization.tflite\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpg9ezb9dq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpg9ezb9dq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TFLite model (9381848 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpuqsm2b44/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpuqsm2b44/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic range quantizatized TFLite model (2769648 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_dynamic_rage_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp_u_23b2u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp_u_23b2u/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized TFLite model (2975920 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_full_integer_quantization.tflite\n",
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpr1ote9l2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpr1ote9l2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full integer quantizatized with integer io TFLite model (2974680 Bytes) saved to: flowers_models_optimized/MobileNetV2_flowers_model_ConstantSparsity50_full_integer_quantization_integer_io.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-22-7097d41c5c42>\", line 3, in <module>\n",
      "    model_quantization(model_path=model_path, ds=flowers_datasets[0])\n",
      "  File \"<ipython-input-6-8b0f13698ff5>\", line 63, in model_quantization\n",
      "    tflite_model_quant = converter.convert()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 829, in convert\n",
      "    saved_model_convert_result = self._convert_as_saved_model()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 782, in _convert_as_saved_model\n",
      "    self._keras_model.save(temp_dir, save_format=\"tf\")\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 2001, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\", line 156, in save_model\n",
      "    saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save.py\", line 89, in save\n",
      "    save_lib.save(model, filepath, signatures, options)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\", line 1032, in save\n",
      "    _, exported_graph, object_saver, asset_info = _build_meta_graph(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\", line 1198, in _build_meta_graph\n",
      "    return _build_meta_graph_impl(obj, signatures, options, meta_graph_def)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\", line 1151, in _build_meta_graph_impl\n",
      "    asset_info, exported_graph = _fill_meta_graph_def(meta_graph_def,\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\", line 692, in _fill_meta_graph_def\n",
      "    graph_def = exported_graph.as_graph_def(add_shapes=True)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3345, in as_graph_def\n",
      "    result, _ = self._as_graph_def(from_version, add_shapes)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3314, in _as_graph_def\n",
      "    node.attr[\"_output_shapes\"].list.shape.extend(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/inspect.py\", line 747, in getmodule\n",
      "    if f == _filesbymodname.get(modname, None):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-22-7097d41c5c42>\", line 3, in <module>\n",
      "    model_quantization(model_path=model_path, ds=flowers_datasets[0])\n",
      "  File \"<ipython-input-6-8b0f13698ff5>\", line 63, in model_quantization\n",
      "    tflite_model_quant = converter.convert()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 829, in convert\n",
      "    saved_model_convert_result = self._convert_as_saved_model()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 782, in _convert_as_saved_model\n",
      "    self._keras_model.save(temp_dir, save_format=\"tf\")\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 2001, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\", line 156, in save_model\n",
      "    saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save.py\", line 89, in save\n",
      "    save_lib.save(model, filepath, signatures, options)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\", line 1032, in save\n",
      "    _, exported_graph, object_saver, asset_info = _build_meta_graph(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\", line 1198, in _build_meta_graph\n",
      "    return _build_meta_graph_impl(obj, signatures, options, meta_graph_def)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\", line 1151, in _build_meta_graph_impl\n",
      "    asset_info, exported_graph = _fill_meta_graph_def(meta_graph_def,\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\", line 692, in _fill_meta_graph_def\n",
      "    graph_def = exported_graph.as_graph_def(add_shapes=True)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3345, in as_graph_def\n",
      "    result, _ = self._as_graph_def(from_version, add_shapes)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3314, in _as_graph_def\n",
      "    node.attr[\"_output_shapes\"].list.shape.extend(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3434, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2046, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1335, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_path in model_paths:\n",
    "    if \"flowers\" in model_path:\n",
    "        model_quantization(model_path=model_path, ds=flowers_datasets[0])\n",
    "    if \"beans\" in model_path:\n",
    "        model_quantization(model_path=model_path, ds=beans_datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
