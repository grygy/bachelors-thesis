{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base MNIST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import tempfile\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.5368 - accuracy: 0.8479 - val_loss: 0.1312 - val_accuracy: 0.9642\n",
      "Epoch 2/4\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.1468 - accuracy: 0.9589 - val_loss: 0.0860 - val_accuracy: 0.9773\n",
      "Epoch 3/4\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0952 - accuracy: 0.9733 - val_loss: 0.0741 - val_accuracy: 0.9807\n",
      "Epoch 4/4\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0720 - accuracy: 0.9797 - val_loss: 0.0651 - val_accuracy: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14b153c70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved baseline model to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkq987gss.h5\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_reshape  (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_6 (None, 26, 26, 12)        230       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten_ (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_7  (None, 10)                40572     \n",
      "=================================================================\n",
      "Total params: 40,805\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,395\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_images = x_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  3/422 [..............................] - ETA: 22s - loss: 0.0938 - accuracy: 0.9831 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0086s vs `on_train_batch_end` time: 0.0143s). Check your callbacks.\n",
      "422/422 [==============================] - 5s 9ms/step - loss: 0.0700 - accuracy: 0.9816 - val_loss: 0.1066 - val_accuracy: 0.9732\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.1321 - accuracy: 0.9621 - val_loss: 0.1025 - val_accuracy: 0.9725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14b3dc6a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9790999889373779\n",
      "Pruned test accuracy: 0.9671000242233276\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-61fa5d0d5ac6ab2d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-61fa5d0d5ac6ab2d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp51nf40pq.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpst5354gm/assets\n",
      "Saved pruned TFLite model to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmp9yxnguq0.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 78207.00 bytes\n",
      "Size of gzipped pruned Keras model: 25944.00 bytes\n",
      "Size of gzipped pruned TFlite model: 25208.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkvff_gf9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmpkvff_gf9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized and pruned TFLite model to: /var/folders/_1/7lg8klcj1d55272nzrt0k5740000gn/T/tmppu1lhzug.tflite\n",
      "Size of gzipped baseline Keras model: 78207.00 bytes\n",
      "Size of gzipped pruned and quantized TFlite model: 8249.00 bytes\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on ever y image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == test_labels).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Pruned and quantized TFLite test_accuracy: 0.9671\n",
      "Pruned TF test accuracy: 0.9671000242233276\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)\n",
    "print('Pruned TF test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
