{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import tempfile\n",
    "from os import path\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base MNIST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constatns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "NUM_CLASSES = 10\n",
    "INPUT_SHAPE = (28, 28, 1)\n",
    "MODEL_PATH = './mnist_models/first_mnist_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAI+CAYAAACxLHDrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqI0lEQVR4nO3deZheVZkv7GelEjJAAiSQyBDGEAJhFJBBIKLg0K04gYjQIo6AgCIOrUe72xZPa2s7gODMoHajjRM4KwoclUFQQAWSMIY5QJjJQKVqnz+gv0/dT3Gqkqq8Vavu+7q4Lv1lZb9PsN7Ur7Z7vas0TRMAADUZ0+kBAAAGm4IDAFRHwQEAqqPgAADVUXAAgOooOABAdRQcAKA6Cs4QKKVcXEpZXkp5/Ol/FnR6JuikUsrUUsr3SilPlFIWlVJe1+mZYDgopWzz9PeLb3R6ltooOEPn+KZp1nn6n207PQx02OkR8WREzIiIIyLi86WUuZ0dCYaF0yPiyk4PUSMFBxhSpZS1I+LVEfGhpmkeb5rmNxFxQUT8Q2cng84qpbw2Ih6OiF92eJQqKThD599KKQ+UUn5bSnlep4eBDpodESubpln4F9m1EeEODqNWKWVKRPxrRLyr07PUSsEZGu+LiK0iYpOI+FJE/KCUsnVnR4KOWSciHv2b7JGImNyBWWC4+EhEfLVpmjs7PUitFJwh0DTNFU3TPNY0zYqmac6JiN9GxN91ei7okMcjYsrfZFMi4rEOzAIdV0rZJSIOjIhPd3iUqo3t9ACjRBMRpdNDQIcsjIixpZRtmqa58els54i4roMzQSc9LyK2iIjbSykRT93l7CqlbN80zbM7OFdVStM0nZ6hKqWU9SJiz4i4JCJWRsRh8dT/TbXr3zyDAKNGKeWb8VTRf3NE7BIRP46IfZqmUXIYdUopk+Kv72q+O54qPMc2TXN/R4aqkDs4g29cRJwSEXMioici5kfEK5QbRrnjIuLMiLgvIpbEU3+RKzeMSk3TLI2Ipf/z30spj0fEcuVmcLmDAwBUx0PGAEB1FBwAoDoKDgBQHQUHAKiOggMAVOcZt4kfNOZQW6zomF/0njfsPhzRe4JO8p6Av/ZM7wl3cACA6ig4AEB1FBwAoDoKDgBQHQUHAKiOggMAVEfBAQCqo+AAANVRcACA6ig4AEB1FBwAoDoKDgBQHQUHAKiOggMAVEfBAQCqo+AAANVRcACA6ig4AEB1FBwAoDoKDgBQHQUHAKiOggMAVGdspwcAWPn83VrZPcetSNdeu/c5ab7zZUel+canr9XKui76wwCmA0Yid3AAgOooOABAdRQcAKA6Cg4AUB0FBwCojl1UA1TGtv+VdW24wWpfd8G7t0jznkm9ab751vel+aTjSiu791PtXSQREX/Y/Vtp/kDPE61sz/NOTtfOetflaQ6Z3nm7pvmpZ36ulc0al//1lL8jIq7e+6w0X7B7Tyt7zxZ79XEVGJ2eOGTPNP/4v38+zT/ymte3suaqPw/qTKvLHRwAoDoKDgBQHQUHAKiOggMAVKfKh4y7ttumlTXjx6Vr7563Xpov26v9oG1ExNR12/mvd84f1h1KP1k6Oc0//rkXt7IrdvyvdO2t3cvS/GOLD2plG/+6GcB0jHbdL9w9zd97xtfTfPa49oPwvX08TnxLd3eaP9I7Ps13TeIVL9kjXTvxoj+lee/y5WnO0Fr28ufk+bSuVjb1zMuGepyq3bd7fr/jI7e9bA1PMnjcwQEAqqPgAADVUXAAgOooOABAdRQcAKA6I3oXVc/znp3mnzr79FaW7dIYCbqb9sfMR0T802lvSPOxT7R3O+193vHp2sl3rUzz8Q+0d1dNuuqKPiZktOiaMiXNn9h/Tis76dP5zr0DJj7ex9X7/7PW2Q/tk+a/PGPvNP/tv5zayn7xlS+ka7f/Rv5e2ep9duh0wt37518Xk7Z+uB2eObSzVGVMexdas1m+q/YF0+en+S9L/j4cTtzBAQCqo+AAANVRcACA6ig4AEB1FBwAoDojehfV+AV3p/nvl89sZbPHLR7qcVpOvmevNL/l8Q1a2dlbfztd+0hvfgbUjFMvXfXB/h+cOkXmzq9tkuZX7tHetTiU/nX6lWn+03XyXR1H3/bCVnbOFhema6dsv2TVB2PQffil56X5x29o/29K/3VtvXkrmz8v34a2y++OTPONr8zPbRtO3MEBAKqj4AAA1VFwAIDqKDgAQHVG9EPGK++5N81P+/ihreyjL34iXdv1x3XS/NrjTuv3HKc8sFOa33TgpDTvefieVva6vY9L1952Yv6aW8a1/RsOBmjl83dL83N3+Vyaj4n+H4Ny9KIXpPlVF27Xyv70pvz1Llo2Ic2nX5V/1PxND7WPkhj3vy9K144paUyHjCv5cTKsnrFfWdrvtctuzo9oGQncwQEAqqPgAADVUXAAgOooOABAdRQcAKA6I3oXVV+mnnVZK9vwB9PStT1LHkzzuTu8Mc2v27/9cdYXfGleunb6w/0/TqFclu+K2rL9R4FB0Ttv1zQ/9cx899KscflfF73R28oOnv/KdG3XIfluxvX+vn1AyPZfPz5dO/v0O9J8zB1Xp/n6v25n3R/tSdd+Z6f84+rfeEB7O2PXRX9I1zJwvfvukub7TfjNmh1klNhi7f4fSTLzwvy9MhK4gwMAVEfBAQCqo+AAANVRcACA6ig4AEB1qtxFlel5oP9PjUdEdD/a//N15h5xfZrf//mu/Df0jtyn0hmZym5zW9kD78rPbpo9Lv/a//2K/Nq/enz7VrbkmzPTtdMeyrcFrvuNy9tZ/nIxlKcTzegan+ZL3tk+u2d6fpwVq2DRSyem+fSu/Dw/+mfsFpul+SFTL+j3NSbe+lCaj4TvYu7gAADVUXAAgOooOABAdRQcAKA6Cg4AUJ1Rs4tqoLZ738I0P3rHF7Syszb/Zbp23qFvT/PJ32rvGIHBMGZSvutk5b8/2soun/PddO2tK59M83d94OQ0X//Xt7ey6Wvfl64dCTsvMs/ZaFEru23Nj1GtsbMeG9D65fPXG5pBKnPHZ9ZO8+eOb58f99VHN80v8nD7746Rwh0cAKA6Cg4AUB0FBwCojoIDAFTHQ8Z96Hn4kTRfcux2rez2C/KPvP/HU76W5u9/zStbWXN1/sH0Mz+af7R9NE2eM6otm9c+kiEi4mdzzuj3Nd78jpPSfPL384fjh/LoBMhMv6r9kGxtujaY1soWv3p2unbqa+5M80tmf7WPq09oJZ8//RXpyumLL+3jGsOfOzgAQHUUHACgOgoOAFAdBQcAqI6CAwBUxy6qAeq99oZW9toPvydd+5///Mk0v2avZHfVXvnrzV37+DTf5sv3pPnKW27LL8SosNNHrknzMcnPMkcvah87EhEx8fu/G8yRhqVxpSvNu/vYnNhV7FocTpZNbX8954cSDEzvfrumedNV0vyOA8en+ZMbd7eyMWvlB5X8fL/T0nxc8pL39uSv96Fb2jtzIyIe7M13m00a055lxhX5cRkj+SvfHRwAoDoKDgBQHQUHAKiOggMAVEfBAQCqYxfVIJh6Zn5e1PEL3p7mUz7WPjfk3K1+lq697vWfS/M5M9+c5tt+uN1Ze268JV3LyPXwP+yd5h+cke/c6421Wtnvf759unazGLlnz/RXd5PvaOmNfNfJT29o/7vaJv4wqDONZiuWj0vz3j728Jz1gU+3sguO32W153jftK+k+ZjId1Eta55M87t72l9fn7v/eenaAy98Z5qvd3X7PbvRzxena8ui/Cyq+2+YmOYzutq7vJor/5SuHcncwQEAqqPgAADVUXAAgOooOABAdTxkPITKb69J86WHTG9lexx2Qrr2ivd9Ns3nH5A/DHfEFi9sZY/s28eAjFgr82cHY90x7QcTIyIuW97+iPetvnZ3fu1VnqqzxkyalObzP7lDkv4+XXvELS9J8znvuLWV5Y8psypmHXl1ms/9t/yompl73DUkc1x03+w0v/8nm6b5tOvaD+tGRKz10yuTNF87O67q12wRfX/N3fW+fdJ8j/H5BphvPr5Jv19zJHMHBwCojoIDAFRHwQEAqqPgAADVUXAAgOrYRdUBPYvva2UzTm1nERHL35vvaZlU8t0yX97ih63spa98Z36N713Rx4TUZknPOq1s5S23rflBBkFfu6UWfGzHNJ//8vZxJz9Zum669u7TZ6X55Icu7+d0DKYt35/vAlrTNorbOz3CM5q0//0DWv/Bi17dymbH7wZrnGHDHRwAoDoKDgBQHQUHAKiOggMAVEfBAQCqYxfVEOrdd5c0v/nQCa1sh11uS9f2tVuqL6c9uGv7Guf3/6wT6vTu3x7aymb3cR7TcNE7r/21HBFx37uWpfkNu7d3S0VEvOBPh7WytV98S7p2ctgtRf02P7/p9AhrhDs4AEB1FBwAoDoKDgBQHQUHAKiOggMAVMcuqgEqu+/Qyhae2Me5UM89J833n/Dkas+xoulO88sf3LId9t6z2q/HMFPyeEwfP7N8dt9zW9npMXswJ1oti/5171b2ndd/Kl07e1z+fnv2745K841fef2qDwaMWO7gAADVUXAAgOooOABAdRQcAKA6o/4h47Fbbp7mNx+9cZr/y2HfbGWvXueBQZ3pL31g8e5pfsln90rz9c+5bMhmYRjp45PWe6M3zedNXNLK3nn2bunarc/KrzHu3sfSfPG8DVvZ1MPuTNeesNkv0/wlk9rHRlzwxIx07ev/9OI03+CLa6c5jFZdJb+H8dDsca3sWT8Z6mnWPHdwAIDqKDgAQHUUHACgOgoOAFAdBQcAqE6Vu6jGbrFZK3tkt43StYf960/T/Jj1vjuoM/2lk+9p74C67Ix8t9TUs3+X5uv32i1F/00o7bf6DQd9IV37m/0mpPmNK56V5keve9sqz/U/3nH3fq3sp5fukq7d5h2Xr/brwWjQ0+Q7IkfLrY1R8scEAEYTBQcAqI6CAwBUR8EBAKqj4AAA1RkRu6jGbpTv3njwzPzsmWO3vKSVHT558aDO9JeOv2vfNP/D53dJ8w2+/edWNvUxu6LovxkX35fm73vb3mn+8Wf1/+tr/wlPpvm+E27r9zWuXpH/7HT4JW9N89lHt8+i2ibsloKhsHSPpZ0eYY1wBwcAqI6CAwBUR8EBAKqj4AAA1enYQ8ZPvig/muDJkx5sZR+Y9eN07QsnPjGoM/2lxT3L0nz/C05uZXM+OD9dO/Xh/MHOPj48G/qtZ+HNaX7joVuk+fYnnNDKrn/NaYMyy5wfH9fKtj0jf4hx9tXth4mBodFVRvc9jNH9pwcAqqTgAADVUXAAgOooOABAdRQcAKA6HdtFddsr8m61cMfzVvvapz+8dSv77CUvTNeWnpLmc065Nc23WXxFK+sZwGwwlFbecluazzqpnR980h6D8pqz48pW1gzKlYH+WHHhhmnes8vo3rPrDg4AUB0FBwCojoIDAFRHwQEAqqPgAADVKU3T936Hg8YcajMEHfOL3vPyLW4d5D1BJ3lPwF97pveEOzgAQHUUHACgOgoOAFAdBQcAqI6CAwBUR8EBAKqj4AAA1VFwAIDqKDgAQHUUHACgOgoOAFAdBQcAqI6CAwBUR8EBAKqj4AAA1VFwAIDqlKZpOj0DAMCgcgcHAKiOggMAVEfBAQCqo+AAANVRcACA6ig4AEB1FBwAoDoKDgBQHQUHAKiOggMAVEfBAQCqo+AAANVRcACA6ig4AEB1FBwAoDoKDgBQHQVnCJRSji+lXFVKWVFKObvT80CnlVK2K6X8qpTySCnlplLKKzs9E3RKKWV8KeWrpZRFpZTHSinXlFJe0um5aqPgDI27I+KUiDiz04NAp5VSxkbE+RHxw4iYGhFvjYhvlFJmd3Qw6JyxEXFHRMyLiHUj4oMR8d+llC06OVRtStM0nZ6hWqWUUyJi06Zp3tDpWaBTSik7RMTlETG5efovnFLKzyPiiqZpPtTR4WCYKKX8MSI+3DTNdzo9Sy3cwQE6oUTEDp0eAoaDUsqMiJgdEdd1epaaKDjAUFsQEfdFxHtKKeNKKS+Mp27NT+rsWNB5pZRxEfGfEXFO0zTzOz1PTRQcYEg1TdMdEa+IiL+PiHsj4uSI+O+IuLODY0HHlVLGRMTXI+LJiDi+w+NUZ2ynBwDq1zTNH+OpuzYREVFKuTQizuncRNBZpZQSEV+NiBkR8XdP/yDAIFJwhsDTu0bGRkRXRHSVUiZExMqmaVZ2djLojFLKThGxMJ66a3xcRGwUEWd3cibosM9HxHYRcWDTNMs6PUyN/F9UQ+ODEbEsIv4xIo58+j9/sKMTQWf9Q0TcE089i/OCiDioaZoVnR0JOqOUsnlEvC0idomIe0spjz/9zxGdnawutokDANVxBwcAqI6CAwBUR8EBAKqj4AAA1VFwAIDqPOPn4Bw05lBbrOiYX/SeVzo9w9/ynqCTvCfgrz3Te8IdHACgOgoOAFAdBQcAqI6CAwBUR8EBAKqj4AAA1VFwAIDqKDgAQHUUHACgOgoOAFAdBQcAqI6CAwBUR8EBAKqj4AAA1VFwAIDqKDgAQHUUHACgOgoOAFAdBQcAqI6CAwBUR8EBAKqj4AAA1VFwAIDqKDgAQHUUHACgOgoOAFAdBQcAqI6CAwBUZ2ynB2DV3PyJvdP8htd9rpWNK13p2v2Pe2uaT/z+71Z9MABWW9e0qa2srDslXXv7qzdO8+UbNGk+68PXtrLepUsHMN3I4A4OAFAdBQcAqI6CAwBUR8EBAKrjIeNh7t6T9knziw/79zTvbtbq/8Xz588AGGRjdpiT5je+f2Kav3HHS1vZydN+NiizbDfjmFa2zRt+PyjXHk7cwQEAqqPgAADVUXAAgOooOABAdRQcAKA6dlENc4/P7E3zqWMGsFsKhtCTL9q9lS06Iv+6PfbZl6T5O9df2O/X2/ErJ6T5pHvybYEP77OilW3+n/nPdmv97Kp+zwFljx3T/KaT2sfjXLxv+xidiIgNu8an+Zjk/sOPlq6frr1lxfQ0f/v6C9L86/t/uZV9ZI+j0rXNlX9K85HAHRwAoDoKDgBQHQUHAKiOggMAVEfBAQCqYxfVMPH4oXum+Xde+dk+fkdJ0y883D7v5MLXtHe5RESsvei6NM/3vzDa3X/M3ml+2ntPb2W7j+9J12Y7QyIijrrtwFa267q3p2uvfXNf74lc9pr7TD08XTt1cI76YYTq2nDDNF/42U3S/Af7nJHmW40bl6T5bqm+nPXozFb2/Vfvm67tHZ+9XsTbf5jvosren8tm5GdiTehrwBHAHRwAoDoKDgBQHQUHAKiOggMAVMdDxh2w/KXPaWX//G9npmtnj8sfJu7LOV9+cSt71vWXDugajA5lXH7cx/IDd07z77z/E2m+8dj2w5NvWnRQunbRJ7dN87V/dE0ru2jSZunaS743O59vmwvSPPPoNdPSfGq/r0CN7jpymzS/bl5fD7bnD/cOxDeSh4kjIr7/in1aWc+C/EiTsuvc1Z6jRu7gAADVUXAAgOooOABAdRQcAKA6Cg4AUB27qDrgniOXt7IDJrazp3SlafbR9hERz/qsHVP0zz3H50d4/O7dfe0YyT9q/tCbXtbKVr66O1076YEr0rxJsrvfulu69optBnZUw0+WTm5ls754R7p25YCuTG02Ofi2QbnOtx9/Viv71MIXpGtnvDf76o/oWXBjv1/voR2n9HvtaOIODgBQHQUHAKiOggMAVEfBAQCqo+AAANWxi2oIjd10kzS/br+zWll305OuvSHfjBK3fyo/j2ftyHepMLrdeNqerWzBq05L1/b2cY3tfnFMms95922trOeBJf0drU/HHHv+al8jIuKUjx7Vyta/47JBuTaVeUu+U3D7t5+Q5jN/kf+9vfZ197ayDRbl50jlVxiYpTMGdmbhaOEODgBQHQUHAKiOggMAVEfBAQCqo+AAANWxi2oQdM3dNs13/68/r/a1D/vuiWm+9XcuX+1rU5+b/2OvNF/wqtNb2SO9+flnh85/XZpve0Ifu0Aee6yf00WMWXvtNF9yyE6t7OXrfCK/RkxM8znnvT3NZ51txxT903PTrWk+66Q878uaPtOse4/+vwdHE3dwAIDqKDgAQHUUHACgOgoOAFAdDxkPgkUHT0vzb0+7uo/f0dVKXnfzy9KVsz92c5oPxsd7M3J1zZie5ue88ow0700OYOjrYeK1DlrUxzX6b8wu26f5DmfekOanzDg1SfOPzX/uNa9N823/Jb+29wrDwe3/tE+ar5zU5L8hO32hj6Wv2mZgD9Iff+fzWtnEn/4hXdvHS44I7uAAANVRcACA6ig4AEB1FBwAoDoKDgBQHbuoBujBo/duZd87Jv9I+YhxaXrMHfNaWfdR+Y6Rnvtv7/dsjB5lQv71svv4/u8ZmnjiWvm1N5+Z5jces2mav/DA9u6Lk6Z/KV272dj8mIVsh1ZPk+/fKN/aIM17Hr4xzWF1dU2ZkubLn7NNmo97/+JW9sc5pw3oNceV9m7b7mZgewIvWjYpze9862atrFmZ70IcydzBAQCqo+AAANVRcACA6ig4AEB1FBwAoDp2UfWha+62aX7pKZ9L0gkDuvZld27Rymbe9ucBXYPRrVm+Is2vWJHv3NtzfHcrO//Cb6Zrs3OrBurCZflOpxu7851RB0x8vJVd9WS+y2u9rw3s3B3IlPHtnYhPztsxXXvSGV9P8wMm/jLNF/e0358XLVs/XftPC1+e5ufOPbuVbTw23z3Zlwlj2u/7iIhbXrNeK9tqQf59rHf58gG95nDiDg4AUB0FBwCojoIDAFRHwQEAquMh4z4s/ED+EdcD/ajszGYfa2f5o5eQ61l8X5r/87FvTvNPfuGMVrZT/gxvfOPR/KiGUy45OM1nn91+CHHs4kfStdPPfTDND5j5q1Z21EX5n2V2XJXmkBkzIX94dslhu7ayX//vUwd07bnnnpDmm17U/j4x/kdXpmunbdR+wD4i4tyf7dbKTp42sM0o2eaCiIg/vqH959z7jhPTtTO+dm2a9y5dOqBZOsEdHACgOgoOAFAdBQcAqI6CAwBUR8EBAKoz6ndR9c5rP0kfEXHK7t9f7Wsf9OfXpvk6VzmWgaGx1s/yHUYf2PI5q33t2fG7fq997OX56/1os/PTvLtp/6w18bY+tnlBIjt6ISJi/qd2yvOX93/H1MsXvCLNZ3/iljTPdjmOnblpunbnC25P8/dMu76VPdL7ZLp2z++cnOYbzcl3W/5yx2+1sss+lP/7OOzwl6b5A6e2j7WYsCTftdWXrov/MKD1A+UODgBQHQUHAKiOggMAVEfBAQCqo+AAANUZ9buoPnr2l9J8h3H9Px3q3ffsn+brHv5Qmq/+aVYwvK2cmP/s1NdZbr3R28q2PDvfXbJy1ceiEmVs+1vXgs/snK6df/DpaX7nyhWt7OAvvjddu8WZN6f5yj7OhOs+sH2O1A4fvzpd+8/Tf5/mZz26eSv7+v96Wbp21ncvT/OuDaal+fMOap+h9cRh+flx39v1y2m+6an5rrXMD5/I5/jS7K36fY1V4Q4OAFAdBQcAqI6CAwBUR8EBAKqj4AAA1Rn1u6h2XWtguz0yl5317DSf/tClqzQTjHSTv5nv6oj/WLNzUKc73tM+62z+wZ9N196d7JaKiDj0Y+9pZVt8Pz9b6sHnb5nmzZGT0/zbO7Rn2bAr33U095vtHU0REbO/9EArm7TginRtX3oeWJLmU85t51POza9xyHH5zrIZhyzq/yAnr9fHL1zX/2usAndwAIDqKDgAQHUUHACgOgoOAFCdUfOQ8R3f3iHNx5VrVvvaG13cfhgswpEMjF6PvXavPn4l/1h6GIjPv+WMfq+dUPL8Zcf8n1a2yYn58TpHTflBv1/vKe0Hiuf+14npylnvvzLNe1YOj0NJpp+Rb5Zp+v8/QUTcNSizDJQ7OABAdRQcAKA6Cg4AUB0FBwCojoIDAFSnyl1UvfN2bWWf2eUb6dq+jmR4pHd5mu/xk3e2sjmLru//cDAKPLKVn50YOv/n8TmtbM/xf0rXTu3jiIQPbHBNv1/vpfNflea3X7Zpmm/17Uda2azr8h2EzTDZLVUjfwsBANVRcACA6ig4AEB1FBwAoDoKDgBQnSp3US2fulYr23fCE32s7krTny3dLM1nv7V9bkhvvyeD0WGTS5am+bjj8/dbdzOU01CbSw/YuJXtecTz07WP7Pxkmo+9f1wrm/2F/Myksffel+ZbLL8jzX1PGB7cwQEAqqPgAADVUXAAgOooOABAdap8yBjorPLba9L87Eenp/nhk9sPdy6du1G6dq077lzluahDz5IHW9mMUy9N184YwHUdmlAXd3AAgOooOABAdRQcAKA6Cg4AUB0FBwCoTpW7qKZcc28rO+HO/GO8vzDzkqEeB3jap794SJof/u7PtrKNPnRTunbJwzvlF7/8j6s8F1Afd3AAgOooOABAdRQcAKA6Cg4AUB0FBwCoTpW7qFbeuqiV3blXvvalsdsQTwP8j02+viDND3vFS1vZt2b9MF07758OT/Opr1s3zXsefqSf0wE1cQcHAKiOggMAVEfBAQCqo+AAANVRcACA6lS5iwoYnnoeWJLmT756Wivb7j/elq694cAvpvnBc96Uv6gzqmBUcgcHAKiOggMAVEfBAQCqo+AAANXxkDHQcdnDx9sclT+QfHDs0cdVPEwM/P/cwQEAqqPgAADVUXAAgOooOABAdRQcAKA6pWmaTs8AADCo3MEBAKqj4AAA1VFwAIDqKDgAQHUUHACgOgoOAFAdBQcAqI6CAwBUR8EBAKqj4AAA1VFwAIDqKDgAQHUUHACgOgoOAFAdBQcAqI6CAwBUR8EZAqWU40spV5VSVpRSzu70PNBppZRvlFLuKaU8WkpZWEp5c6dngk7yfWLolaZpOj1DdUopr4qI3oh4UURMbJrmDZ2dCDqrlDI3Im5qmmZFKWVORFwcEX/fNM3vOzsZdIbvE0PPHZwh0DTNd5um+X5ELOn0LDAcNE1zXdM0K/7nvz79z9YdHAk6yveJoafgAGtEKeWMUsrSiJgfEfdExI87PBJQMQUHWCOapjkuIiZHxH4R8d2IWPHMvwNg1Sk4wBrTNE1P0zS/iYhNI+LYTs8D1EvBATphbHgGBxhCCs4QKKWMLaVMiIiuiOgqpUwopYzt9FzQCaWU6aWU15ZS1imldJVSXhQRh0fELzs9G3SK7xNDT8EZGh+MiGUR8Y8RceTT//mDHZ0IOqeJp/7vqDsj4qGI+GREvLNpmgs6OhV0lu8TQ8zn4AAA1XEHBwCojoIDAFRHwQEAqqPgAADVUXAAgOo84577g8YcaosVHfOL3vNKp2f4W94TdJL3BPy1Z3pPuIMDAFRHwQEAqqPgAADVUXAAgOooOABAdRQcAKA6Cg4AUB0FBwCojoIDAFRHwQEAqqPgAADVUXAAgOooOABAdRQcAKA6Cg4AUB0FBwCojoIDAFRHwQEAqqPgAADVUXAAgOooOABAdRQcAKA6Yzs9wEiz8KzdWtmtL/pquvZTD26V5he+ZvdW1nP9wtUbDAD4/7iDAwBUR8EBAKqj4AAA1VFwAIDqKDgAQHXsoupD19xt0/z8A05vZd3NuHTt29dfkObf3umFrWzy9QMYDjqg7DY3zXvXav81ctfz1k7XXnfCGWne3fSs+mCr4AV/PiTN1375PWneu3z5UI5DZcr48a1s6Ut2Ttfu9L+uTfMb91gxqDONRu7gAADVUXAAgOooOABAdRQcAKA6HjLuy133pvGJC1/byn4x9ztDPQ0Mumbv/KHHG9+wVpp/+vnnpvm4srKVHTjxsXRtd5P/TNUbvWk+VH6xw3+n+S5ff2Oab3ns3a2s54ElgzoT9ejacINWdtHpX0jX/np5/m34E1u+rJWtvHXR6g02yriDAwBUR8EBAKqj4AAA1VFwAIDqKDgAQHXsoupDz8OPpPmiO7dph/kn2MOw1pzyYJrPn/PdNTzJ8HHNPmem+Yv2PK6Vjf+RXVSsvv0mtHchRkR8dLOprWyMXVQD4g4OAFAdBQcAqI6CAwBUR8EBAKqj4AAA1bGLqg9dM6an+X7bLVzDk8DQuOvimfkvzBnYdS5bPr6VvfHHb8kXlz4u0vT/9fZ6dv4ePGuLn/f/IjBMdBX3GYaKf7MAQHUUHACgOgoOAFAdBQcAqI6HjPsyee00/rupV672pe/brf2k5Xp/nJ2u7bneQ80Mjc0+dlWav/K/Dx/QdcqT3a1sm1uvWKWZ+uPhDaal+YWXT07zAyc+1u9rP/9Ph6X5lIuua2W9/b4q9K2nyb+Suie1vz23H+fnmbiDAwBUR8EBAKqj4AAA1VFwAIDqKDgAQHXsoupDz023pvkHf9DeZfHqw08f0LWve92prWzXR96Rrp1pFxVDpOl+Ms17Fty0hicZmMWvyncc7rjW+X38jv7vPbn77qlpvs7SW/p9DRgM9+02rpXN/EkHBhnB3MEBAKqj4AAA1VFwAIDqKDgAQHUUHACgOnZRDdDW7768HQ7s6B6gH+4/du80n3Pk/DSf0bX6J/Vs995892TPal+Z0aTpbp/PtrB7ebp29rgJab5sy3yXI/3nDg4AUB0FBwCojoIDAFRHwQEAqqPgAADVsYtqEIwrXWne3azhQWCYu+/4fdL8qGN/3MqOnPLJdO3kMWut9hwfuf/Zad6ssHOF1dez+L5WduLN7XMMIyJ+OqevM9RYXe7gAADVUXAAgOooOABAdRQcAKA6HjIeBN1N/kHuvdG7hieB/uuau22aLzx6/TSft++fV/s1fzjztDTP3ysDe5j4pu6VaX7Y509uZZt9b3E+x2M3D+g1geHLHRwAoDoKDgBQHQUHAKiOggMAVEfBAQCqYxcVjALNc3dpZW8463vp2pev/cAQTjJ0P1OdeFP+UfibfPzSVpbve4ThY52pSzs9wojnDg4AUB0FBwCojoIDAFRHwQEAqqPgAADVsYsKRqmuaNJ8zBD+3DOudKV5dz7KgPx0u3xX2H5HvL2Vrfufl6/+C8IQ+s6zv9zKTojndmCSkcsdHACgOgoOAFAdBQcAqI6CAwBUx0PGg2AwHpycss99gzQNtJXfXtPKvvqKF6dr//EN09J8s589meZdy1au8lzP5MY3jUvz+S/+/JC8HgylO34zM/+FOWt2jtHEHRwAoDoKDgBQHQUHAKiOggMAVEfBAQCqYxfVIOhuetK8N3r7fY1Ldj43zQ/e6035b7j8j/2+NmR6rl+Y5lu9dw0P0oftbtww/4V88xcMa+vcMbDzSCaX9vqu7Wena/t6L4927uAAANVRcACA6ig4AEB1FBwAoDoKDgBQHbuoBsGcX705za9//pdW+9oL37pWms++fLUvDcPa4lfN6vQIMGjGDPDItq5SWlnvxPx8NnLu4AAA1VFwAIDqKDgAQHUUHACgOgoOAFAdu6gGwfiFE/NfeP6anYPRo4wfn+YPH7prmq9//nWtrPexxwZ1ptVxz8n7tLLzT/z3Plbnf3YYztY/+7I0/8J7N0/zY9Zd1MpuPCnfVTvryFWfq2bu4AAA1VFwAIDqKDgAQHUUHACgOh4yHgQzP3Jpmp97xCZpfsTke/p97Vtf/JU0f8nOh6d577U39PvajAzLX/acVrbuu29P114y67Q0f+WVydfLgqF7yHjsRs9K87sO2SrNv3XCJ1vZxmMH9jDx4p4VaT5uWTOg68Ca9MnLX5TmL37BZ1rZ7LctTNf2DuZAFXEHBwCojoIDAFRHwQEAqqPgAADVUXAAgOrYRTWEzr69/fHzERGHzz2v39fotgFk1HvRRy9pZSdP+/OArjH/A1Pa4eN7rupI/0+v3Sf/WPrvT/9RmvfGuH5f+6jb8l0nN521bZpP+24+CwxnPVFaWe+y5R2YZORyBwcAqI6CAwBUR8EBAKqj4AAA1VFwAIDq2EU1hFacnZ/HE59Ys3PADQd+sdMjPC3/meqy5e1zp95yxevTtbPecmOaT3vCbinqsfXYia1sydHtc+kiIqZ91dd+xh0cAKA6Cg4AUB0FBwCojoIDAFTHQ8ZDaP1rHkzz0x9qf6T829dfMNTjMEL96sTntrKvHZc/bHjtc88c6nFavvHozFZ2T/d66doz/9D+s0REzPpyTyvb6rfXpGt7+z0ZDH9nzcvfsw/1LmtlG/zx8XStE31y7uAAANVRcACA6ig4AEB1FBwAoDoKDgBQHbuohlDP9QvT/Gc7TGlnsccAr37DKkzESNR18R9a2Za/m5Su3e3Ed6T5OW/7TCvbYa2Srn3+nw5L80cuzo8e2fxbd7WylbcuStduE79Pcxit3nPDIWl+yOZXt7IxT6xI17b3IBLhDg4AUCEFBwCojoIDAFRHwQEAqqPgAADVsYsKRqDepUvTfJOPXZrmH/hYfnZVZp24ZUD5yn5fGfhbU1+a77b9VaydpPlacu7gAADVUXAAgOooOABAdRQcAKA6Cg4AUB0FBwCojoIDAFRHwQEAqqPgAADVUXAAgOooOABAdRQcAKA6Cg4AUB0FBwCojoIDAFRHwQEAqlOapun0DAAAg8odHACgOgoOAFAdBQcAqI6CAwBUR8EBAKqj4AAA1fm/WvYOWqFGDZEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(train_images[i])\n",
    "    plt.title(int(train_labels[i]))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000, 28, 28), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.dtypes.cast(train_images, tf.float32)\n",
    "tf.dtypes.cast(test_images, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(28, 1, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 1, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "844/844 [==============================] - 495s 584ms/step - loss: 0.2071 - accuracy: 0.9357 - val_loss: 0.1034 - val_accuracy: 0.9715\n",
      "Epoch 2/4\n",
      "844/844 [==============================] - 484s 573ms/step - loss: 0.0457 - accuracy: 0.9854 - val_loss: 0.0521 - val_accuracy: 0.9870\n",
      "Epoch 3/4\n",
      "844/844 [==============================] - 488s 578ms/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 0.0556 - val_accuracy: 0.9852\n",
      "Epoch 4/4\n",
      "844/844 [==============================] - 507s 601ms/step - loss: 0.0342 - accuracy: 0.9898 - val_loss: 0.0518 - val_accuracy: 0.9852\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "if path.exists(MODEL_PATH):\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "else:\n",
    "    model = make_model(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n",
    "\n",
    "    # Train the digit classification model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(\n",
    "        train_images,\n",
    "        train_labels,\n",
    "        epochs=4,\n",
    "        validation_split=0.1,\n",
    "        batch_size=64,\n",
    "    )\n",
    "    \n",
    "    # save model\n",
    "    model.save(MODEL_PATH)\n",
    "    print('Saved')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 23s 75ms/step - loss: 0.0452 - accuracy: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04520625248551369, 0.984499990940094]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_1 (Rescaling)         (None, 28, 28, 1)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 28, 28, 28)   56          rescaling_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 28)   112         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 28)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 64)   1856        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 64)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_9 (SeparableCo (None, 28, 28, 128)  8896        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 128)  512         separable_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_10 (SeparableC (None, 28, 28, 128)  17664       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 128)  512         separable_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 14, 14, 128)  8320        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 128)  0           max_pooling2d_4[0][0]            \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 14, 14, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_11 (SeparableC (None, 14, 14, 256)  34176       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 14, 14, 256)  1024        separable_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 14, 14, 256)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_12 (SeparableC (None, 14, 14, 256)  68096       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 14, 14, 256)  1024        separable_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 256)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 7, 7, 256)    33024       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 7, 7, 256)    0           max_pooling2d_5[0][0]            \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 7, 7, 256)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_13 (SeparableC (None, 7, 7, 512)    133888      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 7, 7, 512)    2048        separable_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 7, 7, 512)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_14 (SeparableC (None, 7, 7, 512)    267264      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 7, 7, 512)    2048        separable_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 4, 4, 512)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 512)    131584      add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 512)    0           max_pooling2d_6[0][0]            \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_15 (SeparableC (None, 4, 4, 728)    378072      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 4, 728)    2912        separable_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 4, 4, 728)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_16 (SeparableC (None, 4, 4, 728)    537264      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 4, 4, 728)    2912        separable_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 2, 2, 728)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 2, 2, 728)    373464      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 728)    0           max_pooling2d_7[0][0]            \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_17 (SeparableC (None, 2, 2, 1024)   753048      add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 2, 2, 1024)   4096        separable_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 2, 2, 1024)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1024)         0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           10250       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,774,378\n",
      "Trainable params: 2,765,650\n",
      "Non-trainable params: 8,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "NUM_CLASSES = 10\n",
    "INPUT_SHAPE = (32, 32, 3)\n",
    "MODEL_PATH = './cifar_models/first_cifar_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2617s 15us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "704/704 [==============================] - 481s 675ms/step - loss: 1.5306 - accuracy: 0.4531 - val_loss: 0.9998 - val_accuracy: 0.6560\n",
      "Epoch 2/30\n",
      "704/704 [==============================] - 1773s 3s/step - loss: 0.8345 - accuracy: 0.7062 - val_loss: 0.9009 - val_accuracy: 0.7066\n",
      "Epoch 3/30\n",
      "704/704 [==============================] - 467s 663ms/step - loss: 0.6205 - accuracy: 0.7850 - val_loss: 0.7882 - val_accuracy: 0.7484\n",
      "Epoch 4/30\n",
      "704/704 [==============================] - 459s 651ms/step - loss: 0.4840 - accuracy: 0.8322 - val_loss: 0.7921 - val_accuracy: 0.7560\n",
      "Epoch 5/30\n",
      "704/704 [==============================] - 459s 652ms/step - loss: 0.3936 - accuracy: 0.8655 - val_loss: 0.9241 - val_accuracy: 0.7384\n",
      "Epoch 6/30\n",
      "704/704 [==============================] - 490s 697ms/step - loss: 0.3393 - accuracy: 0.8815 - val_loss: 0.8502 - val_accuracy: 0.7626\n",
      "Epoch 7/30\n",
      "704/704 [==============================] - 459s 652ms/step - loss: 0.2373 - accuracy: 0.9178 - val_loss: 0.8760 - val_accuracy: 0.7504\n",
      "Epoch 8/30\n",
      "704/704 [==============================] - 460s 654ms/step - loss: 0.2171 - accuracy: 0.9233 - val_loss: 0.7383 - val_accuracy: 0.8048\n",
      "Epoch 9/30\n",
      "704/704 [==============================] - 457s 650ms/step - loss: 0.1841 - accuracy: 0.9355 - val_loss: 0.9388 - val_accuracy: 0.7662\n",
      "Epoch 10/30\n",
      "704/704 [==============================] - 459s 653ms/step - loss: 0.1571 - accuracy: 0.9452 - val_loss: 1.0929 - val_accuracy: 0.7484\n",
      "Epoch 11/30\n",
      "704/704 [==============================] - 459s 652ms/step - loss: 0.1317 - accuracy: 0.9536 - val_loss: 0.7610 - val_accuracy: 0.8064\n",
      "Epoch 12/30\n",
      "704/704 [==============================] - 459s 652ms/step - loss: 0.1393 - accuracy: 0.9524 - val_loss: 0.9099 - val_accuracy: 0.7844\n",
      "Epoch 13/30\n",
      "704/704 [==============================] - 457s 649ms/step - loss: 0.1021 - accuracy: 0.9654 - val_loss: 1.0199 - val_accuracy: 0.7878\n",
      "Epoch 14/30\n",
      "704/704 [==============================] - 460s 653ms/step - loss: 0.1303 - accuracy: 0.9551 - val_loss: 0.8073 - val_accuracy: 0.8100\n",
      "Epoch 15/30\n",
      "704/704 [==============================] - 457s 649ms/step - loss: 0.1167 - accuracy: 0.9610 - val_loss: 0.8803 - val_accuracy: 0.8098\n",
      "Epoch 16/30\n",
      "704/704 [==============================] - 458s 651ms/step - loss: 0.1087 - accuracy: 0.9631 - val_loss: 0.7218 - val_accuracy: 0.8298\n",
      "Epoch 17/30\n",
      "704/704 [==============================] - 461s 655ms/step - loss: 0.0697 - accuracy: 0.9759 - val_loss: 0.7624 - val_accuracy: 0.8214\n",
      "Epoch 18/30\n",
      "704/704 [==============================] - 457s 650ms/step - loss: 0.0731 - accuracy: 0.9737 - val_loss: 0.8313 - val_accuracy: 0.8160\n",
      "Epoch 19/30\n",
      "704/704 [==============================] - 457s 650ms/step - loss: 0.0879 - accuracy: 0.9695 - val_loss: 1.1431 - val_accuracy: 0.7866\n",
      "Epoch 20/30\n",
      "704/704 [==============================] - 461s 655ms/step - loss: 0.0645 - accuracy: 0.9780 - val_loss: 0.9734 - val_accuracy: 0.8002\n",
      "Epoch 21/30\n",
      "704/704 [==============================] - 457s 650ms/step - loss: 0.0680 - accuracy: 0.9756 - val_loss: 0.9436 - val_accuracy: 0.8030\n",
      "Epoch 22/30\n",
      "704/704 [==============================] - 457s 649ms/step - loss: 0.1115 - accuracy: 0.9628 - val_loss: 0.9181 - val_accuracy: 0.8150\n",
      "Epoch 23/30\n",
      "704/704 [==============================] - 459s 652ms/step - loss: 0.0661 - accuracy: 0.9782 - val_loss: 0.9437 - val_accuracy: 0.8110\n",
      "Epoch 24/30\n",
      "704/704 [==============================] - 474s 673ms/step - loss: 0.0527 - accuracy: 0.9826 - val_loss: 0.8712 - val_accuracy: 0.8228\n",
      "Epoch 25/30\n",
      "704/704 [==============================] - 472s 671ms/step - loss: 0.0685 - accuracy: 0.9771 - val_loss: 0.9333 - val_accuracy: 0.8156\n",
      "Epoch 26/30\n",
      "704/704 [==============================] - 457s 649ms/step - loss: 0.0660 - accuracy: 0.9785 - val_loss: 1.0089 - val_accuracy: 0.8062\n",
      "Epoch 27/30\n",
      "704/704 [==============================] - 457s 648ms/step - loss: 0.0520 - accuracy: 0.9812 - val_loss: 1.0637 - val_accuracy: 0.7954\n",
      "Epoch 28/30\n",
      "704/704 [==============================] - 458s 650ms/step - loss: 0.0725 - accuracy: 0.9764 - val_loss: 0.8991 - val_accuracy: 0.8226\n",
      "Epoch 29/30\n",
      "704/704 [==============================] - 460s 653ms/step - loss: 0.0426 - accuracy: 0.9852 - val_loss: 0.9876 - val_accuracy: 0.8108\n",
      "Epoch 30/30\n",
      "704/704 [==============================] - 483s 685ms/step - loss: 0.0510 - accuracy: 0.9827 - val_loss: 0.9708 - val_accuracy: 0.8126\n",
      "Saved to: ./cifar_models/first_cifar_model.h5\n"
     ]
    }
   ],
   "source": [
    "if path.exists(MODEL_PATH):\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    print('Loaded from: ' + MODEL_PATH)\n",
    "else:\n",
    "    model = make_model(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n",
    "\n",
    "    # Train the digit classification model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    checkpoint_filepath = './tmp/'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "    model.fit(\n",
    "        train_images,\n",
    "        train_labels,\n",
    "        epochs=30,\n",
    "        validation_split=0.1,\n",
    "        batch_size=64,\n",
    "        callbacks=[model_checkpoint_callback]\n",
    "    )\n",
    "    \n",
    "    # save model\n",
    "    model.save(MODEL_PATH)\n",
    "    print('Saved to: ' + MODEL_PATH)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 32s 99ms/step - loss: 0.7219 - accuracy: 0.7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7163470983505249, 0.7759000062942505]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
