{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation scrip to run on NXP board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save images to png\n",
    "\n",
    "inspirated by https://stackoverflow.com/questions/57338091/how-to-save-tensor-as-a-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "\n",
    "def preprocess_flowers_test_and_val(image, label):\n",
    "    image = tf.image.resize(image, [256, 256],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "(ds_tran, ds_test), ds_info = tfds.load(\n",
    "        'oxford_flowers102',\n",
    "        split=['train','test'],\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "ds_test = ds_test.map(preprocess_flowers_test_and_val)\n",
    "\n",
    "i = 0\n",
    "for image, label in ds_test.as_numpy_iterator():\n",
    "    i+=1\n",
    "    img = Image.fromarray(image)\n",
    "    image_directory = pathlib.Path(\"../datasets/flowers_test/\" + str(label))\n",
    "    image_directory.mkdir(parents=True, exist_ok=True)\n",
    "    image_path = image_directory/(str(i) + '.png')\n",
    "    img.save(str(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_tran, ds_test), ds_info = tfds.load(\n",
    "        'beans',\n",
    "        split=['train','test'],\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "\n",
    "i = 0\n",
    "for image, label in ds_test.as_numpy_iterator():\n",
    "    i+=1\n",
    "    img = Image.fromarray(image)\n",
    "    image_directory = pathlib.Path(\"../datasets/beans_test/\" + str(label))\n",
    "    image_directory.mkdir(parents=True, exist_ok=True)\n",
    "    image_path = image_directory/(str(i) + '.png')\n",
    "    img.save(str(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation script to run on mobile device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating: MobileNetV2_flowers_model_PolynomialDecay50_float16_quantization.tflite\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-288b56d58966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# check if model is in tflite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluating: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mevaluated_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-288b56d58966>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model_path, dataset_path)\u001b[0m\n\u001b[1;32m    110\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                                      \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                                      \u001b[0mavg_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mavg_time\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                                      gzip_size=gzip_size)\n\u001b[1;32m    114\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'avg time: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'ms, gzip: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgzip_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Bytes\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import copy\n",
    "from json import JSONEncoder\n",
    "import os\n",
    "import os\n",
    "import zipfile\n",
    "import tempfile\n",
    "import sys\n",
    "\n",
    "# todo uncomment this on device and comment line bellow\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "\n",
    "# import tensorflow.lite as tflite\n",
    "\n",
    "\n",
    "class EvaluatedModel:\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    model_name = ''\n",
    "    avg_time = 0.0\n",
    "    gzip_size = 0\n",
    "\n",
    "    def __init__(self, dict1=None, y_pred=[], y_true=[], model_name='', avg_time=0.0, gzip_size=0):\n",
    "        if (dict1 == None):\n",
    "            self.y_pred = copy.deepcopy(y_pred)\n",
    "            self.y_true = copy.deepcopy(y_true)\n",
    "            self.model_name = model_name\n",
    "            self.avg_time = avg_time\n",
    "            self.gzip_size = gzip_size\n",
    "        else:\n",
    "            self.__dict__.update(dict1)\n",
    "\n",
    "\n",
    "# subclass JSONEncoder\n",
    "class EvaluatedModelEncoder(JSONEncoder):\n",
    "    def default(self, o):\n",
    "        return o.__dict__\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    if len(argv) != 2:\n",
    "        print('args: beans/flowers MobileNetV2/EfficentNetB0')\n",
    "        sys.exit(2)\n",
    "    # parse arguments\n",
    "    dataset = argv[0]\n",
    "    model = argv[1]\n",
    "\n",
    "    def get_gzipped_model_size(file):\n",
    "        # Returns size of gzipped model, in bytes.\n",
    "\n",
    "        _, zipped_file = tempfile.mkstemp('.zip')\n",
    "        with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "            f.write(file)\n",
    "\n",
    "        return os.path.getsize(zipped_file)\n",
    "\n",
    "    def evaluate_model(model_path, dataset_path):\n",
    "        \"\"\" returns EvaluatedModel for given model and dataset \"\"\"\n",
    "\n",
    "        # model cannot use\n",
    "        if \"dynamic_rage_quantization\" in model_path:\n",
    "            print(\"model cannot use  NNAPI\\n\\n\")\n",
    "            return EvaluatedModel(dict1=None,\n",
    "                                  y_pred=[],\n",
    "                                  y_true=[],\n",
    "                                  model_name=model_path.split('/')[-1],\n",
    "                                  avg_time=0,\n",
    "                                  gzip_size=0)\n",
    "\n",
    "        interpreter = tflite.Interpreter(\n",
    "            model_path=model_path, num_threads=None)\n",
    "        interpreter.allocate_tensors()\n",
    "\n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "\n",
    "        # check the type of the input tensor\n",
    "        floating_model = input_details[0]['dtype'] == np.float32 or input_details[0]['dtype'] == np.float16\n",
    "        if not floating_model:\n",
    "            print('model has int i/o')\n",
    "\n",
    "        input_index = input_details[0][\"index\"]\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        avg_time = 0.0\n",
    "\n",
    "        for subdir, dirs, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "                if file == '.DS_Store':\n",
    "                    continue\n",
    "\n",
    "                y_true.append(int(subdir.split('/')[-1]))\n",
    "\n",
    "                img = Image.open(os.path.join(subdir, file))\n",
    "\n",
    "                # add batch dimension\n",
    "                test_image = np.expand_dims(img, axis=0)\n",
    "\n",
    "                if floating_model:\n",
    "                    test_image = (np.float32(test_image) / 255.0)\n",
    "\n",
    "                interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "\n",
    "                # ignore the 1st invoke\n",
    "                interpreter.invoke()\n",
    "\n",
    "                startTime = time.time()\n",
    "                interpreter.invoke()\n",
    "                delta = (time.time() - startTime) * 1000\n",
    "                avg_time += delta\n",
    "\n",
    "                output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "                # remove batch dimension and return predicted label\n",
    "                y_pred.append(np.argmax(output[0]).item())\n",
    "\n",
    "        gzip_size = get_gzipped_model_size(model_path)\n",
    "\n",
    "        evaluated_model = EvaluatedModel(dict1=None,\n",
    "                                         y_pred=y_pred,\n",
    "                                         y_true=y_true,\n",
    "                                         model_name=model_path.split('/')[-1],\n",
    "                                         avg_time=avg_time / len(y_pred),\n",
    "                                         gzip_size=gzip_size)\n",
    "        print('avg time: ' + str(evaluated_model.avg_time) + 'ms, gzip: ' + str(evaluated_model.gzip_size) + 'Bytes\\n')\n",
    "\n",
    "        return evaluated_model\n",
    "\n",
    "    dataset_path = 'datasets/' + dataset + '_test/'\n",
    "    print(dataset_path)\n",
    "    evaluated_models = []\n",
    "\n",
    "    for subdir, dirs, files in os.walk(dataset + '_models_optimized/'):\n",
    "        model_no = 0\n",
    "        for file in files:\n",
    "\n",
    "            if file.split('.')[-1] == 'tflite' and model in file:\n",
    "                model_no += 1\n",
    "                # check if model is in tflite\n",
    "                print('evaluating: ' + file)\n",
    "                evaluated_models.append(evaluate_model(os.path.join(subdir, file), dataset_path))\n",
    "                if model_no % 10 == 0:\n",
    "                    encoded_json = EvaluatedModelEncoder().encode(evaluated_models)\n",
    "                    with open('evaluated_' + dataset + '_models_on_' + model + str(model_no) + '.json', 'w') as f:\n",
    "                        f.write(encoded_json)\n",
    "\n",
    "    encoded_json = EvaluatedModelEncoder().encode(evaluated_models)\n",
    "    with open('evaluated_' + dataset + '_models_on_' + model + '.json', 'w') as f:\n",
    "        f.write(encoded_json)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
